{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SC_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waynchi/SC-Net/blob/master/SC_CNN_with_stop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U22qZkbsfEyI",
        "colab_type": "code",
        "outputId": "4e88c963-7aac-4719-a319-a4dfa061e6e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install mnist\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mnist in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mnist) (1.18.4)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45bLorRNFfdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LsQqrsgeqA1",
        "colab_type": "code",
        "outputId": "75569a4a-a7d0-4295-fa2e-f69b84e532eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.is_gpu_available()\n"
      ],
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 360
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VxF9dG1KU6Mf"
      },
      "source": [
        "# What about a GAN + Self correcting U-Net ? That would make for a cool architecture\n",
        "# Following CGAN -> adding a 1-hot vector encoding of the label to the training data\n",
        "# Simulated Annealing?\n",
        "# Generator -> VAE -> Discriminator?\n",
        "# What about feeding in a dicriminator's confidence level as a temperature during the autoregressive? Inverse confidence?\n",
        "# What about a 3 dimensional GAN?\n",
        "\n",
        "# Umut Notes\n",
        "- Add a stop condition to the softmax\n",
        "- 2 steps process (pick note and then choose how much through binary cross entropy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OeM4sX2NNYT0",
        "outputId": "968a04f6-103c-48db-c2ad-902e4707e7b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "import mnist\n",
        "import scipy.misc\n",
        "from PIL import Image\n",
        "from pprint import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "\n",
        "def create_image(image, name, image_shape=(28, 28)):\n",
        "    img_arr = deepcopy(image.reshape(image_shape)).astype(np.uint8)\n",
        "    # print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "    # print(img_arr)\n",
        "    img_arr[img_arr > 0] = 255\n",
        "    # pprint(img_arr)\n",
        "    # print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "    img = Image.fromarray(img_arr.astype(np.uint8), 'L')\n",
        "    img.save(name)\n",
        "    return img\n",
        "\n",
        "images = mnist.train_images()\n",
        "num_samples = 60000\n",
        "np.random.shuffle(images)\n",
        "images = images[:num_samples, :, :]\n",
        "# For black and white\n",
        "images[images > 0] = 1\n",
        "\n",
        "# For grayscale\n",
        "# images = images / 255.0\n",
        "# images = images.reshape(images.shape[0], -1)\n",
        "pprint(images)\n",
        "print(images.shape)\n",
        "\n",
        "labels = mnist.train_labels()\n",
        "n_labels = np.max(labels) + 1\n",
        "labels = np.eye(n_labels)[labels]\n",
        "print(labels.shape)\n",
        "\n",
        "create_image(images[0], 'my.png')\n",
        "print(labels[0])\n",
        "\n",
        "# images = images[:1000, :, :]\n",
        "# print(images[0].shape)\n",
        "# pprint(images[0])\n",
        "# img = Image.fromarray(images[0], 'L')\n",
        "# img.save('my.png')\n",
        "# img.show()\n",
        "\n",
        "image_shape = np.expand_dims(images[0], axis=-1).shape \n",
        "# print(image_shape)"
      ],
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "array([[[0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)\n",
            "(60000, 28, 28)\n",
            "(60000, 10)\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OlmEDomwi9dZ",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Flatten, Dense, Softmax\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "def built_in_softmax_kl_loss(target, output):\n",
        "    target = K.flatten(target)\n",
        "    output = K.flatten(output)\n",
        "    \n",
        "    target = target / K.sum(target)\n",
        "    output = K.softmax(output)\n",
        "    return keras.losses.kullback_leibler_divergence(target, output)\n",
        "\n",
        "keras.losses.built_in_softmax_kl_loss = built_in_softmax_kl_loss\n",
        " \n",
        "def unet_model(input_size=(28, 28, 1), n_filters_start=32, growth_factor=2,\n",
        "               upconv=False):\n",
        "    droprate=0.5\n",
        "    n_filters = n_filters_start\n",
        "    inputs = Input(input_size)\n",
        "    conv_first = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv_first = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_first)\n",
        "    pool_first = MaxPooling2D(pool_size=(2, 2))(conv_first)\n",
        "\n",
        "    prev_pool = pool_first\n",
        "    hidden_layers = []\n",
        "    for _ in range(1):\n",
        "        n_filters *= growth_factor\n",
        "        pool = BatchNormalization()(prev_pool)\n",
        "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool)\n",
        "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv)\n",
        "        pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
        "        pool = Dropout(droprate)(pool)\n",
        "        prev_pool = pool\n",
        "        hidden_layers.append(conv)\n",
        " \n",
        "    n_filters *= growth_factor\n",
        "    conv_mid = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(prev_pool)\n",
        "    conv_mid = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_mid)\n",
        " \n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up_first = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv_mid), hidden_layers[-1]])\n",
        "    else:\n",
        "        up_first = concatenate([UpSampling2D(size=(2, 2))(conv_mid), hidden_layers[-1]])\n",
        "    up_first = BatchNormalization()(up_first)\n",
        "    conv_mid_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up_first)\n",
        "    conv_mid_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_mid_2)\n",
        "    conv_mid_2 = Dropout(droprate)(conv_mid_2)\n",
        "\n",
        "    prev_conv = conv_mid_2\n",
        "    for i in range(0):\n",
        "        n_filters //= growth_factor\n",
        "        if upconv:\n",
        "            up = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(prev_conv), hidden_layers[-i-2]])\n",
        "        else:\n",
        "            up = concatenate([UpSampling2D(size=(2, 2))(prev_conv), hidden_layers[-i-2]])\n",
        "        up = BatchNormalization()(up)\n",
        "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up)\n",
        "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv)\n",
        "        conv = Dropout(droprate)(conv)\n",
        "        prev_conv = conv\n",
        " \n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up_last = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv_mid_2), conv_first])\n",
        "    else:\n",
        "        up_last = concatenate([UpSampling2D(size=(2, 2))(conv_mid_2), conv_first])\n",
        "    conv_last = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up_last)\n",
        "    conv_last = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_last)\n",
        " \n",
        "    conv_out = Conv2D(1, 1, activation='linear')(conv_last)\n",
        "    output = Flatten()(conv_out)\n",
        "\n",
        "    flatten = Flatten()(conv_last)\n",
        "    dense = Dense(1, activation='linear')(flatten)\n",
        "\n",
        "    output = concatenate([output, dense])\n",
        "    # output = Softmax()(output)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    # model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.compile(optimizer=Adam(), loss=built_in_softmax_kl_loss)\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rSjQr52iQzlu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b2c373a3-bd34-42dc-de33-82ee65fa8bd2"
      },
      "source": [
        "model = unet_model(input_size=image_shape)"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_44\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_47 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_507 (Conv2D)             (None, 28, 28, 32)   320         input_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_508 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_507[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_93 (MaxPooling2D) (None, 14, 14, 32)   0           conv2d_508[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 14, 14, 32)   128         max_pooling2d_93[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_509 (Conv2D)             (None, 14, 14, 64)   18496       batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_510 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_509[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_94 (MaxPooling2D) (None, 7, 7, 64)     0           conv2d_510[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_93 (Dropout)            (None, 7, 7, 64)     0           max_pooling2d_94[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_511 (Conv2D)             (None, 7, 7, 128)    73856       dropout_93[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_512 (Conv2D)             (None, 7, 7, 128)    147584      conv2d_511[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_93 (UpSampling2D) (None, 14, 14, 128)  0           conv2d_512[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_117 (Concatenate)   (None, 14, 14, 192)  0           up_sampling2d_93[0][0]           \n",
            "                                                                 conv2d_510[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 14, 14, 192)  768         concatenate_117[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_513 (Conv2D)             (None, 14, 14, 64)   110656      batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_514 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_513[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_94 (Dropout)            (None, 14, 14, 64)   0           conv2d_514[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_94 (UpSampling2D) (None, 28, 28, 64)   0           dropout_94[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_118 (Concatenate)   (None, 28, 28, 96)   0           up_sampling2d_94[0][0]           \n",
            "                                                                 conv2d_508[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_515 (Conv2D)             (None, 28, 28, 32)   27680       concatenate_118[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_516 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_515[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_517 (Conv2D)             (None, 28, 28, 1)    33          conv2d_516[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_62 (Flatten)            (None, 25088)        0           conv2d_516[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_61 (Flatten)            (None, 784)          0           conv2d_517[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 1)            25089       flatten_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_119 (Concatenate)   (None, 785)          0           flatten_61[0][0]                 \n",
            "                                                                 dense_25[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 496,962\n",
            "Trainable params: 496,514\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsFM5XMYeqBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBEdqEBxFqNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# discriminator_model = discriminator(input_size=image_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SVUVU8Kt_aCm",
        "colab": {}
      },
      "source": [
        "from copy import deepcopy\n",
        "import math\n",
        "import itertools\n",
        "def mask_image(image):\n",
        "    image = deepcopy(image)\n",
        "    sampling_percentage = np.random.uniform(0, 100)\n",
        "    non_zero = np.nonzero(image)\n",
        "    mask1 = np.full(len(non_zero[0]), False)\n",
        "    mask1[:math.floor(len(non_zero[0]) * (sampling_percentage/100))] = True\n",
        "    np.random.shuffle(mask1)\n",
        "    # pprint(mask1)\n",
        "    r1 = list(itertools.compress(non_zero[0], mask1))\n",
        "    c1 = list(itertools.compress(non_zero[1], mask1))\n",
        "    output_image = deepcopy(image)\n",
        "    output_image[r1,c1] = 0\n",
        "    return output_image\n",
        "\n",
        "def mask_image_with_noise(image):\n",
        "    image = deepcopy(image)\n",
        "    sampling_percentage_mask = np.random.uniform(0, 100)\n",
        "    sampling_percentage_noise = np.random.uniform(0, 20)\n",
        "    non_zero = np.nonzero(image)\n",
        "    zeroes = np.nonzero(image == 0)\n",
        "    mask = np.full(len(non_zero[0]), False)\n",
        "    noise = np.full(len(zeroes[0]), False) \n",
        "    amount_to_mask = math.floor(len(non_zero[0]) * (sampling_percentage_mask/100))\n",
        "    mask[:amount_to_mask] = True\n",
        "    amount_to_mask_2 = math.floor(len(zeroes[0]) * (sampling_percentage_noise/100))\n",
        "    noise[:amount_to_mask_2] = True\n",
        "    np.random.shuffle(mask)\n",
        "    np.random.shuffle(noise)\n",
        "    # pprint(mask1)\n",
        "    output_image = deepcopy(image)\n",
        "    r1 = list(itertools.compress(non_zero[0], mask))\n",
        "    c1 = list(itertools.compress(non_zero[1], mask))\n",
        "    r2 = list(itertools.compress(zeroes[0], noise))\n",
        "    c2 = list(itertools.compress(zeroes[1], noise))\n",
        "    output_image[r1,c1] = 0\n",
        "    output_image[r2,c2] = 1\n",
        "    return output_image\n",
        "\n",
        "def mask_image_with_noise_grayscale(image):\n",
        "    image = deepcopy(image)\n",
        "    sampling_percentage_mask = np.random.uniform(0, 100)\n",
        "    sampling_percentage_noise = np.random.uniform(0, 20)\n",
        "    non_zero = np.nonzero(image)\n",
        "    zeroes = np.nonzero(image == 0)\n",
        "    mask = np.full(len(non_zero[0]), False)\n",
        "    noise = np.full(len(zeroes[0]), False) \n",
        "    amount_to_mask = math.floor(len(non_zero[0]) * (sampling_percentage_mask/100))\n",
        "    mask[:amount_to_mask] = True\n",
        "    amount_to_mask_2 = math.floor(len(zeroes[0]) * (sampling_percentage_noise/100))\n",
        "    noise[:amount_to_mask_2] = True\n",
        "    np.random.shuffle(mask)\n",
        "    np.random.shuffle(noise)\n",
        "    # pprint(mask1)\n",
        "    output_image = deepcopy(image)\n",
        "    r1 = list(itertools.compress(non_zero[0], mask))\n",
        "    c1 = list(itertools.compress(non_zero[1], mask))\n",
        "    r2 = list(itertools.compress(zeroes[0], noise))\n",
        "    c2 = list(itertools.compress(zeroes[1], noise))\n",
        "    output_image[r1,c1] = -1.0\n",
        "    output_image[r2,c2] = 1.0\n",
        "    return output_image\n",
        "\n",
        "class ImageGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, sample_list, image_shape, batch_size, samples_per_data_item, stops_per_data_item, seed=None):\n",
        "        print(\"sample_list: {}\".format(len(sample_list)))\n",
        "        self.sample_list = sample_list\n",
        "        self.image_shape = image_shape\n",
        "        self.batch_size = batch_size\n",
        "        self.samples_per_data_item = samples_per_data_item\n",
        "        self.stops_per_data_item = stops_per_data_item\n",
        "        # self.training_input = []\n",
        "        # self.training_target = []\n",
        "        # self.training_original = []\n",
        "        self.sample_index = 0\n",
        "        self.seed = seed\n",
        "        # if self.seed is not None:\n",
        "        #     np.random.seed(self.seed)\n",
        "\n",
        "    def generate_training_pairs(self):\n",
        "        '''\n",
        "        Generates Training Pairs till @training_input / @training_target have @batch_size files.\n",
        "        '''\n",
        "        training_input = []\n",
        "        training_original = []\n",
        "        training_target = []\n",
        "        while len(training_input) < self.batch_size:\n",
        "            original_image = deepcopy(self.sample_list[self.sample_index])\n",
        "            original_image = original_image.reshape(self.image_shape)\n",
        "            original_image[original_image > 0] = 1\n",
        "            self.sample_index = (self.sample_index + 1) % len(self.sample_list)\n",
        "            # print(\"sample_list length: {}. sample_index: {}\".format(\n",
        "            #     len(self.sample_list), self.sample_index))\n",
        "            try:\n",
        "                # augment by adding and removing random values in the array\n",
        "\n",
        "                # Add random values\n",
        "                for _ in range(self.samples_per_data_item):\n",
        "                    input_image = mask_image_with_noise(original_image)\n",
        "\n",
        "                    # xor_target = original_image\n",
        "                    xor_target = np.logical_xor(input_image, original_image)\n",
        "                    input_image = input_image.astype(np.float32)\n",
        "                    xor_target = xor_target.astype(np.float32)\n",
        "                    xor_target = xor_target.flatten()\n",
        "                    xor_target = np.append(xor_target, 0.0)\n",
        "                    original_image = original_image.astype(np.float32)\n",
        "                    training_input.append(deepcopy(input_image))\n",
        "                    training_original.append(deepcopy(original_image))\n",
        "                    training_target.append(deepcopy(xor_target))\n",
        "\n",
        "                # Add original\n",
        "                training_input.append(deepcopy(original_image.astype(np.float32)))\n",
        "                training_original.append(deepcopy(original_image.astype(np.float32)))\n",
        "                xor_target = np.full(np.prod(self.image_shape), 0.0, dtype=np.float32)\n",
        "                xor_target = np.append(xor_target, 1.0)\n",
        "                training_target.append(deepcopy(xor_target))\n",
        "\n",
        "            except Exception as e:\n",
        "                print('Error generating input and target pair')\n",
        "                traceback.print_exc()\n",
        "        return np.asarray(training_input), np.asarray(training_target), np.asarray(training_original)\n",
        "\n",
        "    def save_image(self, img_arr, img_name):\n",
        "        img_arr = img_arr.reshape(self.image_shape)\n",
        "        print(img_name)\n",
        "        print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "        img_arr = img_arr[:, :, 0]\n",
        "        print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "        #pprint(img_arr)\n",
        "        img_arr[img_arr != 0] = 255\n",
        "        #pprint(img_arr)\n",
        "        print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "        img = Image.fromarray(img_arr.astype(np.uint8), 'L')\n",
        "        img.save(img_name)\n",
        "\n",
        "    def get_random_training_pair(self):\n",
        "        import random\n",
        "        training_input, training_target, training_original = self.generate_training_pairs()\n",
        "        print(\"training_input shape: {}\".format(training_input.shape))\n",
        "        index = random.randrange(0, len(training_input))\n",
        "        self.save_image(deepcopy(training_input[index]), 'training_input.png')\n",
        "        training_image = training_target[index][:np.prod(self.image_shape)]\n",
        "        print(training_target[index][-1])\n",
        "        self.save_image(deepcopy(training_image), 'training_target.png')\n",
        "        self.save_image(deepcopy(training_original[index]), 'training_original.png')\n",
        "\n",
        "    def generate_validation_samples(self):\n",
        "        old_batch_size = self.batch_size\n",
        "        self.batch_size = len(self.sample_list) * (self.samples_per_data_item + self.stops_per_data_item)\n",
        "        training_input, training_target, training_original = self.generate_training_pairs()\n",
        "        # training_input = np.asarray(self.training_input[:self.batch_size])\n",
        "        # training_target = np.asarray(self.training_target[:self.batch_size])\n",
        "        self.batch_size = old_batch_size\n",
        "        return training_input, training_target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''Generates 1 batch of data'''\n",
        "        training_input, training_target, training_original = self.generate_training_pairs()\n",
        "        # training_input = np.asarray(self.training_input[:self.batch_size])\n",
        "        # training_target = np.asarray(self.training_target[:self.batch_size])\n",
        "        # self.training_input = self.training_input[self.batch_size:]\n",
        "        # self.training_target = self.training_target[self.batch_size:]\n",
        "        # print(\"training input sum: {}. target sum: {}\".format(training_input.sum(), training_target.sum()))\n",
        "        return np.asarray(training_input), np.asarray(training_target)\n",
        "\n",
        "    def __len__(self):\n",
        "        '''Number of batches / epoch'''\n",
        "        # print(\"sample_list: {}. samples_per_data_item: {}, batch size: {}\".\n",
        "        #       format(len(self.sample_list), self.samples_per_data_item,\n",
        "        #              self.batch_size))\n",
        "        samples_to_generate = int(\n",
        "            (len(self.sample_list) * (self.samples_per_data_item + self.stops_per_data_item)) /\n",
        "            self.batch_size)\n",
        "        # print(\"samples to generate: {}\".format(samples_to_generate))\n",
        "        return samples_to_generate\n",
        "    \n",
        "    #def on_epoch_end(self):\n",
        "    #    if self.seed is not None:\n",
        "    #        np.random.seed(self.seed)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1zwLYew1a-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Config\n",
        "batch_size = 32\n",
        "samples_per_data_item = 1 \n",
        "stops_per_data_item = 1\n",
        "split = 0.8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ngo7o_rw2TsK",
        "outputId": "e9913838-9a62-428b-e6fc-5675bb89a31e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "\n",
        "training_samples = images[:int(len(images) * split)]\n",
        "validation_samples = images[int(len(images) * split):]\n",
        "\n",
        "print(\"training samples: {}. validation samples: {}\".format(len(training_samples), len(validation_samples)))\n",
        "\n",
        "steps_per_epoch = int(len(training_samples) * (samples_per_data_item + stops_per_data_item) / batch_size)\n",
        "\n",
        "# pprint(training_samples[0])\n",
        "\n",
        "training_generator = ImageGenerator(\n",
        "    sample_list=training_samples,\n",
        "    image_shape=image_shape,\n",
        "    batch_size=batch_size,\n",
        "    samples_per_data_item=samples_per_data_item,\n",
        "    stops_per_data_item=stops_per_data_item)\n",
        "\n",
        "validation_generator = ImageGenerator(\n",
        "    sample_list=validation_samples,\n",
        "    image_shape=image_shape,\n",
        "    batch_size=batch_size,\n",
        "    samples_per_data_item=samples_per_data_item,\n",
        "    stops_per_data_item=stops_per_data_item)\n",
        "\n",
        "validation_data = validation_generator.generate_validation_samples()\n",
        "\n",
        "# print(\"validation data input and target shape: {}\".format(validation_data[0].shape))\n",
        "training_generator.get_random_training_pair()\n",
        "\n",
        "\n"
      ],
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training samples: 48000. validation samples: 12000\n",
            "sample_list: 48000\n",
            "sample_list: 12000\n",
            "training_input shape: (32, 28, 28, 1)\n",
            "training_input.png\n",
            "img shape: (28, 28, 1). img sum: 160.0\n",
            "img shape: (28, 28). img sum: 160.0\n",
            "img shape: (28, 28). img sum: 40800.0\n",
            "0.0\n",
            "training_target.png\n",
            "img shape: (28, 28, 1). img sum: 85.0\n",
            "img shape: (28, 28). img sum: 85.0\n",
            "img shape: (28, 28). img sum: 21675.0\n",
            "training_original.png\n",
            "img shape: (28, 28, 1). img sum: 81.0\n",
            "img shape: (28, 28). img sum: 81.0\n",
            "img shape: (28, 28). img sum: 20655.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk-zvNP9DGWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_location = F'/content/drive/My Drive/sc-model.hdf5'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dQKfsm7sEpV0",
        "outputId": "7b929247-5802-45fd-c54a-7eb5e9d1246f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "\n",
        "model = unet_model(input_size=(28, 28, 1))\n",
        "# model = keras.models.load_model(model_location)\n",
        "\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_location,\n",
        "    monitor='val_loss',\n",
        "    save_weights_only=False,\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir='./logs', update_freq='epoch')\n",
        "\n",
        "if True:\n",
        "    history = model.fit(\n",
        "        training_generator,\n",
        "        validation_data=validation_data,\n",
        "        verbose=1,\n",
        "        shuffle=True,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=20,\n",
        "        callbacks=[model_checkpoint_callback, tensorboard_callback])\n",
        "    #epochs=cfg.epochs,\n",
        "    #callbacks=callbacks)\n",
        "# model.save(\"sc-model.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_45\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_48 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_518 (Conv2D)             (None, 28, 28, 32)   320         input_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_519 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_518[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_95 (MaxPooling2D) (None, 14, 14, 32)   0           conv2d_519[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 14, 14, 32)   128         max_pooling2d_95[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_520 (Conv2D)             (None, 14, 14, 64)   18496       batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_521 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_520[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_96 (MaxPooling2D) (None, 7, 7, 64)     0           conv2d_521[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_95 (Dropout)            (None, 7, 7, 64)     0           max_pooling2d_96[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_522 (Conv2D)             (None, 7, 7, 128)    73856       dropout_95[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_523 (Conv2D)             (None, 7, 7, 128)    147584      conv2d_522[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_95 (UpSampling2D) (None, 14, 14, 128)  0           conv2d_523[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_120 (Concatenate)   (None, 14, 14, 192)  0           up_sampling2d_95[0][0]           \n",
            "                                                                 conv2d_521[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 14, 14, 192)  768         concatenate_120[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_524 (Conv2D)             (None, 14, 14, 64)   110656      batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_525 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_524[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_96 (Dropout)            (None, 14, 14, 64)   0           conv2d_525[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_96 (UpSampling2D) (None, 28, 28, 64)   0           dropout_96[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_121 (Concatenate)   (None, 28, 28, 96)   0           up_sampling2d_96[0][0]           \n",
            "                                                                 conv2d_519[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_526 (Conv2D)             (None, 28, 28, 32)   27680       concatenate_121[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_527 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_526[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_528 (Conv2D)             (None, 28, 28, 1)    33          conv2d_527[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_64 (Flatten)            (None, 25088)        0           conv2d_527[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_63 (Flatten)            (None, 784)          0           conv2d_528[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 1)            25089       flatten_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_122 (Concatenate)   (None, 785)          0           flatten_63[0][0]                 \n",
            "                                                                 dense_26[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 496,962\n",
            "Trainable params: 496,514\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "  12/3000 [..............................] - ETA: 5:33 - loss: 1.9897"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.111827). Check your callbacks.\n",
            "  % (hook_name, delta_t_median), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 526/3000 [====>.........................] - ETA: 48s - loss: 0.8262"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKxrjiG_eqBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"Loss\"\n",
        "if True:\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0IEPAcide5lS"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PBu4a18br7wL",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "def inference(model, input_image, directory, iterations, temp_start=2, temp_end=0.5, top_k=250):\n",
        "    create_image(input_image, \"{}/input.png\".format(directory))\n",
        "\n",
        "    temperatures = np.linspace(temp_end, temp_start, num=iterations)[::-1]\n",
        "    # pprint(temperatures)\n",
        "    \n",
        "    working_image = deepcopy(input_image)\n",
        "    working_images = []\n",
        "    num_added = 0\n",
        "    num_removed = 0\n",
        "    for i in range(iterations):\n",
        "        temp = temperatures[i]\n",
        "        predictions = model.predict(working_image)\n",
        "        if i % 50 == 0:\n",
        "          print(predictions[0][-1])\n",
        "        predictions = predictions.flatten()\n",
        "        # print(predictions.shape)\n",
        "        predictions = np.exp(predictions / temp)\n",
        "        predictions = predictions / np.sum(predictions)\n",
        "        # print(predictions[-1])\n",
        "        indices = np.arange(predictions.shape[0])\n",
        "\n",
        "        zipped = zip(predictions, indices)\n",
        "        zipped = list(reversed(sorted(zipped, key = lambda x : x[0])))\n",
        "        zipped = zipped[:top_k]\n",
        "        predictions, indices = zip(*zipped)\n",
        "        predictions = np.asarray(predictions)\n",
        "        predictions = predictions / np.sum(predictions)\n",
        "        indices = np.asarray(indices)\n",
        "\n",
        "        index = np.random.choice(indices, p=predictions)\n",
        "        working_image = working_image.flatten()\n",
        "        if index == predictions.shape[0]:\n",
        "            print(\"stopping\")\n",
        "            break\n",
        "        elif working_image[index] == 1:\n",
        "            num_removed += 1\n",
        "            working_image[index] = 0\n",
        "        elif working_image[index] == 0:\n",
        "            num_added += 1\n",
        "            working_image[index] = 1\n",
        "        else:\n",
        "            print(working_image[index])\n",
        "        working_image = np.reshape(working_image, [1, *image_shape])\n",
        "        if i % 50 == 0:\n",
        "            print(predictions[-1])\n",
        "            create_image(working_image, os.path.join(directory, \"working_{}.png\".format(i)))\n",
        "\n",
        "    print(working_image.shape)\n",
        "    print(\"num added: {}. num removed: {}\".format(num_added, num_removed))\n",
        "    img = create_image(working_image, os.path.join(directory, \"final.png\"))\n",
        "    return img, deepcopy(working_image)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJjq3kNqJCOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC6ZVFAFeqBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_images = []\n",
        "\n",
        "# model = keras.models.load_model(model_location)\n",
        "\n",
        "\n",
        "def generate_noise():\n",
        "    input_image = np.full((28, 28), 0)\n",
        "\n",
        "    # Random noise\n",
        "    # input_image = np.random.rand(28, 28)\n",
        "    # input_image[input_image >= 0.5] = 1\n",
        "    # input_image[input_image < 0.5] = 0\n",
        "\n",
        "    input_image = input_image.astype(np.float32)\n",
        "    input_image = np.expand_dims(input_image, 0)\n",
        "    input_image = np.expand_dims(input_image, -1)\n",
        "    return input_image\n",
        "\n",
        "sample_sqrt = 3\n",
        "for i in range(sample_sqrt**2):\n",
        "    directory = \"images_{}\".format(i)\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    # input_image = generate_noise()\n",
        "    input_image = np.expand_dims(np.expand_dims(images[i], 0), -1)\n",
        "\n",
        "    img, _ = inference(model, input_image, directory, 250, temp_start=0.99, temp_end=0.99, top_k=500)\n",
        "    generated_images.append(img)\n",
        "    \n",
        "final_im = Image.new('RGB', (28 * sample_sqrt, 28 * sample_sqrt))\n",
        "\n",
        "y_offset = 0\n",
        "for i in range(sample_sqrt):\n",
        "    x_offset = 0\n",
        "    new_im = Image.new('RGB', (28 * sample_sqrt, 28))\n",
        "    for j in range(sample_sqrt):\n",
        "        im = generated_images[(i * sample_sqrt) + j]\n",
        "        new_im.paste(im, (x_offset, 0))\n",
        "        x_offset += 28\n",
        "    final_im.paste(new_im, (0, y_offset))\n",
        "    y_offset += 28\n",
        "    \n",
        "final_im.save('final.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DF783hh7cg_P"
      },
      "source": [
        "## Train Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW-M3GAmeqBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterations = 500\n",
        " \n",
        "generated_samples = []\n",
        "for i in range(int(len(training_samples) / 2)):\n",
        "    directory = \"discriminator\"\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    input_image = generate_noise()\n",
        "\n",
        "    _, generated = inference(model, input_image, directory, iterations, temp_start=1, temp_end=1)\n",
        "    generated_samples.append(generated)\n",
        "\n",
        "print(len(generated_samples))\n",
        "original_gen_samples = deepcopy(generated_samples)\n",
        "generated_samples = np.asarray(generated_samples)\n",
        "print(generated_samples.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2tqKYqmJ3uJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_samples = np.random.rand(int(len(training_samples) / 2), *image_shape)\n",
        "random_samples[random_samples >= 0.5] = 1\n",
        "random_samples[random_samples < 0.5] = 0\n",
        "\n",
        "generated_samples = generated_samples.reshape(-1, *image_shape)\n",
        "images = training_samples\n",
        "images = np.expand_dims(images, axis=-1)\n",
        "\n",
        "discriminator_train_x = np.concatenate((generated_samples, random_samples, images), axis=0)\n",
        "print(generated_samples.shape)\n",
        "print(random_samples.shape)\n",
        "print(images.shape)\n",
        "discriminator_train_y = np.concatenate((np.full((generated_samples.shape[0], 1), 0), \n",
        "                                        np.full((random_samples.shape[0], 1), 0),\n",
        "                                        np.full((images.shape[0], 1), 1)), \n",
        "                                        axis=0)\n",
        "\n",
        "print(discriminator_train_x.shape)\n",
        "print(discriminator_train_y.shape)\n",
        "\n",
        "\n",
        "p = np.random.permutation(len(discriminator_train_x))\n",
        "discriminator_train_x, discriminator_train_y = discriminator_train_x[p], discriminator_train_y[p]\n",
        "print(discriminator_train_x.shape)\n",
        "print(discriminator_train_y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PVue6Y9M0Ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Flatten, Dense, Reshape\n",
        "\n",
        "def discriminator(input_size=(28, 28, 1), n_filters_start=16, growth_factor=2, num_layers=1):\n",
        "    inputs = Input(input_size)\n",
        "    droprate = 0.5\n",
        "    n_filters = n_filters_start\n",
        "    prev_layer = inputs\n",
        "    for _ in range(num_layers):\n",
        "        batch_norm = BatchNormalization()(prev_layer)\n",
        "        conv = Conv2D(n_filters, kernel_size=(3, 3), strides=(2,2), activation='relu', padding='same')(batch_norm)\n",
        "        drop_layer = Dropout(droprate)(conv)\n",
        "        prev_layer = drop_layer\n",
        "        n_filters *= growth_factor\n",
        "\n",
        "    flatten = Flatten()(prev_layer)\n",
        "    # reshape_layer = Reshape((-1, 512))(prev_layer)\n",
        "    validity = Dense(1, activation='sigmoid')(flatten)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=validity)\n",
        "    model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNM3mo1NJeub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator_model = discriminator(input_size=image_shape)\n",
        "model_location = F'/content/drive/My Drive/sc-discrim-model.hdf5'\n",
        "\n",
        "# model = keras.models.load_model(model_location)\n",
        "\n",
        "discrim_batch_size = 64\n",
        "\n",
        "steps_per_epoch = int(len(discriminator_train_x) * split / discrim_batch_size)  \n",
        "validation_steps = int(len(discriminator_train_x) * (1 - split) / discrim_batch_size)  \n",
        "\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_location,\n",
        "    monitor='val_loss',\n",
        "    save_weights_only=False,\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir='./logs', update_freq='epoch')\n",
        "\n",
        "if True:\n",
        "    discrim_history = discriminator_model.fit(\n",
        "        x=discriminator_train_x,\n",
        "        y=discriminator_train_y,\n",
        "        batch_size=discrim_batch_size,\n",
        "        validation_split=split,\n",
        "        verbose=1,\n",
        "        shuffle=True,\n",
        "        epochs=100,\n",
        "        callbacks=[model_checkpoint_callback, tensorboard_callback])\n",
        "    #epochs=cfg.epochs,\n",
        "    #callbacks=callbacks)\n",
        "# model.save(\"sc-model.hdf5\")\n",
        "if True:\n",
        "    plt.plot(discrim_history.history['loss'])\n",
        "    plt.plot(discrim_history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz7XvYS3pduE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference_with_discriminator(model, discrim_model, input_image, directory, iterations, temp_low=0.5, temp_high=2):\n",
        "    create_image(input_image, \"{}/input.png\".format(directory))\n",
        "\n",
        "    # pprint(temperatures)\n",
        "    \n",
        "    working_image = deepcopy(input_image)\n",
        "    consecutive = 0\n",
        "    for i in range(iterations):\n",
        "        discrim_predict = discrim_model.predict(working_image)[0]\n",
        "        if discrim_predict >= 0.95:\n",
        "            consecutive += 1\n",
        "            if consecutive >= 100:\n",
        "                break\n",
        "        else:\n",
        "            consecutive = 0\n",
        "\n",
        "        temp = temp_low + ((temp_high - temp_low) * (1 - discrim_predict))\n",
        "        \n",
        "        print(\"temp: {}\".format(temp))\n",
        "        predictions = model.predict(working_image)\n",
        "        predictions = predictions.flatten()\n",
        "        predictions = np.exp(predictions / temp)\n",
        "        predictions = predictions / np.sum(predictions)\n",
        "        # print(predictions)\n",
        "        indices = np.arange(predictions.shape[0])\n",
        "        index = np.random.choice(indices, p=predictions)\n",
        "        working_image = working_image.flatten()\n",
        "        if working_image[index] == 1:\n",
        "            working_image[index] = 0\n",
        "        elif working_image[index] == 0:\n",
        "            working_image[index] = 1\n",
        "        else:\n",
        "            print(working_image[index])\n",
        "        working_image = np.reshape(working_image, [1, *image_shape])\n",
        "        if i % 100 == 0:\n",
        "            create_image(working_image, os.path.join(directory, \"working_{}.png\".format(i)))\n",
        "\n",
        "    print(working_image.shape)\n",
        "    img = create_image(working_image, os.path.join(directory, \"final.png\"))\n",
        "    return img, deepcopy(working_image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NR7vdWxukd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_images = []\n",
        "\n",
        "sample_sqrt = 1\n",
        "for i in range(sample_sqrt**2):\n",
        "    directory = \"images_discrim_{}\".format(i)\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    # input_image = images[0]\n",
        "    # input_image = np.expand_dims(input_image, 0)\n",
        "\n",
        " \n",
        "    img, _ = inference_with_discriminator(model, discriminator_model, input_image, directory, 10000)\n",
        "    generated_images.append(img)\n",
        "    \n",
        "final_im = Image.new('RGB', (28 * sample_sqrt, 28 * sample_sqrt))\n",
        "\n",
        "y_offset = 0\n",
        "for i in range(sample_sqrt):\n",
        "    x_offset = 0\n",
        "    new_im = Image.new('RGB', (28 * sample_sqrt, 28))\n",
        "    for j in range(sample_sqrt):\n",
        "        im = generated_images[(i * sample_sqrt) + j]\n",
        "        new_im.paste(im, (x_offset, 0))\n",
        "        x_offset += 28\n",
        "    final_im.paste(new_im, (0, y_offset))\n",
        "    y_offset += 28\n",
        "    \n",
        "final_im.save('final_with_discrim.png')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}