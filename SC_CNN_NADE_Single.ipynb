{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SC_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waynchi/SC-Net/blob/master/SC_CNN_NADE_Single.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U22qZkbsfEyI",
        "colab_type": "code",
        "outputId": "d95df3c9-4ea7-4037-8dd8-697c43c53a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install mnist\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mnist in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mnist) (1.18.4)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45bLorRNFfdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LsQqrsgeqA1",
        "colab_type": "code",
        "outputId": "a83c717d-7bc1-4ae2-b03e-3d402646a30d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.is_gpu_available()\n"
      ],
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 362
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VxF9dG1KU6Mf"
      },
      "source": [
        "# What about a GAN + Self correcting U-Net ? That would make for a cool architecture\n",
        "# Following CGAN -> adding a 1-hot vector encoding of the label to the training data\n",
        "# Simulated Annealing?\n",
        "# Generator -> VAE -> Discriminator?\n",
        "# What about feeding in a dicriminator's confidence level as a temperature during the autoregressive? Inverse confidence?\n",
        "# What about a 3 dimensional GAN?\n",
        "\n",
        "# Umut Notes\n",
        "- Add a stop condition to the softmax\n",
        "    - Tried both 2 outputs and just an extra variable to the softmax\n",
        "    - 2 outputs fails due to it having too much weight to the loss and the loss fluctuates like crazy\n",
        "    - extra variable fails as the probability is still small even for an original image. Not sure why. Maybe because each time wew generate we use a new random which causes the dataset to be imbalanced?\n",
        "- 2 steps process (pick note and then choose how much through binary cross entropy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OeM4sX2NNYT0",
        "outputId": "aebd0a0e-13dc-499c-8838-09607e8fecb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import mnist\n",
        "import scipy.misc\n",
        "from PIL import Image\n",
        "from pprint import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "\n",
        "def create_image(image, name, image_shape=(28, 28), is_grayscale=True):\n",
        "    img_arr = deepcopy(image.reshape(image_shape)).astype(np.float32)\n",
        "    img_arr = img_arr * 255.0\n",
        "\n",
        "    img = Image.fromarray(img_arr.astype(np.uint8), 'L')\n",
        "    # pprint(img_arr)\n",
        "    # print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "    img.save(name)\n",
        "    return img\n",
        "\n",
        "images = mnist.train_images()\n",
        "num_samples = 1\n",
        "# np.random.shuffle(images)\n",
        "images = images[:num_samples, :, :]\n",
        "\n",
        "is_grayscale = True\n",
        "\n",
        "if not is_grayscale:\n",
        "    # For black and white\n",
        "    images[images > 0] = 1\n",
        "    # images = images / 255.0\n",
        "else:\n",
        "    # For grayscale\n",
        "    images = images / 255.0\n",
        "\n",
        "# pprint(images)\n",
        "print(images.shape)\n",
        "\n",
        "# labels = mnist.train_labels()\n",
        "# n_labels = np.max(labels) + 1\n",
        "# labels = np.eye(n_labels)[labels]\n",
        "# print(labels.shape)\n",
        "\n",
        "create_image(images[0], 'my.png', is_grayscale=is_grayscale)\n",
        "\n",
        "image_shape = np.expand_dims(images[0], axis=-1).shape \n",
        "# print(image_shape)"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OlmEDomwi9dZ",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Flatten, Dense, Softmax\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "def built_in_softmax_kl_loss(target, output):\n",
        "    target = K.flatten(target)\n",
        "    output = K.flatten(output)\n",
        "    \n",
        "    target = target / K.sum(target)\n",
        "    output = K.softmax(output)\n",
        "    return keras.losses.kullback_leibler_divergence(target, output)\n",
        "\n",
        "keras.losses.built_in_softmax_kl_loss = built_in_softmax_kl_loss\n",
        " \n",
        "def unet_model(input_size=(28, 28, 1), n_filters_start=32, growth_factor=2,\n",
        "               upconv=False, is_grayscale=True):\n",
        "    droprate=0.5\n",
        "    n_filters = n_filters_start\n",
        "    inputs = Input(input_size)\n",
        "    conv_first = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv_first = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_first)\n",
        "    pool_first = MaxPooling2D(pool_size=(2, 2))(conv_first)\n",
        "\n",
        "    prev_pool = pool_first\n",
        "    hidden_layers = []\n",
        "    for _ in range(1):\n",
        "        n_filters *= growth_factor\n",
        "        pool = BatchNormalization()(prev_pool)\n",
        "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool)\n",
        "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv)\n",
        "        pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
        "        pool = Dropout(droprate)(pool)\n",
        "        prev_pool = pool\n",
        "        hidden_layers.append(conv)\n",
        " \n",
        "    n_filters *= growth_factor\n",
        "    conv_mid = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(prev_pool)\n",
        "    conv_mid = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_mid)\n",
        " \n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up_first = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv_mid), hidden_layers[-1]])\n",
        "    else:\n",
        "        up_first = concatenate([UpSampling2D(size=(2, 2))(conv_mid), hidden_layers[-1]])\n",
        "    up_first = BatchNormalization()(up_first)\n",
        "    conv_mid_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up_first)\n",
        "    conv_mid_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_mid_2)\n",
        "    conv_mid_2 = Dropout(droprate)(conv_mid_2)\n",
        "\n",
        "    prev_conv = conv_mid_2\n",
        "    for i in range(0):\n",
        "        n_filters //= growth_factor\n",
        "        if upconv:\n",
        "            up = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(prev_conv), hidden_layers[-i-2]])\n",
        "        else:\n",
        "            up = concatenate([UpSampling2D(size=(2, 2))(prev_conv), hidden_layers[-i-2]])\n",
        "        up = BatchNormalization()(up)\n",
        "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up)\n",
        "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv)\n",
        "        conv = Dropout(droprate)(conv)\n",
        "        prev_conv = conv\n",
        " \n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up_last = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv_mid_2), conv_first])\n",
        "    else:\n",
        "        up_last = concatenate([UpSampling2D(size=(2, 2))(conv_mid_2), conv_first])\n",
        "    conv_last = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up_last)\n",
        "    conv_last = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_last)\n",
        " \n",
        "    softmax_out = Conv2D(1, 1, activation='linear')(conv_last)\n",
        "    # softmax_out = Flatten()(conv_out)\n",
        "\n",
        "    # flatten = Flatten()(conv_last)\n",
        "    # dense = Dense(1, activation='linear')(flatten)\n",
        "\n",
        "    # softmax_out = concatenate([conv_out, dense])\n",
        "\n",
        "    if is_grayscale:\n",
        "        sigmoid_out = Conv2D(1, 1, activation='sigmoid')(conv_last)\n",
        "        model = Model(inputs=inputs, outputs=[softmax_out, sigmoid_out])\n",
        "        model.compile(optimizer=Adam(), loss=[built_in_softmax_kl_loss, 'binary_crossentropy'], metrics=['accuracy'])\n",
        "    else:\n",
        "        model = Model(inputs=inputs, outputs=softmax_out)\n",
        "        model.compile(optimizer=Adam(), loss=built_in_softmax_kl_loss)\n",
        "\n",
        "    # model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rSjQr52iQzlu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "e2bbcf3a-4b5b-4c7c-9d33-4771ad55de9e"
      },
      "source": [
        "model = unet_model(input_size=image_shape, is_grayscale=is_grayscale)"
      ],
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_46\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_46 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_502 (Conv2D)             (None, 28, 28, 32)   320         input_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_503 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_502[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_91 (MaxPooling2D) (None, 14, 14, 32)   0           conv2d_503[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 14, 14, 32)   128         max_pooling2d_91[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_504 (Conv2D)             (None, 14, 14, 64)   18496       batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_505 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_504[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_92 (MaxPooling2D) (None, 7, 7, 64)     0           conv2d_505[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_91 (Dropout)            (None, 7, 7, 64)     0           max_pooling2d_92[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_506 (Conv2D)             (None, 7, 7, 128)    73856       dropout_91[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_507 (Conv2D)             (None, 7, 7, 128)    147584      conv2d_506[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_91 (UpSampling2D) (None, 14, 14, 128)  0           conv2d_507[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_91 (Concatenate)    (None, 14, 14, 192)  0           up_sampling2d_91[0][0]           \n",
            "                                                                 conv2d_505[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 14, 14, 192)  768         concatenate_91[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_508 (Conv2D)             (None, 14, 14, 64)   110656      batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_509 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_508[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_92 (Dropout)            (None, 14, 14, 64)   0           conv2d_509[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_92 (UpSampling2D) (None, 28, 28, 64)   0           dropout_92[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_92 (Concatenate)    (None, 28, 28, 96)   0           up_sampling2d_92[0][0]           \n",
            "                                                                 conv2d_503[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_510 (Conv2D)             (None, 28, 28, 32)   27680       concatenate_92[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_511 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_510[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_512 (Conv2D)             (None, 28, 28, 1)    33          conv2d_511[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_513 (Conv2D)             (None, 28, 28, 1)    33          conv2d_511[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 471,906\n",
            "Trainable params: 471,458\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsFM5XMYeqBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBEdqEBxFqNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# discriminator_model = discriminator(input_size=image_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SVUVU8Kt_aCm",
        "colab": {}
      },
      "source": [
        "from copy import deepcopy\n",
        "import math\n",
        "import itertools\n",
        "def mask_image(image, is_grayscale=True):\n",
        "    image = deepcopy(image)\n",
        "    sampling_percentage = np.random.uniform(0, 100)\n",
        "    non_zero = np.nonzero(image)\n",
        "    mask1 = np.full(len(non_zero[0]), False)\n",
        "    mask1[:math.floor(len(non_zero[0]) * (sampling_percentage/100))] = True\n",
        "    np.random.shuffle(mask1)\n",
        "    # pprint(mask1)\n",
        "    r1 = list(itertools.compress(non_zero[0], mask1))\n",
        "    c1 = list(itertools.compress(non_zero[1], mask1))\n",
        "    output_image = deepcopy(image)\n",
        "    output_image[r1,c1] = 0\n",
        "    return output_image\n",
        "\n",
        "def mask_image_with_noise(image, is_grayscale=True):\n",
        "    image = deepcopy(image)\n",
        "    sampling_percentage_mask = np.random.uniform(0, 100)\n",
        "    sampling_percentage_noise = np.random.uniform(0, 20)\n",
        "    non_zero = np.nonzero(image)\n",
        "    zeroes = np.nonzero(image == 0)\n",
        "    mask = np.full(len(non_zero[0]), False)\n",
        "    noise = np.full(len(zeroes[0]), False) \n",
        "    amount_to_mask = math.floor(len(non_zero[0]) * (sampling_percentage_mask/100))\n",
        "    mask[:amount_to_mask] = True\n",
        "    amount_to_mask_2 = math.floor(len(zeroes[0]) * (sampling_percentage_noise/100))\n",
        "    noise[:amount_to_mask_2] = True\n",
        "    np.random.shuffle(mask)\n",
        "    np.random.shuffle(noise)\n",
        "    # pprint(mask1)\n",
        "    output_image = deepcopy(image)\n",
        "    r1 = list(itertools.compress(non_zero[0], mask))\n",
        "    c1 = list(itertools.compress(non_zero[1], mask))\n",
        "    r2 = list(itertools.compress(zeroes[0], noise))\n",
        "    c2 = list(itertools.compress(zeroes[1], noise))\n",
        "    output_image[r1,c1] = 0\n",
        "    output_image[r2,c2] = 1\n",
        "    return output_image\n",
        "\n",
        "class ImageGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, sample_list, image_shape, batch_size, samples_per_data_item, stops_per_data_item, is_grayscale=True, seed=None):\n",
        "        print(\"sample_list: {}\".format(len(sample_list)))\n",
        "        self.sample_list = sample_list\n",
        "        self.image_shape = image_shape\n",
        "        self.batch_size = batch_size\n",
        "        self.samples_per_data_item = samples_per_data_item\n",
        "        self.stops_per_data_item = stops_per_data_item\n",
        "        self.is_grayscale = is_grayscale\n",
        "        # self.training_input = []\n",
        "        # self.training_target = []\n",
        "        # self.training_original = []\n",
        "        self.sample_index = 0\n",
        "        self.seed = seed\n",
        "        # if self.seed is not None:\n",
        "        #     np.random.seed(self.seed)\n",
        "\n",
        "    def generate_training_pairs(self):\n",
        "        '''\n",
        "        Generates Training Pairs till @training_input / @training_target have @batch_size files.\n",
        "        '''\n",
        "        training_input = []\n",
        "        training_original = []\n",
        "        training_target = []\n",
        "        while len(training_input) < self.batch_size:\n",
        "            original_image = deepcopy(self.sample_list[self.sample_index])\n",
        "            original_image = original_image.reshape(self.image_shape)\n",
        "            binary_image = deepcopy(original_image)\n",
        "            binary_image[binary_image > 0] = 1\n",
        "            self.sample_index = (self.sample_index + 1) % len(self.sample_list)\n",
        "            # print(\"sample_list length: {}. sample_index: {}\".format(\n",
        "            #     len(self.sample_list), self.sample_index))\n",
        "            try:\n",
        "                # augment by adding and removing random values in the array\n",
        "\n",
        "                # Add random values\n",
        "                for _ in range(self.samples_per_data_item):\n",
        "                    input_image = mask_image(binary_image, is_grayscale=self.is_grayscale)\n",
        "\n",
        "                    input_image = input_image.astype(np.float32)\n",
        "                    original_image = original_image.astype(np.float32)\n",
        "\n",
        "                    xor_target = np.logical_xor(input_image, binary_image)\n",
        "                    xor_target = xor_target.astype(np.float32)\n",
        "                    # xor_target = xor_target.flatten()\n",
        "                    # xor_target = np.append(xor_target, 0.0)\n",
        "                    \n",
        "                    training_input.append(deepcopy(input_image))\n",
        "                    training_original.append(deepcopy(original_image))\n",
        "                    training_target.append(deepcopy(xor_target))\n",
        "\n",
        "                # Add original\n",
        "                for _ in range(self.stops_per_data_item):\n",
        "                    training_input.append(deepcopy(original_image.astype(np.float32)))\n",
        "                    training_original.append(deepcopy(original_image.astype(np.float32)))\n",
        "                    xor_target = np.full(np.prod(self.image_shape), 0.0, dtype=np.float32)\n",
        "                    xor_target = np.append(xor_target, 1.0)\n",
        "                    training_target.append(deepcopy(xor_target))\n",
        "\n",
        "            except Exception as e:\n",
        "                print('Error generating input and target pair')\n",
        "                traceback.print_exc()\n",
        "        return np.asarray(training_input), np.asarray(training_target), np.asarray(training_original)\n",
        "\n",
        "    def save_image(self, img_arr, img_name):\n",
        "        # img_arr = img_arr.reshape(self.image_shape)\n",
        "        print(img_name)\n",
        "        print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "        img_arr = img_arr[:, :, 0]\n",
        "        print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "        #pprint(img_arr)\n",
        "        img_arr = img_arr * 255\n",
        "        #pprint(img_arr)\n",
        "        print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "        img = Image.fromarray(img_arr.astype(np.uint8), 'L')\n",
        "        img.save(img_name)\n",
        "\n",
        "    def get_random_training_pair(self):\n",
        "        import random\n",
        "        training_input, training_target, training_original = self.generate_training_pairs()\n",
        "        print(\"training_input shape: {}\".format(training_input.shape))\n",
        "        index = random.randrange(0, len(training_input))\n",
        "        self.save_image(deepcopy(training_input[index]), 'training_input.png')\n",
        "        # training_image = training_target[index][:np.prod(self.image_shape)]\n",
        "        # print(training_target[index][-1])\n",
        "        self.save_image(deepcopy(training_target[index]), 'training_target.png')\n",
        "        self.save_image(deepcopy(training_original[index]), 'training_original.png')\n",
        "\n",
        "    def generate_validation_samples(self):\n",
        "        old_batch_size = self.batch_size\n",
        "        self.batch_size = len(self.sample_list) * (self.samples_per_data_item + self.stops_per_data_item)\n",
        "        training_input, training_target, training_original = self.generate_training_pairs()\n",
        "        # training_input = np.asarray(self.training_input[:self.batch_size])\n",
        "        # training_target = np.asarray(self.training_target[:self.batch_size])\n",
        "        self.batch_size = old_batch_size\n",
        "        if self.is_grayscale:\n",
        "            return training_input, [training_target, training_original]\n",
        "        else:\n",
        "            return training_input, training_target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''Generates 1 batch of data'''\n",
        "        training_input, training_target, training_original = self.generate_training_pairs()\n",
        "        # training_input = np.asarray(self.training_input[:self.batch_size])\n",
        "        # training_target = np.asarray(self.training_target[:self.batch_size])\n",
        "        # self.training_input = self.training_input[self.batch_size:]\n",
        "        # self.training_target = self.training_target[self.batch_size:]\n",
        "        # print(\"training input sum: {}. target sum: {}\".format(training_input.sum(), training_target.sum()))\n",
        "        if is_grayscale:\n",
        "            return np.asarray(training_input), [np.asarray(training_target), np.asarray(training_original)]\n",
        "        else:\n",
        "            return np.asarray(training_input), np.asarray(training_target)\n",
        "\n",
        "    def __len__(self):\n",
        "        '''Number of batches / epoch'''\n",
        "        # print(\"sample_list: {}. samples_per_data_item: {}, batch size: {}\".\n",
        "        #       format(len(self.sample_list), self.samples_per_data_item,\n",
        "        #              self.batch_size))\n",
        "        samples_to_generate = int(\n",
        "            (len(self.sample_list) * (self.samples_per_data_item + self.stops_per_data_item)) /\n",
        "            self.batch_size)\n",
        "        # print(\"samples to generate: {}\".format(samples_to_generate))\n",
        "        return samples_to_generate\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        pass\n",
        "        # np.random.seed(7)\n",
        "    #    if self.seed is not None:\n",
        "    #        np.random.seed(self.seed)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1zwLYew1a-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Config\n",
        "batch_size = 128\n",
        "samples_per_data_item = 128\n",
        "stops_per_data_item = 0\n",
        "split = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ngo7o_rw2TsK",
        "outputId": "a6086f16-96da-4b64-cf5f-2d19b70d637d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "\n",
        "training_samples = images[:int(len(images) * split)]\n",
        "validation_samples = images[int(len(images) * split):]\n",
        "\n",
        "print(\"training samples: {}. validation samples: {}\".format(len(training_samples), len(validation_samples)))\n",
        "\n",
        "steps_per_epoch = int(len(training_samples) * (samples_per_data_item + stops_per_data_item) / batch_size)\n",
        "print(\"steps per epoch: {}\".format(steps_per_epoch))\n",
        "\n",
        "# pprint(training_samples[0])\n",
        "\n",
        "training_generator = ImageGenerator(\n",
        "    sample_list=training_samples,\n",
        "    image_shape=image_shape,\n",
        "    batch_size=batch_size,\n",
        "    samples_per_data_item=samples_per_data_item,\n",
        "    stops_per_data_item=stops_per_data_item,\n",
        "    is_grayscale=is_grayscale)\n",
        "\n",
        "validation_generator = ImageGenerator(\n",
        "    sample_list=validation_samples,\n",
        "    image_shape=image_shape,\n",
        "    batch_size=batch_size,\n",
        "    samples_per_data_item=samples_per_data_item,\n",
        "    stops_per_data_item=stops_per_data_item,\n",
        "    is_grayscale=is_grayscale)\n",
        "\n",
        "validation_data = validation_generator.generate_validation_samples()\n",
        "\n",
        "# print(\"validation data input and target shape: {}\".format(validation_data[0].shape))\n",
        "training_generator.get_random_training_pair()\n",
        "\n",
        "\n"
      ],
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training samples: 1. validation samples: 0\n",
            "steps per epoch: 1\n",
            "sample_list: 1\n",
            "sample_list: 0\n",
            "training_input shape: (128, 28, 28, 1)\n",
            "training_input.png\n",
            "img shape: (28, 28, 1). img sum: 150.0\n",
            "img shape: (28, 28). img sum: 150.0\n",
            "img shape: (28, 28). img sum: 38250.0\n",
            "training_target.png\n",
            "img shape: (28, 28, 1). img sum: 16.0\n",
            "img shape: (28, 28). img sum: 16.0\n",
            "img shape: (28, 28). img sum: 4080.0\n",
            "training_original.png\n",
            "img shape: (28, 28, 1). img sum: 107.94117736816406\n",
            "img shape: (28, 28). img sum: 107.94117736816406\n",
            "img shape: (28, 28). img sum: 27525.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk-zvNP9DGWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_location = F'/content/drive/My Drive/sc-model.hdf5'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dQKfsm7sEpV0",
        "outputId": "dca117b4-05d7-4ef7-c608-33e229bb59fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "\n",
        "model = unet_model(input_size=image_shape, is_grayscale=is_grayscale)\n",
        "# model = keras.models.load_model(model_location)\n",
        "\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_location,\n",
        "    monitor='val_loss',\n",
        "    save_weights_only=False,\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir='./logs', update_freq='epoch')\n",
        "\n",
        "if True:\n",
        "    history = model.fit(\n",
        "        training_generator,\n",
        "        # validation_data=validation_data,\n",
        "        verbose=1,\n",
        "        shuffle=True,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=300,\n",
        "        callbacks=[model_checkpoint_callback])#, tensorboard_callback])\n",
        "    #epochs=cfg.epochs,\n",
        "    #callbacks=callbacks)\n",
        "# model.save(\"sc-model.hdf5\")"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_47\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_47 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_514 (Conv2D)             (None, 28, 28, 32)   320         input_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_515 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_514[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_93 (MaxPooling2D) (None, 14, 14, 32)   0           conv2d_515[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 14, 14, 32)   128         max_pooling2d_93[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_516 (Conv2D)             (None, 14, 14, 64)   18496       batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_517 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_516[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_94 (MaxPooling2D) (None, 7, 7, 64)     0           conv2d_517[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_93 (Dropout)            (None, 7, 7, 64)     0           max_pooling2d_94[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_518 (Conv2D)             (None, 7, 7, 128)    73856       dropout_93[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_519 (Conv2D)             (None, 7, 7, 128)    147584      conv2d_518[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_93 (UpSampling2D) (None, 14, 14, 128)  0           conv2d_519[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_93 (Concatenate)    (None, 14, 14, 192)  0           up_sampling2d_93[0][0]           \n",
            "                                                                 conv2d_517[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 14, 14, 192)  768         concatenate_93[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_520 (Conv2D)             (None, 14, 14, 64)   110656      batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_521 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_520[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_94 (Dropout)            (None, 14, 14, 64)   0           conv2d_521[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_94 (UpSampling2D) (None, 28, 28, 64)   0           dropout_94[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_94 (Concatenate)    (None, 28, 28, 96)   0           up_sampling2d_94[0][0]           \n",
            "                                                                 conv2d_515[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_522 (Conv2D)             (None, 28, 28, 32)   27680       concatenate_94[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_523 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_522[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_524 (Conv2D)             (None, 28, 28, 1)    33          conv2d_523[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_525 (Conv2D)             (None, 28, 28, 1)    33          conv2d_523[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 471,906\n",
            "Trainable params: 471,458\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/300\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 3.3132 - conv2d_524_loss: 2.5477 - conv2d_525_loss: 0.7656 - conv2d_524_accuracy: 0.5642 - conv2d_525_accuracy: 0.2603\n",
            "Epoch 2/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.5686 - conv2d_524_loss: 1.9372 - conv2d_525_loss: 0.6314 - conv2d_524_accuracy: 0.6246 - conv2d_525_accuracy: 0.6671\n",
            "Epoch 3/300\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.3205 - conv2d_524_loss: 1.7687 - conv2d_525_loss: 0.5518 - conv2d_524_accuracy: 0.3708 - conv2d_525_accuracy: 0.7764\n",
            "Epoch 4/300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 97ms/step - loss: 2.0177 - conv2d_524_loss: 1.4614 - conv2d_525_loss: 0.5564 - conv2d_524_accuracy: 0.2013 - conv2d_525_accuracy: 0.7872\n",
            "Epoch 5/300\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.9981 - conv2d_524_loss: 1.4966 - conv2d_525_loss: 0.5015 - conv2d_524_accuracy: 0.1464 - conv2d_525_accuracy: 0.7881\n",
            "Epoch 6/300\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.7743 - conv2d_524_loss: 1.3082 - conv2d_525_loss: 0.4661 - conv2d_524_accuracy: 0.1845 - conv2d_525_accuracy: 0.7882\n",
            "Epoch 7/300\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.7531 - conv2d_524_loss: 1.3423 - conv2d_525_loss: 0.4108 - conv2d_524_accuracy: 0.2422 - conv2d_525_accuracy: 0.7883\n",
            "Epoch 8/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.6238 - conv2d_524_loss: 1.2350 - conv2d_525_loss: 0.3888 - conv2d_524_accuracy: 0.2834 - conv2d_525_accuracy: 0.7883\n",
            "Epoch 9/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.5678 - conv2d_524_loss: 1.2107 - conv2d_525_loss: 0.3571 - conv2d_524_accuracy: 0.2587 - conv2d_525_accuracy: 0.7883\n",
            "Epoch 10/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.4215 - conv2d_524_loss: 1.0932 - conv2d_525_loss: 0.3283 - conv2d_524_accuracy: 0.2144 - conv2d_525_accuracy: 0.7882\n",
            "Epoch 11/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.3796 - conv2d_524_loss: 1.0873 - conv2d_525_loss: 0.2923 - conv2d_524_accuracy: 0.1842 - conv2d_525_accuracy: 0.7882\n",
            "Epoch 12/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.2715 - conv2d_524_loss: 1.0074 - conv2d_525_loss: 0.2641 - conv2d_524_accuracy: 0.1393 - conv2d_525_accuracy: 0.7882\n",
            "Epoch 13/300\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.1990 - conv2d_524_loss: 0.9589 - conv2d_525_loss: 0.2401 - conv2d_524_accuracy: 0.1074 - conv2d_525_accuracy: 0.7881\n",
            "Epoch 14/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.1549 - conv2d_524_loss: 0.9315 - conv2d_525_loss: 0.2234 - conv2d_524_accuracy: 0.0927 - conv2d_525_accuracy: 0.7877\n",
            "Epoch 15/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.0968 - conv2d_524_loss: 0.8881 - conv2d_525_loss: 0.2087 - conv2d_524_accuracy: 0.0923 - conv2d_525_accuracy: 0.7865\n",
            "Epoch 16/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.0479 - conv2d_524_loss: 0.8488 - conv2d_525_loss: 0.1992 - conv2d_524_accuracy: 0.0922 - conv2d_525_accuracy: 0.7848\n",
            "Epoch 17/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.0769 - conv2d_524_loss: 0.8836 - conv2d_525_loss: 0.1933 - conv2d_524_accuracy: 0.0917 - conv2d_525_accuracy: 0.7825\n",
            "Epoch 18/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.9514 - conv2d_524_loss: 0.7569 - conv2d_525_loss: 0.1945 - conv2d_524_accuracy: 0.0825 - conv2d_525_accuracy: 0.7795\n",
            "Epoch 19/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 1.0092 - conv2d_524_loss: 0.8324 - conv2d_525_loss: 0.1768 - conv2d_524_accuracy: 0.0838 - conv2d_525_accuracy: 0.7791\n",
            "Epoch 20/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.9518 - conv2d_524_loss: 0.7807 - conv2d_525_loss: 0.1711 - conv2d_524_accuracy: 0.0818 - conv2d_525_accuracy: 0.7763\n",
            "Epoch 21/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.9309 - conv2d_524_loss: 0.7644 - conv2d_525_loss: 0.1665 - conv2d_524_accuracy: 0.0858 - conv2d_525_accuracy: 0.7759\n",
            "Epoch 22/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.9117 - conv2d_524_loss: 0.7465 - conv2d_525_loss: 0.1652 - conv2d_524_accuracy: 0.0838 - conv2d_525_accuracy: 0.7751\n",
            "Epoch 23/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.9027 - conv2d_524_loss: 0.7346 - conv2d_525_loss: 0.1681 - conv2d_524_accuracy: 0.0871 - conv2d_525_accuracy: 0.7723\n",
            "Epoch 24/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.8643 - conv2d_524_loss: 0.6962 - conv2d_525_loss: 0.1681 - conv2d_524_accuracy: 0.0867 - conv2d_525_accuracy: 0.7719\n",
            "Epoch 25/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.8900 - conv2d_524_loss: 0.7304 - conv2d_525_loss: 0.1595 - conv2d_524_accuracy: 0.0893 - conv2d_525_accuracy: 0.7762\n",
            "Epoch 26/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.8432 - conv2d_524_loss: 0.6906 - conv2d_525_loss: 0.1526 - conv2d_524_accuracy: 0.0900 - conv2d_525_accuracy: 0.7788\n",
            "Epoch 27/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.8229 - conv2d_524_loss: 0.6752 - conv2d_525_loss: 0.1477 - conv2d_524_accuracy: 0.0943 - conv2d_525_accuracy: 0.7801\n",
            "Epoch 28/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.8633 - conv2d_524_loss: 0.7179 - conv2d_525_loss: 0.1454 - conv2d_524_accuracy: 0.0915 - conv2d_525_accuracy: 0.7813\n",
            "Epoch 29/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.8320 - conv2d_524_loss: 0.6848 - conv2d_525_loss: 0.1472 - conv2d_524_accuracy: 0.0955 - conv2d_525_accuracy: 0.7806\n",
            "Epoch 30/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.7913 - conv2d_524_loss: 0.6472 - conv2d_525_loss: 0.1441 - conv2d_524_accuracy: 0.0853 - conv2d_525_accuracy: 0.7833\n",
            "Epoch 31/300\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.8361 - conv2d_524_loss: 0.6937 - conv2d_525_loss: 0.1424 - conv2d_524_accuracy: 0.0881 - conv2d_525_accuracy: 0.7827\n",
            "Epoch 32/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.8110 - conv2d_524_loss: 0.6732 - conv2d_525_loss: 0.1378 - conv2d_524_accuracy: 0.0861 - conv2d_525_accuracy: 0.7850\n",
            "Epoch 33/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.7613 - conv2d_524_loss: 0.6224 - conv2d_525_loss: 0.1389 - conv2d_524_accuracy: 0.0873 - conv2d_525_accuracy: 0.7841\n",
            "Epoch 34/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.7685 - conv2d_524_loss: 0.6338 - conv2d_525_loss: 0.1348 - conv2d_524_accuracy: 0.0861 - conv2d_525_accuracy: 0.7849\n",
            "Epoch 35/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.7375 - conv2d_524_loss: 0.6034 - conv2d_525_loss: 0.1341 - conv2d_524_accuracy: 0.0828 - conv2d_525_accuracy: 0.7845\n",
            "Epoch 36/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.7366 - conv2d_524_loss: 0.6019 - conv2d_525_loss: 0.1347 - conv2d_524_accuracy: 0.0789 - conv2d_525_accuracy: 0.7836\n",
            "Epoch 37/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.7900 - conv2d_524_loss: 0.6604 - conv2d_525_loss: 0.1297 - conv2d_524_accuracy: 0.0844 - conv2d_525_accuracy: 0.7847\n",
            "Epoch 38/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.7347 - conv2d_524_loss: 0.6033 - conv2d_525_loss: 0.1314 - conv2d_524_accuracy: 0.0826 - conv2d_525_accuracy: 0.7851\n",
            "Epoch 39/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.7659 - conv2d_524_loss: 0.6379 - conv2d_525_loss: 0.1280 - conv2d_524_accuracy: 0.0794 - conv2d_525_accuracy: 0.7860\n",
            "Epoch 40/300\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.7098 - conv2d_524_loss: 0.5830 - conv2d_525_loss: 0.1268 - conv2d_524_accuracy: 0.0709 - conv2d_525_accuracy: 0.7858\n",
            "Epoch 41/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.7442 - conv2d_524_loss: 0.6189 - conv2d_525_loss: 0.1253 - conv2d_524_accuracy: 0.0717 - conv2d_525_accuracy: 0.7850\n",
            "Epoch 42/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.7226 - conv2d_524_loss: 0.6015 - conv2d_525_loss: 0.1211 - conv2d_524_accuracy: 0.0699 - conv2d_525_accuracy: 0.7856\n",
            "Epoch 43/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.6745 - conv2d_524_loss: 0.5520 - conv2d_525_loss: 0.1225 - conv2d_524_accuracy: 0.0723 - conv2d_525_accuracy: 0.7853\n",
            "Epoch 44/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.7018 - conv2d_524_loss: 0.5815 - conv2d_525_loss: 0.1203 - conv2d_524_accuracy: 0.0700 - conv2d_525_accuracy: 0.7868\n",
            "Epoch 45/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.6255 - conv2d_524_loss: 0.5050 - conv2d_525_loss: 0.1205 - conv2d_524_accuracy: 0.0722 - conv2d_525_accuracy: 0.7862\n",
            "Epoch 46/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.6405 - conv2d_524_loss: 0.5225 - conv2d_525_loss: 0.1180 - conv2d_524_accuracy: 0.0731 - conv2d_525_accuracy: 0.7862\n",
            "Epoch 47/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.5962 - conv2d_524_loss: 0.4793 - conv2d_525_loss: 0.1169 - conv2d_524_accuracy: 0.0798 - conv2d_525_accuracy: 0.7864\n",
            "Epoch 48/300\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.5799 - conv2d_524_loss: 0.4630 - conv2d_525_loss: 0.1170 - conv2d_524_accuracy: 0.0791 - conv2d_525_accuracy: 0.7865\n",
            "Epoch 49/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.6071 - conv2d_524_loss: 0.4945 - conv2d_525_loss: 0.1126 - conv2d_524_accuracy: 0.0803 - conv2d_525_accuracy: 0.7872\n",
            "Epoch 50/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.5651 - conv2d_524_loss: 0.4518 - conv2d_525_loss: 0.1133 - conv2d_524_accuracy: 0.0758 - conv2d_525_accuracy: 0.7866\n",
            "Epoch 51/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.5099 - conv2d_524_loss: 0.3949 - conv2d_525_loss: 0.1151 - conv2d_524_accuracy: 0.0772 - conv2d_525_accuracy: 0.7863\n",
            "Epoch 52/300\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.5258 - conv2d_524_loss: 0.4101 - conv2d_525_loss: 0.1158 - conv2d_524_accuracy: 0.0815 - conv2d_525_accuracy: 0.7865\n",
            "Epoch 53/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.4756 - conv2d_524_loss: 0.3625 - conv2d_525_loss: 0.1131 - conv2d_524_accuracy: 0.0817 - conv2d_525_accuracy: 0.7867\n",
            "Epoch 54/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.4966 - conv2d_524_loss: 0.3864 - conv2d_525_loss: 0.1102 - conv2d_524_accuracy: 0.0821 - conv2d_525_accuracy: 0.7870\n",
            "Epoch 55/300\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.4525 - conv2d_524_loss: 0.3446 - conv2d_525_loss: 0.1079 - conv2d_524_accuracy: 0.0813 - conv2d_525_accuracy: 0.7871\n",
            "Epoch 56/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.4421 - conv2d_524_loss: 0.3332 - conv2d_525_loss: 0.1089 - conv2d_524_accuracy: 0.0822 - conv2d_525_accuracy: 0.7869\n",
            "Epoch 57/300\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.4429 - conv2d_524_loss: 0.3374 - conv2d_525_loss: 0.1055 - conv2d_524_accuracy: 0.0943 - conv2d_525_accuracy: 0.7870\n",
            "Epoch 58/300\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.4212 - conv2d_524_loss: 0.3120 - conv2d_525_loss: 0.1091 - conv2d_524_accuracy: 0.0839 - conv2d_525_accuracy: 0.7856\n",
            "Epoch 59/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.3957 - conv2d_524_loss: 0.2873 - conv2d_525_loss: 0.1084 - conv2d_524_accuracy: 0.0774 - conv2d_525_accuracy: 0.7861\n",
            "Epoch 60/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.3748 - conv2d_524_loss: 0.2656 - conv2d_525_loss: 0.1092 - conv2d_524_accuracy: 0.0691 - conv2d_525_accuracy: 0.7862\n",
            "Epoch 61/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.3968 - conv2d_524_loss: 0.2908 - conv2d_525_loss: 0.1060 - conv2d_524_accuracy: 0.0773 - conv2d_525_accuracy: 0.7866\n",
            "Epoch 62/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.3754 - conv2d_524_loss: 0.2704 - conv2d_525_loss: 0.1050 - conv2d_524_accuracy: 0.0608 - conv2d_525_accuracy: 0.7871\n",
            "Epoch 63/300\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.3440 - conv2d_524_loss: 0.2404 - conv2d_525_loss: 0.1036 - conv2d_524_accuracy: 0.0480 - conv2d_525_accuracy: 0.7864\n",
            "Epoch 64/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.3428 - conv2d_524_loss: 0.2379 - conv2d_525_loss: 0.1049 - conv2d_524_accuracy: 0.0442 - conv2d_525_accuracy: 0.7860\n",
            "Epoch 65/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.3220 - conv2d_524_loss: 0.2197 - conv2d_525_loss: 0.1024 - conv2d_524_accuracy: 0.0362 - conv2d_525_accuracy: 0.7865\n",
            "Epoch 66/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.3227 - conv2d_524_loss: 0.2193 - conv2d_525_loss: 0.1033 - conv2d_524_accuracy: 0.0367 - conv2d_525_accuracy: 0.7864\n",
            "Epoch 67/300\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.3039 - conv2d_524_loss: 0.2034 - conv2d_525_loss: 0.1004 - conv2d_524_accuracy: 0.0337 - conv2d_525_accuracy: 0.7870\n",
            "Epoch 68/300\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.2914 - conv2d_524_loss: 0.1919 - conv2d_525_loss: 0.0995 - conv2d_524_accuracy: 0.0382 - conv2d_525_accuracy: 0.7876\n",
            "Epoch 69/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.2885 - conv2d_524_loss: 0.1881 - conv2d_525_loss: 0.1004 - conv2d_524_accuracy: 0.0588 - conv2d_525_accuracy: 0.7874\n",
            "Epoch 70/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.2827 - conv2d_524_loss: 0.1821 - conv2d_525_loss: 0.1006 - conv2d_524_accuracy: 0.0597 - conv2d_525_accuracy: 0.7869\n",
            "Epoch 71/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.2671 - conv2d_524_loss: 0.1691 - conv2d_525_loss: 0.0980 - conv2d_524_accuracy: 0.0489 - conv2d_525_accuracy: 0.7876\n",
            "Epoch 72/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.2695 - conv2d_524_loss: 0.1709 - conv2d_525_loss: 0.0986 - conv2d_524_accuracy: 0.0559 - conv2d_525_accuracy: 0.7877\n",
            "Epoch 73/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.2536 - conv2d_524_loss: 0.1575 - conv2d_525_loss: 0.0961 - conv2d_524_accuracy: 0.0587 - conv2d_525_accuracy: 0.7882\n",
            "Epoch 74/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.2516 - conv2d_524_loss: 0.1543 - conv2d_525_loss: 0.0973 - conv2d_524_accuracy: 0.0767 - conv2d_525_accuracy: 0.7880\n",
            "Epoch 75/300\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.2502 - conv2d_524_loss: 0.1515 - conv2d_525_loss: 0.0987 - conv2d_524_accuracy: 0.0956 - conv2d_525_accuracy: 0.7883\n",
            "Epoch 76/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.2375 - conv2d_524_loss: 0.1411 - conv2d_525_loss: 0.0964 - conv2d_524_accuracy: 0.0850 - conv2d_525_accuracy: 0.7885\n",
            "Epoch 77/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.2401 - conv2d_524_loss: 0.1428 - conv2d_525_loss: 0.0973 - conv2d_524_accuracy: 0.0890 - conv2d_525_accuracy: 0.7882\n",
            "Epoch 78/300\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.2267 - conv2d_524_loss: 0.1319 - conv2d_525_loss: 0.0949 - conv2d_524_accuracy: 0.0830 - conv2d_525_accuracy: 0.7884\n",
            "Epoch 79/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.2249 - conv2d_524_loss: 0.1303 - conv2d_525_loss: 0.0945 - conv2d_524_accuracy: 0.0935 - conv2d_525_accuracy: 0.7880\n",
            "Epoch 80/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.2226 - conv2d_524_loss: 0.1292 - conv2d_525_loss: 0.0934 - conv2d_524_accuracy: 0.0950 - conv2d_525_accuracy: 0.7884\n",
            "Epoch 81/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.2138 - conv2d_524_loss: 0.1193 - conv2d_525_loss: 0.0946 - conv2d_524_accuracy: 0.1050 - conv2d_525_accuracy: 0.7880\n",
            "Epoch 82/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.2115 - conv2d_524_loss: 0.1178 - conv2d_525_loss: 0.0937 - conv2d_524_accuracy: 0.0978 - conv2d_525_accuracy: 0.7881\n",
            "Epoch 83/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.2092 - conv2d_524_loss: 0.1152 - conv2d_525_loss: 0.0940 - conv2d_524_accuracy: 0.0959 - conv2d_525_accuracy: 0.7883\n",
            "Epoch 84/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.2082 - conv2d_524_loss: 0.1130 - conv2d_525_loss: 0.0952 - conv2d_524_accuracy: 0.1064 - conv2d_525_accuracy: 0.7884\n",
            "Epoch 85/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1993 - conv2d_524_loss: 0.1073 - conv2d_525_loss: 0.0920 - conv2d_524_accuracy: 0.0907 - conv2d_525_accuracy: 0.7887\n",
            "Epoch 86/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.2049 - conv2d_524_loss: 0.1108 - conv2d_525_loss: 0.0941 - conv2d_524_accuracy: 0.0993 - conv2d_525_accuracy: 0.7885\n",
            "Epoch 87/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1936 - conv2d_524_loss: 0.1011 - conv2d_525_loss: 0.0924 - conv2d_524_accuracy: 0.1011 - conv2d_525_accuracy: 0.7883\n",
            "Epoch 88/300\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.1924 - conv2d_524_loss: 0.1007 - conv2d_525_loss: 0.0918 - conv2d_524_accuracy: 0.0955 - conv2d_525_accuracy: 0.7885\n",
            "Epoch 89/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1944 - conv2d_524_loss: 0.1010 - conv2d_525_loss: 0.0933 - conv2d_524_accuracy: 0.1002 - conv2d_525_accuracy: 0.7884\n",
            "Epoch 90/300\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1934 - conv2d_524_loss: 0.1008 - conv2d_525_loss: 0.0926 - conv2d_524_accuracy: 0.0940 - conv2d_525_accuracy: 0.7886\n",
            "Epoch 91/300\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.1813 - conv2d_524_loss: 0.0904 - conv2d_525_loss: 0.0909 - conv2d_524_accuracy: 0.0959 - conv2d_525_accuracy: 0.7888\n",
            "Epoch 92/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1891 - conv2d_524_loss: 0.0970 - conv2d_525_loss: 0.0921 - conv2d_524_accuracy: 0.0933 - conv2d_525_accuracy: 0.7883\n",
            "Epoch 93/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1782 - conv2d_524_loss: 0.0861 - conv2d_525_loss: 0.0921 - conv2d_524_accuracy: 0.1079 - conv2d_525_accuracy: 0.7888\n",
            "Epoch 94/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1826 - conv2d_524_loss: 0.0906 - conv2d_525_loss: 0.0920 - conv2d_524_accuracy: 0.0988 - conv2d_525_accuracy: 0.7888\n",
            "Epoch 95/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1731 - conv2d_524_loss: 0.0827 - conv2d_525_loss: 0.0904 - conv2d_524_accuracy: 0.0962 - conv2d_525_accuracy: 0.7889\n",
            "Epoch 96/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1711 - conv2d_524_loss: 0.0809 - conv2d_525_loss: 0.0903 - conv2d_524_accuracy: 0.0927 - conv2d_525_accuracy: 0.7889\n",
            "Epoch 97/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1719 - conv2d_524_loss: 0.0813 - conv2d_525_loss: 0.0906 - conv2d_524_accuracy: 0.0880 - conv2d_525_accuracy: 0.7888\n",
            "Epoch 98/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1678 - conv2d_524_loss: 0.0781 - conv2d_525_loss: 0.0897 - conv2d_524_accuracy: 0.0936 - conv2d_525_accuracy: 0.7888\n",
            "Epoch 99/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1707 - conv2d_524_loss: 0.0804 - conv2d_525_loss: 0.0903 - conv2d_524_accuracy: 0.0995 - conv2d_525_accuracy: 0.7889\n",
            "Epoch 100/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1635 - conv2d_524_loss: 0.0739 - conv2d_525_loss: 0.0896 - conv2d_524_accuracy: 0.0984 - conv2d_525_accuracy: 0.7889\n",
            "Epoch 101/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1609 - conv2d_524_loss: 0.0723 - conv2d_525_loss: 0.0886 - conv2d_524_accuracy: 0.0778 - conv2d_525_accuracy: 0.7888\n",
            "Epoch 102/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1642 - conv2d_524_loss: 0.0746 - conv2d_525_loss: 0.0896 - conv2d_524_accuracy: 0.0872 - conv2d_525_accuracy: 0.7890\n",
            "Epoch 103/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1631 - conv2d_524_loss: 0.0736 - conv2d_525_loss: 0.0894 - conv2d_524_accuracy: 0.0886 - conv2d_525_accuracy: 0.7890\n",
            "Epoch 104/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1590 - conv2d_524_loss: 0.0704 - conv2d_525_loss: 0.0886 - conv2d_524_accuracy: 0.0949 - conv2d_525_accuracy: 0.7891\n",
            "Epoch 105/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1544 - conv2d_524_loss: 0.0658 - conv2d_525_loss: 0.0887 - conv2d_524_accuracy: 0.1007 - conv2d_525_accuracy: 0.7890\n",
            "Epoch 106/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1527 - conv2d_524_loss: 0.0643 - conv2d_525_loss: 0.0884 - conv2d_524_accuracy: 0.0867 - conv2d_525_accuracy: 0.7888\n",
            "Epoch 107/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1527 - conv2d_524_loss: 0.0650 - conv2d_525_loss: 0.0877 - conv2d_524_accuracy: 0.0861 - conv2d_525_accuracy: 0.7891\n",
            "Epoch 108/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1496 - conv2d_524_loss: 0.0624 - conv2d_525_loss: 0.0872 - conv2d_524_accuracy: 0.0797 - conv2d_525_accuracy: 0.7891\n",
            "Epoch 109/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1479 - conv2d_524_loss: 0.0600 - conv2d_525_loss: 0.0878 - conv2d_524_accuracy: 0.0901 - conv2d_525_accuracy: 0.7891\n",
            "Epoch 110/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1590 - conv2d_524_loss: 0.0708 - conv2d_525_loss: 0.0881 - conv2d_524_accuracy: 0.0893 - conv2d_525_accuracy: 0.7891\n",
            "Epoch 111/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1462 - conv2d_524_loss: 0.0588 - conv2d_525_loss: 0.0873 - conv2d_524_accuracy: 0.0933 - conv2d_525_accuracy: 0.7891\n",
            "Epoch 112/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1479 - conv2d_524_loss: 0.0603 - conv2d_525_loss: 0.0876 - conv2d_524_accuracy: 0.0936 - conv2d_525_accuracy: 0.7889\n",
            "Epoch 113/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1454 - conv2d_524_loss: 0.0582 - conv2d_525_loss: 0.0871 - conv2d_524_accuracy: 0.0875 - conv2d_525_accuracy: 0.7891\n",
            "Epoch 114/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1506 - conv2d_524_loss: 0.0630 - conv2d_525_loss: 0.0876 - conv2d_524_accuracy: 0.0847 - conv2d_525_accuracy: 0.7891\n",
            "Epoch 115/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1373 - conv2d_524_loss: 0.0512 - conv2d_525_loss: 0.0861 - conv2d_524_accuracy: 0.0791 - conv2d_525_accuracy: 0.7892\n",
            "Epoch 116/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1407 - conv2d_524_loss: 0.0548 - conv2d_525_loss: 0.0859 - conv2d_524_accuracy: 0.0784 - conv2d_525_accuracy: 0.7890\n",
            "Epoch 117/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1449 - conv2d_524_loss: 0.0578 - conv2d_525_loss: 0.0871 - conv2d_524_accuracy: 0.0903 - conv2d_525_accuracy: 0.7890\n",
            "Epoch 118/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1370 - conv2d_524_loss: 0.0510 - conv2d_525_loss: 0.0860 - conv2d_524_accuracy: 0.0872 - conv2d_525_accuracy: 0.7892\n",
            "Epoch 119/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1394 - conv2d_524_loss: 0.0536 - conv2d_525_loss: 0.0858 - conv2d_524_accuracy: 0.0781 - conv2d_525_accuracy: 0.7892\n",
            "Epoch 120/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1359 - conv2d_524_loss: 0.0504 - conv2d_525_loss: 0.0855 - conv2d_524_accuracy: 0.0739 - conv2d_525_accuracy: 0.7892\n",
            "Epoch 121/300\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1390 - conv2d_524_loss: 0.0532 - conv2d_525_loss: 0.0858 - conv2d_524_accuracy: 0.0773 - conv2d_525_accuracy: 0.7892\n",
            "Epoch 122/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1337 - conv2d_524_loss: 0.0488 - conv2d_525_loss: 0.0849 - conv2d_524_accuracy: 0.0814 - conv2d_525_accuracy: 0.7892\n",
            "Epoch 123/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1398 - conv2d_524_loss: 0.0540 - conv2d_525_loss: 0.0858 - conv2d_524_accuracy: 0.0863 - conv2d_525_accuracy: 0.7892\n",
            "Epoch 124/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1375 - conv2d_524_loss: 0.0517 - conv2d_525_loss: 0.0857 - conv2d_524_accuracy: 0.0795 - conv2d_525_accuracy: 0.7892\n",
            "Epoch 125/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1355 - conv2d_524_loss: 0.0496 - conv2d_525_loss: 0.0859 - conv2d_524_accuracy: 0.0771 - conv2d_525_accuracy: 0.7893\n",
            "Epoch 126/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1356 - conv2d_524_loss: 0.0502 - conv2d_525_loss: 0.0854 - conv2d_524_accuracy: 0.0823 - conv2d_525_accuracy: 0.7892\n",
            "Epoch 127/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1319 - conv2d_524_loss: 0.0469 - conv2d_525_loss: 0.0850 - conv2d_524_accuracy: 0.0869 - conv2d_525_accuracy: 0.7893\n",
            "Epoch 128/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1295 - conv2d_524_loss: 0.0447 - conv2d_525_loss: 0.0848 - conv2d_524_accuracy: 0.0924 - conv2d_525_accuracy: 0.7892\n",
            "Epoch 129/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1333 - conv2d_524_loss: 0.0488 - conv2d_525_loss: 0.0845 - conv2d_524_accuracy: 0.0763 - conv2d_525_accuracy: 0.7893\n",
            "Epoch 130/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1288 - conv2d_524_loss: 0.0443 - conv2d_525_loss: 0.0845 - conv2d_524_accuracy: 0.0650 - conv2d_525_accuracy: 0.7893\n",
            "Epoch 131/300\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.1254 - conv2d_524_loss: 0.0412 - conv2d_525_loss: 0.0842 - conv2d_524_accuracy: 0.0651 - conv2d_525_accuracy: 0.7893\n",
            "Epoch 132/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1313 - conv2d_524_loss: 0.0464 - conv2d_525_loss: 0.0849 - conv2d_524_accuracy: 0.0776 - conv2d_525_accuracy: 0.7892\n",
            "Epoch 133/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1280 - conv2d_524_loss: 0.0430 - conv2d_525_loss: 0.0850 - conv2d_524_accuracy: 0.0953 - conv2d_525_accuracy: 0.7891\n",
            "Epoch 134/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1297 - conv2d_524_loss: 0.0452 - conv2d_525_loss: 0.0845 - conv2d_524_accuracy: 0.0786 - conv2d_525_accuracy: 0.7892\n",
            "Epoch 135/300\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1257 - conv2d_524_loss: 0.0417 - conv2d_525_loss: 0.0840 - conv2d_524_accuracy: 0.0631 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 136/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1241 - conv2d_524_loss: 0.0407 - conv2d_525_loss: 0.0833 - conv2d_524_accuracy: 0.0531 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 137/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1243 - conv2d_524_loss: 0.0405 - conv2d_525_loss: 0.0838 - conv2d_524_accuracy: 0.0599 - conv2d_525_accuracy: 0.7891\n",
            "Epoch 138/300\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1224 - conv2d_524_loss: 0.0389 - conv2d_525_loss: 0.0835 - conv2d_524_accuracy: 0.0726 - conv2d_525_accuracy: 0.7891\n",
            "Epoch 139/300\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.1235 - conv2d_524_loss: 0.0401 - conv2d_525_loss: 0.0834 - conv2d_524_accuracy: 0.0702 - conv2d_525_accuracy: 0.7892\n",
            "Epoch 140/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1211 - conv2d_524_loss: 0.0379 - conv2d_525_loss: 0.0832 - conv2d_524_accuracy: 0.0500 - conv2d_525_accuracy: 0.7893\n",
            "Epoch 141/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1216 - conv2d_524_loss: 0.0388 - conv2d_525_loss: 0.0829 - conv2d_524_accuracy: 0.0395 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 142/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1191 - conv2d_524_loss: 0.0362 - conv2d_525_loss: 0.0830 - conv2d_524_accuracy: 0.0548 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 143/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1217 - conv2d_524_loss: 0.0386 - conv2d_525_loss: 0.0831 - conv2d_524_accuracy: 0.0712 - conv2d_525_accuracy: 0.7893\n",
            "Epoch 144/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1191 - conv2d_524_loss: 0.0355 - conv2d_525_loss: 0.0836 - conv2d_524_accuracy: 0.0662 - conv2d_525_accuracy: 0.7892\n",
            "Epoch 145/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1152 - conv2d_524_loss: 0.0324 - conv2d_525_loss: 0.0828 - conv2d_524_accuracy: 0.0589 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 146/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1163 - conv2d_524_loss: 0.0342 - conv2d_525_loss: 0.0821 - conv2d_524_accuracy: 0.0460 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 147/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1169 - conv2d_524_loss: 0.0334 - conv2d_525_loss: 0.0834 - conv2d_524_accuracy: 0.0591 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 148/300\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.1162 - conv2d_524_loss: 0.0343 - conv2d_525_loss: 0.0819 - conv2d_524_accuracy: 0.0606 - conv2d_525_accuracy: 0.7893\n",
            "Epoch 149/300\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.1165 - conv2d_524_loss: 0.0340 - conv2d_525_loss: 0.0825 - conv2d_524_accuracy: 0.0644 - conv2d_525_accuracy: 0.7893\n",
            "Epoch 150/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1165 - conv2d_524_loss: 0.0344 - conv2d_525_loss: 0.0821 - conv2d_524_accuracy: 0.0604 - conv2d_525_accuracy: 0.7893\n",
            "Epoch 151/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1178 - conv2d_524_loss: 0.0356 - conv2d_525_loss: 0.0822 - conv2d_524_accuracy: 0.0570 - conv2d_525_accuracy: 0.7893\n",
            "Epoch 152/300\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.1129 - conv2d_524_loss: 0.0306 - conv2d_525_loss: 0.0822 - conv2d_524_accuracy: 0.0566 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 153/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1136 - conv2d_524_loss: 0.0316 - conv2d_525_loss: 0.0820 - conv2d_524_accuracy: 0.0529 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 154/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1150 - conv2d_524_loss: 0.0330 - conv2d_525_loss: 0.0820 - conv2d_524_accuracy: 0.0493 - conv2d_525_accuracy: 0.7893\n",
            "Epoch 155/300\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.1113 - conv2d_524_loss: 0.0300 - conv2d_525_loss: 0.0813 - conv2d_524_accuracy: 0.0601 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 156/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1118 - conv2d_524_loss: 0.0297 - conv2d_525_loss: 0.0821 - conv2d_524_accuracy: 0.0595 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 157/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1141 - conv2d_524_loss: 0.0320 - conv2d_525_loss: 0.0821 - conv2d_524_accuracy: 0.0453 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 158/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1132 - conv2d_524_loss: 0.0318 - conv2d_525_loss: 0.0813 - conv2d_524_accuracy: 0.0370 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 159/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1125 - conv2d_524_loss: 0.0306 - conv2d_525_loss: 0.0819 - conv2d_524_accuracy: 0.0588 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 160/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1125 - conv2d_524_loss: 0.0308 - conv2d_525_loss: 0.0818 - conv2d_524_accuracy: 0.0668 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 161/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1093 - conv2d_524_loss: 0.0283 - conv2d_525_loss: 0.0809 - conv2d_524_accuracy: 0.0547 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 162/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1099 - conv2d_524_loss: 0.0288 - conv2d_525_loss: 0.0812 - conv2d_524_accuracy: 0.0358 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 163/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1084 - conv2d_524_loss: 0.0274 - conv2d_525_loss: 0.0810 - conv2d_524_accuracy: 0.0372 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 164/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1089 - conv2d_524_loss: 0.0283 - conv2d_525_loss: 0.0807 - conv2d_524_accuracy: 0.0511 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 165/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1092 - conv2d_524_loss: 0.0276 - conv2d_525_loss: 0.0816 - conv2d_524_accuracy: 0.0537 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 166/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1076 - conv2d_524_loss: 0.0269 - conv2d_525_loss: 0.0807 - conv2d_524_accuracy: 0.0396 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 167/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1101 - conv2d_524_loss: 0.0282 - conv2d_525_loss: 0.0819 - conv2d_524_accuracy: 0.0307 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 168/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1080 - conv2d_524_loss: 0.0272 - conv2d_525_loss: 0.0808 - conv2d_524_accuracy: 0.0428 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 169/300\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.1084 - conv2d_524_loss: 0.0273 - conv2d_525_loss: 0.0811 - conv2d_524_accuracy: 0.0581 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 170/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1067 - conv2d_524_loss: 0.0255 - conv2d_525_loss: 0.0811 - conv2d_524_accuracy: 0.0383 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 171/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1070 - conv2d_524_loss: 0.0269 - conv2d_525_loss: 0.0802 - conv2d_524_accuracy: 0.0228 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 172/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1074 - conv2d_524_loss: 0.0267 - conv2d_525_loss: 0.0807 - conv2d_524_accuracy: 0.0325 - conv2d_525_accuracy: 0.7893\n",
            "Epoch 173/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1063 - conv2d_524_loss: 0.0260 - conv2d_525_loss: 0.0803 - conv2d_524_accuracy: 0.0557 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 174/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1062 - conv2d_524_loss: 0.0264 - conv2d_525_loss: 0.0798 - conv2d_524_accuracy: 0.0514 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 175/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1047 - conv2d_524_loss: 0.0245 - conv2d_525_loss: 0.0801 - conv2d_524_accuracy: 0.0284 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 176/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1052 - conv2d_524_loss: 0.0254 - conv2d_525_loss: 0.0798 - conv2d_524_accuracy: 0.0216 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 177/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1064 - conv2d_524_loss: 0.0264 - conv2d_525_loss: 0.0800 - conv2d_524_accuracy: 0.0304 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 178/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1063 - conv2d_524_loss: 0.0259 - conv2d_525_loss: 0.0804 - conv2d_524_accuracy: 0.0618 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 179/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1031 - conv2d_524_loss: 0.0235 - conv2d_525_loss: 0.0796 - conv2d_524_accuracy: 0.0511 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 180/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1034 - conv2d_524_loss: 0.0234 - conv2d_525_loss: 0.0799 - conv2d_524_accuracy: 0.0252 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 181/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1043 - conv2d_524_loss: 0.0247 - conv2d_525_loss: 0.0797 - conv2d_524_accuracy: 0.0145 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 182/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1033 - conv2d_524_loss: 0.0234 - conv2d_525_loss: 0.0799 - conv2d_524_accuracy: 0.0314 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 183/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1028 - conv2d_524_loss: 0.0232 - conv2d_525_loss: 0.0796 - conv2d_524_accuracy: 0.0499 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 184/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1033 - conv2d_524_loss: 0.0236 - conv2d_525_loss: 0.0797 - conv2d_524_accuracy: 0.0479 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 185/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1010 - conv2d_524_loss: 0.0220 - conv2d_525_loss: 0.0790 - conv2d_524_accuracy: 0.0254 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 186/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1017 - conv2d_524_loss: 0.0227 - conv2d_525_loss: 0.0790 - conv2d_524_accuracy: 0.0154 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 187/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1008 - conv2d_524_loss: 0.0219 - conv2d_525_loss: 0.0789 - conv2d_524_accuracy: 0.0186 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 188/300\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1020 - conv2d_524_loss: 0.0225 - conv2d_525_loss: 0.0794 - conv2d_524_accuracy: 0.0296 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 189/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1003 - conv2d_524_loss: 0.0215 - conv2d_525_loss: 0.0789 - conv2d_524_accuracy: 0.0301 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 190/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1000 - conv2d_524_loss: 0.0208 - conv2d_525_loss: 0.0792 - conv2d_524_accuracy: 0.0273 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 191/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1019 - conv2d_524_loss: 0.0225 - conv2d_525_loss: 0.0794 - conv2d_524_accuracy: 0.0257 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 192/300\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0998 - conv2d_524_loss: 0.0212 - conv2d_525_loss: 0.0786 - conv2d_524_accuracy: 0.0239 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 193/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0994 - conv2d_524_loss: 0.0210 - conv2d_525_loss: 0.0784 - conv2d_524_accuracy: 0.0232 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 194/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0994 - conv2d_524_loss: 0.0205 - conv2d_525_loss: 0.0789 - conv2d_524_accuracy: 0.0227 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 195/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0981 - conv2d_524_loss: 0.0193 - conv2d_525_loss: 0.0788 - conv2d_524_accuracy: 0.0220 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 196/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0987 - conv2d_524_loss: 0.0202 - conv2d_525_loss: 0.0785 - conv2d_524_accuracy: 0.0269 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 197/300\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0986 - conv2d_524_loss: 0.0202 - conv2d_525_loss: 0.0784 - conv2d_524_accuracy: 0.0331 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 198/300\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0977 - conv2d_524_loss: 0.0195 - conv2d_525_loss: 0.0781 - conv2d_524_accuracy: 0.0262 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 199/300\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0978 - conv2d_524_loss: 0.0194 - conv2d_525_loss: 0.0784 - conv2d_524_accuracy: 0.0148 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 200/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0983 - conv2d_524_loss: 0.0199 - conv2d_525_loss: 0.0784 - conv2d_524_accuracy: 0.0123 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 201/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0971 - conv2d_524_loss: 0.0189 - conv2d_525_loss: 0.0782 - conv2d_524_accuracy: 0.0201 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 202/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0972 - conv2d_524_loss: 0.0189 - conv2d_525_loss: 0.0783 - conv2d_524_accuracy: 0.0334 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 203/300\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0968 - conv2d_524_loss: 0.0186 - conv2d_525_loss: 0.0781 - conv2d_524_accuracy: 0.0249 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 204/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0976 - conv2d_524_loss: 0.0193 - conv2d_525_loss: 0.0782 - conv2d_524_accuracy: 0.0137 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 205/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0952 - conv2d_524_loss: 0.0173 - conv2d_525_loss: 0.0779 - conv2d_524_accuracy: 0.0110 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 206/300\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0959 - conv2d_524_loss: 0.0177 - conv2d_525_loss: 0.0782 - conv2d_524_accuracy: 0.0202 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 207/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0970 - conv2d_524_loss: 0.0190 - conv2d_525_loss: 0.0780 - conv2d_524_accuracy: 0.0296 - conv2d_525_accuracy: 0.7894\n",
            "Epoch 208/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0949 - conv2d_524_loss: 0.0172 - conv2d_525_loss: 0.0778 - conv2d_524_accuracy: 0.0213 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 209/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0947 - conv2d_524_loss: 0.0170 - conv2d_525_loss: 0.0778 - conv2d_524_accuracy: 0.0113 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 210/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0947 - conv2d_524_loss: 0.0171 - conv2d_525_loss: 0.0776 - conv2d_524_accuracy: 0.0102 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 211/300\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0957 - conv2d_524_loss: 0.0179 - conv2d_525_loss: 0.0778 - conv2d_524_accuracy: 0.0225 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 212/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0963 - conv2d_524_loss: 0.0185 - conv2d_525_loss: 0.0779 - conv2d_524_accuracy: 0.0287 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 213/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0959 - conv2d_524_loss: 0.0182 - conv2d_525_loss: 0.0777 - conv2d_524_accuracy: 0.0121 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 214/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0960 - conv2d_524_loss: 0.0183 - conv2d_525_loss: 0.0777 - conv2d_524_accuracy: 0.0056 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 215/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0959 - conv2d_524_loss: 0.0177 - conv2d_525_loss: 0.0782 - conv2d_524_accuracy: 0.0076 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 216/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0941 - conv2d_524_loss: 0.0164 - conv2d_525_loss: 0.0777 - conv2d_524_accuracy: 0.0156 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 217/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0952 - conv2d_524_loss: 0.0171 - conv2d_525_loss: 0.0781 - conv2d_524_accuracy: 0.0212 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 218/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0943 - conv2d_524_loss: 0.0172 - conv2d_525_loss: 0.0771 - conv2d_524_accuracy: 0.0102 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 219/300\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0943 - conv2d_524_loss: 0.0167 - conv2d_525_loss: 0.0776 - conv2d_524_accuracy: 0.0051 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 220/300\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0936 - conv2d_524_loss: 0.0161 - conv2d_525_loss: 0.0775 - conv2d_524_accuracy: 0.0059 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 221/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0927 - conv2d_524_loss: 0.0156 - conv2d_525_loss: 0.0771 - conv2d_524_accuracy: 0.0111 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 222/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0932 - conv2d_524_loss: 0.0160 - conv2d_525_loss: 0.0773 - conv2d_524_accuracy: 0.0170 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 223/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0922 - conv2d_524_loss: 0.0155 - conv2d_525_loss: 0.0767 - conv2d_524_accuracy: 0.0079 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 224/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0923 - conv2d_524_loss: 0.0154 - conv2d_525_loss: 0.0769 - conv2d_524_accuracy: 0.0028 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 225/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0931 - conv2d_524_loss: 0.0160 - conv2d_525_loss: 0.0770 - conv2d_524_accuracy: 0.0033 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 226/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0920 - conv2d_524_loss: 0.0149 - conv2d_525_loss: 0.0771 - conv2d_524_accuracy: 0.0062 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 227/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0920 - conv2d_524_loss: 0.0150 - conv2d_525_loss: 0.0769 - conv2d_524_accuracy: 0.0065 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 228/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0908 - conv2d_524_loss: 0.0141 - conv2d_525_loss: 0.0767 - conv2d_524_accuracy: 0.0057 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 229/300\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0946 - conv2d_524_loss: 0.0174 - conv2d_525_loss: 0.0772 - conv2d_524_accuracy: 0.0039 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 230/300\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0915 - conv2d_524_loss: 0.0149 - conv2d_525_loss: 0.0767 - conv2d_524_accuracy: 0.0040 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 231/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0908 - conv2d_524_loss: 0.0140 - conv2d_525_loss: 0.0768 - conv2d_524_accuracy: 0.0085 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 232/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0910 - conv2d_524_loss: 0.0142 - conv2d_525_loss: 0.0769 - conv2d_524_accuracy: 0.0074 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 233/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0920 - conv2d_524_loss: 0.0153 - conv2d_525_loss: 0.0768 - conv2d_524_accuracy: 0.0045 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 234/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0911 - conv2d_524_loss: 0.0146 - conv2d_525_loss: 0.0765 - conv2d_524_accuracy: 0.0047 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 235/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0909 - conv2d_524_loss: 0.0145 - conv2d_525_loss: 0.0764 - conv2d_524_accuracy: 0.0059 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 236/300\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0927 - conv2d_524_loss: 0.0157 - conv2d_525_loss: 0.0769 - conv2d_524_accuracy: 0.0046 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 237/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0909 - conv2d_524_loss: 0.0144 - conv2d_525_loss: 0.0766 - conv2d_524_accuracy: 0.0035 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 238/300\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0906 - conv2d_524_loss: 0.0141 - conv2d_525_loss: 0.0764 - conv2d_524_accuracy: 0.0053 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 239/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0897 - conv2d_524_loss: 0.0134 - conv2d_525_loss: 0.0763 - conv2d_524_accuracy: 0.0085 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 240/300\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0901 - conv2d_524_loss: 0.0136 - conv2d_525_loss: 0.0765 - conv2d_524_accuracy: 0.0034 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 241/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0901 - conv2d_524_loss: 0.0138 - conv2d_525_loss: 0.0762 - conv2d_524_accuracy: 0.0015 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 242/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0897 - conv2d_524_loss: 0.0135 - conv2d_525_loss: 0.0762 - conv2d_524_accuracy: 0.0021 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 243/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0897 - conv2d_524_loss: 0.0135 - conv2d_525_loss: 0.0761 - conv2d_524_accuracy: 0.0048 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 244/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0894 - conv2d_524_loss: 0.0133 - conv2d_525_loss: 0.0761 - conv2d_524_accuracy: 0.0043 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 245/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0893 - conv2d_524_loss: 0.0131 - conv2d_525_loss: 0.0762 - conv2d_524_accuracy: 0.0012 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 246/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0890 - conv2d_524_loss: 0.0130 - conv2d_525_loss: 0.0760 - conv2d_524_accuracy: 0.0010 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 247/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0888 - conv2d_524_loss: 0.0126 - conv2d_525_loss: 0.0762 - conv2d_524_accuracy: 0.0026 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 248/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0882 - conv2d_524_loss: 0.0121 - conv2d_525_loss: 0.0761 - conv2d_524_accuracy: 0.0039 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 249/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0887 - conv2d_524_loss: 0.0123 - conv2d_525_loss: 0.0764 - conv2d_524_accuracy: 0.0024 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 250/300\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0876 - conv2d_524_loss: 0.0119 - conv2d_525_loss: 0.0757 - conv2d_524_accuracy: 0.0014 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 251/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0891 - conv2d_524_loss: 0.0127 - conv2d_525_loss: 0.0764 - conv2d_524_accuracy: 0.0010 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 252/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0888 - conv2d_524_loss: 0.0127 - conv2d_525_loss: 0.0761 - conv2d_524_accuracy: 0.0012 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 253/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0888 - conv2d_524_loss: 0.0128 - conv2d_525_loss: 0.0760 - conv2d_524_accuracy: 9.0681e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 254/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0892 - conv2d_524_loss: 0.0130 - conv2d_525_loss: 0.0761 - conv2d_524_accuracy: 0.0012 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 255/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0883 - conv2d_524_loss: 0.0123 - conv2d_525_loss: 0.0759 - conv2d_524_accuracy: 0.0018 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 256/300\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0880 - conv2d_524_loss: 0.0119 - conv2d_525_loss: 0.0761 - conv2d_524_accuracy: 0.0017 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 257/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0876 - conv2d_524_loss: 0.0119 - conv2d_525_loss: 0.0757 - conv2d_524_accuracy: 0.0010 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 258/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0875 - conv2d_524_loss: 0.0120 - conv2d_525_loss: 0.0755 - conv2d_524_accuracy: 0.0014 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 259/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0878 - conv2d_524_loss: 0.0118 - conv2d_525_loss: 0.0760 - conv2d_524_accuracy: 0.0021 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 260/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0868 - conv2d_524_loss: 0.0111 - conv2d_525_loss: 0.0757 - conv2d_524_accuracy: 0.0013 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 261/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0868 - conv2d_524_loss: 0.0112 - conv2d_525_loss: 0.0757 - conv2d_524_accuracy: 8.0716e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 262/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0867 - conv2d_524_loss: 0.0113 - conv2d_525_loss: 0.0754 - conv2d_524_accuracy: 0.0011 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 263/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0854 - conv2d_524_loss: 0.0103 - conv2d_525_loss: 0.0752 - conv2d_524_accuracy: 0.0019 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 264/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0864 - conv2d_524_loss: 0.0109 - conv2d_525_loss: 0.0756 - conv2d_524_accuracy: 0.0010 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 265/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0870 - conv2d_524_loss: 0.0112 - conv2d_525_loss: 0.0757 - conv2d_524_accuracy: 3.8863e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 266/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0870 - conv2d_524_loss: 0.0115 - conv2d_525_loss: 0.0755 - conv2d_524_accuracy: 0.0010 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 267/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0868 - conv2d_524_loss: 0.0115 - conv2d_525_loss: 0.0753 - conv2d_524_accuracy: 0.0025 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 268/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0865 - conv2d_524_loss: 0.0111 - conv2d_525_loss: 0.0754 - conv2d_524_accuracy: 6.0786e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 269/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0864 - conv2d_524_loss: 0.0112 - conv2d_525_loss: 0.0752 - conv2d_524_accuracy: 1.9930e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 270/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0862 - conv2d_524_loss: 0.0111 - conv2d_525_loss: 0.0752 - conv2d_524_accuracy: 4.7832e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 271/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0860 - conv2d_524_loss: 0.0108 - conv2d_525_loss: 0.0752 - conv2d_524_accuracy: 0.0019 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 272/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0855 - conv2d_524_loss: 0.0102 - conv2d_525_loss: 0.0752 - conv2d_524_accuracy: 0.0010 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 273/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0862 - conv2d_524_loss: 0.0110 - conv2d_525_loss: 0.0751 - conv2d_524_accuracy: 3.7867e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 274/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0861 - conv2d_524_loss: 0.0108 - conv2d_525_loss: 0.0753 - conv2d_524_accuracy: 4.0856e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 275/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0853 - conv2d_524_loss: 0.0100 - conv2d_525_loss: 0.0753 - conv2d_524_accuracy: 0.0010 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 276/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0847 - conv2d_524_loss: 0.0100 - conv2d_525_loss: 0.0746 - conv2d_524_accuracy: 0.0011 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 277/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0852 - conv2d_524_loss: 0.0102 - conv2d_525_loss: 0.0749 - conv2d_524_accuracy: 4.6835e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 278/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0849 - conv2d_524_loss: 0.0100 - conv2d_525_loss: 0.0748 - conv2d_524_accuracy: 2.4912e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 279/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0847 - conv2d_524_loss: 0.0099 - conv2d_525_loss: 0.0748 - conv2d_524_accuracy: 3.0891e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 280/300\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0849 - conv2d_524_loss: 0.0100 - conv2d_525_loss: 0.0748 - conv2d_524_accuracy: 5.6800e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 281/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0850 - conv2d_524_loss: 0.0100 - conv2d_525_loss: 0.0750 - conv2d_524_accuracy: 3.8863e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 282/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0849 - conv2d_524_loss: 0.0100 - conv2d_525_loss: 0.0749 - conv2d_524_accuracy: 2.5909e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 283/300\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0854 - conv2d_524_loss: 0.0105 - conv2d_525_loss: 0.0749 - conv2d_524_accuracy: 2.3916e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 284/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0853 - conv2d_524_loss: 0.0101 - conv2d_525_loss: 0.0751 - conv2d_524_accuracy: 7.7726e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 285/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0845 - conv2d_524_loss: 0.0098 - conv2d_525_loss: 0.0748 - conv2d_524_accuracy: 5.7797e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 286/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0845 - conv2d_524_loss: 0.0098 - conv2d_525_loss: 0.0747 - conv2d_524_accuracy: 1.8933e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 287/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0845 - conv2d_524_loss: 0.0098 - conv2d_525_loss: 0.0747 - conv2d_524_accuracy: 4.3846e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 288/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0847 - conv2d_524_loss: 0.0099 - conv2d_525_loss: 0.0748 - conv2d_524_accuracy: 7.2744e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 289/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0839 - conv2d_524_loss: 0.0091 - conv2d_525_loss: 0.0748 - conv2d_524_accuracy: 1.9930e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 290/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0851 - conv2d_524_loss: 0.0104 - conv2d_525_loss: 0.0747 - conv2d_524_accuracy: 1.6940e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 291/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0842 - conv2d_524_loss: 0.0095 - conv2d_525_loss: 0.0747 - conv2d_524_accuracy: 4.3846e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 292/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0840 - conv2d_524_loss: 0.0093 - conv2d_525_loss: 0.0747 - conv2d_524_accuracy: 0.0011 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 293/300\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0850 - conv2d_524_loss: 0.0100 - conv2d_525_loss: 0.0750 - conv2d_524_accuracy: 3.8863e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 294/300\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0840 - conv2d_524_loss: 0.0096 - conv2d_525_loss: 0.0744 - conv2d_524_accuracy: 6.9754e-05 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 295/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0839 - conv2d_524_loss: 0.0093 - conv2d_525_loss: 0.0745 - conv2d_524_accuracy: 1.9930e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 296/300\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0838 - conv2d_524_loss: 0.0097 - conv2d_525_loss: 0.0742 - conv2d_524_accuracy: 0.0017 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 297/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0831 - conv2d_524_loss: 0.0086 - conv2d_525_loss: 0.0746 - conv2d_524_accuracy: 2.2919e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 298/300\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0831 - conv2d_524_loss: 0.0088 - conv2d_525_loss: 0.0743 - conv2d_524_accuracy: 2.9895e-05 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 299/300\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0832 - conv2d_524_loss: 0.0090 - conv2d_525_loss: 0.0742 - conv2d_524_accuracy: 1.5944e-04 - conv2d_525_accuracy: 0.7895\n",
            "Epoch 300/300\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0848 - conv2d_524_loss: 0.0101 - conv2d_525_loss: 0.0747 - conv2d_524_accuracy: 0.0011 - conv2d_525_accuracy: 0.7895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKxrjiG_eqBO",
        "colab_type": "code",
        "outputId": "89c15273-8f44-4f0f-c542-21d8ca561500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "# \"Loss\"\n",
        "if True:\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-372-c0f5efe24d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAen0lEQVR4nO3de3hddZ3v8fd337Jza9I06T2QUkqxoBQMCIJaRRTwgs7gWJ3DeDunz1EZdPQ883BmzpEZR+c8zKPoQXxEFI/VR8ELKhzECwoKHuSScqmUttCWQq8kbdPcL/vyPX/slZKkSRPanaysnc/rYT9Ze62Vvb+LlX7Wb//2Wr9l7o6IiERfLOwCRESkOBToIiIlQoEuIlIiFOgiIiVCgS4iUiISYb1xfX29NzU1hfX2IiKRtGHDhgPu3jDWstACvampiZaWlrDeXkQkkszshfGWqctFRKREKNBFREqEAl1EpEQo0EVESoQCXUSkRCjQRURKhAJdRKRERC7Qt+7v4su/3crB7oGwSxERmVEiF+jb27r52n3bONA9GHYpIiIzSuQCPRkvlJzJ5UOuRERkZolcoCfiBsCgAl1EZITIBXpqqIWeVaCLiAwXuUAf6nLJ5nUvVBGR4SIY6OpyEREZSwQDXV0uIiJjiW6g59TlIiIyXAQDvdDlks2rhS4iMlwEA71Q8qC6XERERohsoKvLRURkpAgGurpcRETGEr1AT6jLRURkLNEL9Ji6XERExhK9QA+6XDQ4l4jISJEL9HjMMIOsAl1EZIQJA93M0mb2qJk9ZWabzOxfx1inzMx+ZGbbzOwRM2uaimKD9yIZjzGoLhcRkREm00IfAN7i7mcBq4FLzez8Uet8DGh391OBrwDXF7fMkZIxU5eLiMgoEwa6F3QHT5PBY3Tz+ApgfTD9U+BiM7OiVTlKMhFToIuIjDKpPnQzi5vZk0ArcK+7PzJqlSXALgB3zwIdwLwxXmedmbWYWUtbW9txF52Mx3SWi4jIKJMKdHfPuftqYClwnpmdeTxv5u63uHuzuzc3NDQcz0sA6nIRERnLKzrLxd0PA/cDl45atAdoBDCzBFADHCxGgWNRl4uIyNEmc5ZLg5nVBtPlwCXAllGr3QV8KJi+ErjP3aesTyQZj5FVl4uIyAiJSayzCFhvZnEKB4Afu/vdZvZ5oMXd7wJuBb5vZtuAQ8DaKasYgtMW1UIXERluwkB3943A2WPM/9yw6X7gfcUtbXzJuPrQRURGi9yVojB0losCXURkuIgGuum0RRGRUSIa6Gqhi4iMpkAXESkREQ1002mLIiKjRDTQddqiiMhokQ10dbmIiIwU0UA3Mll1uYiIDBfRQI+RzauFLiIyXGQDfTCrQBcRGS6iga4Li0RERotooOtLURGR0SIb6Nm8M4Uj9IqIRE5EA71wu1J1u4iIvCyigV4oW90uIiIvi3Sg6/J/EZGXRTTQC10uuvxfRORlEQ10dbmIiIymQBcRKRHRDPTEUKCrD11EZEgkAz011Ieuy/9FRI6IZKBXpBIA9AxmQ65ERGTmmDDQzazRzO43s2fMbJOZfWqMddaYWYeZPRk8Pjc15RbUlCcB6OjNTOXbiIhESmIS62SBz7r742ZWDWwws3vd/ZlR6z3o7u8sfolHq60oBPrhPgW6iMiQCVvo7r7P3R8PpruAzcCSqS7sWI600BXoIiJHvKI+dDNrAs4GHhlj8QVm9pSZ/crMzhjn99eZWYuZtbS1tb3iYodUpxXoIiKjTTrQzawKuAP4tLt3jlr8OHCyu58FfA34xViv4e63uHuzuzc3NDQcb83EY0Z1OkGnAl1E5IhJBbqZJSmE+Q/c/Wejl7t7p7t3B9P3AEkzqy9qpaPUlCfVQhcRGWYyZ7kYcCuw2d1vGGedhcF6mNl5weseLGaho9VWKNBFRIabzFkuFwJXAX8xsyeDef8EnATg7jcDVwIfN7Ms0Aes9Sm++4Ra6CIiI00Y6O7+J8AmWOcm4KZiFTUZNeVJ9nd0TedbiojMaJG8UhSGWui6UlREZEhkA31OeZLOvozuKyoiEohsoNeUJxnM5enPaIAuERGIcKDXlqcAXVwkIjIksoGuy/9FREaKbKDPKS+coNPVr0AXEYEIB3pVWRDoAzrTRUQEIhzo1elCoHf3K9BFRCDCgV5VVuhD71YLXUQEiHKgp9WHLiIyXGQDvSIZx0xdLiIiQyIb6LGYUZVK6EtREZFAZAMdCt0uaqGLiBREO9DLEvpSVEQkEO1ATyvQRUSGRDvQyxJ0qctFRASIeKBXq4UuInJEpAO9qkxfioqIDIl4oCfVQhcRCUQ70IMul3xedy0SEYl0oFcHIy72DKqVLiIyYaCbWaOZ3W9mz5jZJjP71BjrmJndaGbbzGyjmZ0zNeWONDSei7pdREQm10LPAp9191XA+cAnzWzVqHUuA1YEj3XAN4pa5Tg0hK6IyMsmDHR33+fujwfTXcBmYMmo1a4AvucFDwO1Zrao6NWOMq+yDID7trRO9VuJiMx4r6gP3cyagLOBR0YtWgLsGvZ8N0eHftG9blkdbz9jAdf/egvb27qn+u1ERGa0SQe6mVUBdwCfdvfO43kzM1tnZi1m1tLW1nY8LzFCLGZ8Ys2p5B2eb+s54dcTEYmySQW6mSUphPkP3P1nY6yyB2gc9nxpMG8Ed7/F3ZvdvbmhoeF46j3K3IoUAO29g0V5PRGRqJrMWS4G3ApsdvcbxlntLuDvgrNdzgc63H1fEescV21l4VZ0h3t15yIRmd0Sk1jnQuAq4C9m9mQw75+AkwDc/WbgHuByYBvQC3yk+KWOrbosQSJmaqGLyKw3YaC7+58Am2AdBz5ZrKJeCTOjtiJJu1roIjLLRfpK0SG1FSkOq4UuIrNcSQT63IqkulxEZNYriUAvtNDV5SIis1tJBLpa6CIiJRPoKdp7MxS+mxURmZ1KItBrK1IMZvP0ZXJhlyIiEpqSCPS5FYWLi3TqoojMZiUR6LVDl//3qB9dRGavkgj0pXPLAbh747SMNiAiMiOVRKCfuaSGtec2cvMft/P0no6wyxERCUVJBDrAJ9acCsAze49rZF8RkcgrmUBfVJsmZrCrvTfsUkREQlEygZ6Mx1hUU86uQwp0EZmdSibQARrrytnV3hd2GSIioSitQJ9boRa6iMxapRXodRW0dg3QrytGRWQWKrFAL5yPvlvdLiIyC5VUoJ9UVwHAjrbukCsREZl+JRXoZyyuoTwZ54Hn2sIuRURk2pVUoKeTcS5aUc/9W9o0lK6IzDolFegAF58+nz2H+9iyvyvsUkREplXJBfq5y+oADQEgIrPPhIFuZt8xs1Yze3qc5WvMrMPMngwenyt+mZO3pLZwpsu+Dp3pIiKzS2IS63wXuAn43jHWedDd31mUik5QOhmnrjLF3o7+sEsREZlWE7bQ3f0B4NA01FI0i2rS7DusFrqIzC7F6kO/wMyeMrNfmdkZ461kZuvMrMXMWtrapu7UwkU15exTC11EZpliBPrjwMnufhbwNeAX463o7re4e7O7Nzc0NBThrce2uDbNXrXQRWSWOeFAd/dOd+8Opu8BkmZWf8KVnYBFNeV09mfpGciGWYaIyLQ64UA3s4VmZsH0ecFrHjzR1z0Ri2vTgM50EZHZZcKzXMzsNmANUG9mu4HrgCSAu98MXAl83MyyQB+w1kO+THNx7cuDdJ06vzrMUkREps2Ege7uH5hg+U0UTmucMU5bUE0qEeO+La2sWTk/7HJERKZFyV0pClBTnuQdr17Ez5/YQ9+gxkYXkdmhJAMd4P3nNtLVn+X+ra1hlyIiMi1KNtBXN9ZiBls1SJeIzBIlG+jpZJylc8vZcaAn7FJERKZFyQY6wCn1Vbp7kYjMGiUd6MsbqtjR1kM+r5tdiEjpK+lAP6Whkr5Mjv2dGtdFREpfyQc6wI429aOLSOkr6UBfuaBwlegz+zpCrkREZOqVdKDPqyqjaV4FLTvbwy5FRGTKlXSgA5xz8lw2vNBOyMPLiIhMuZIP9OaT6zjYM8gLB3vDLkVEZEqVfKCf2zQXgIe2hzqir4jIlCv5QD91fhXLGyr5+RO7wy5FRGRKlXygmxlXvraRx3a2s1PDAIhICSv5QAd479lLALh7496QKxERmTqzItAX1qR59ZIa/rC1LexSRESmzKwIdIA1Kxt4/MV2DvcOhl2KiMiUmEWBPp+8wwPPHQi7FBGRKTFrAn11Yy31VWX8cuNebrj3WbZrWF0RKTGzJtDjMePyVy/kN5te4sbfP8dN920LuyQRkaKaNYEO8M7XLD4yndMY6SJSYiYMdDP7jpm1mtnT4yw3M7vRzLaZ2UYzO6f4ZRZH88lz+cwlp7G4Js2udg0FICKlZTIt9O8Clx5j+WXAiuCxDvjGiZc1NWIx45qLV/CmlQ3sOtTL3Rv3sq+jL+yyRESKYsJAd/cHgEPHWOUK4Hte8DBQa2aLilXgVGisq+BA9yBX//AJbvy9+tJFpDQUow99CbBr2PPdwbyjmNk6M2sxs5a2tvAu8jmpruLI9B+2tmpoXREpCdP6pai73+Luze7e3NDQMJ1vPcLwQN/X0c/Wl7pCq0VEpFiKEeh7gMZhz5cG82asoUC/ZNUCAG5/dNexVhcRiYREEV7jLuBqM7sdeB3Q4e77ivC6U6a2IsVX37+aC5bPY351Gd99aCerG2t5z9lj9hSJiETChIFuZrcBa4B6M9sNXAckAdz9ZuAe4HJgG9ALfGSqii2mofC+7l1nsK21m3+8YyM15UnefPr8kCsTETk+FtYXgs3Nzd7S0hLKe492qGeQK29+iB1tPVx72em877VLqSxLkE7Gwy5NRGQEM9vg7s1jLZtVV4qOp64yxT3XvIE3rKjnm3/czsU3/JHr7twUdlkiIq+IAj2QTsb5+JuW096b4XBvhrs37qVvMMfdG/fy6PPHOg1fRGRmUKAPc8HyeVz52qWsPbeRnsEcP9mwi8/8+Cn+/rbH6c/kwi5PROSYinGWS8kwM770vrPI550HnzvAv939DJmc81LnAOsf2smLh3pJJWJc964zwi5VROQoCvQxxGLGV9eu5oPfepjzltWRisf41oM7ONQzSN7hwuX1vDU4h11EZKZQl8s4zm2q485PXsRNHzybqy44mQPdhTBfUlvODfc+O2LdfN41HK+IhE6BfgyrFs9hfnWai0+fz6KaNOc2zeUjFzbxzL5Onj/Qc2S9f7xjI3/77YdDrFRERF0uk5KIx/jRugtIJ2Nk884XfrmZN3/pD1x72el8+PVN/HLjPvoyOX72+G4A/uqcpSFXLCKzkQJ9kk6a9/KAXq9fPo+Hth/kP369BQP6gjNgPvPjpyhPxlmzcj79mRyLa8tDqlZEZiNdKXoc+gZzHOge4LL//SA9g1mqUgnmlCfZc7hws4wFc8ro6s9y5ycvZMWC6pCrFZFScqwrRdVCPw7lqTiNdRV87YNn84sn9nDBKfOImfFcaxc/eORFXuocwAyuuf1J7rnmIsws7JJFZBZQoJ+AN6+cz5tXjhzMa3d7Hw9tP8jVbz6VL96zmW89uIP+TJ5rLl4RUpUiMlso0Ivsi+99NV39Geakk1z/6y38+z1bAPjQ65uoKU+GXJ2IlDKdtlhkdZUpTp5XydzKFG887eW7Mm3cfTjEqkRkNlCgT6Hr3rWKGz9wNmbwxIsKdBGZWgr0KXTyvErefdZiljdUccO9z/KBWx4mm8uHXZaIlCgF+jR41aI5APx5x0Ee3HYg5GpEpFQp0KfB/3zHq/jmVa9lbkWSn27Yzd0b9/I33/wzA1kNySsixaOzXKbB/Dlp3n7GQh7ZcYj1f97JA1vb6BrI8ttNL/GusxaHXZ6IlAi10KfRpy9ZwerGWvqzOeqrUtz26IthlyQiJUQt9Gk0J53kh//ldbR1DfDzx/fw5XufZV9HH4tqNOaLiJy4SbXQzexSM9tqZtvM7Noxln/YzNrM7Mng8Z+LX2ppKEvEWTq3gkvPXAjA7ze3hlyRiJSKCQPdzOLA14HLgFXAB8xs1Rir/sjdVwePbxe5zpJz6vwqTqqr4H/84mned/NDdA9kwy5JRCJuMi3084Bt7r7D3QeB24Erpras0mdmvPG0egAe29nOfVtadSNqETkhkwn0JcCuYc93B/NG+2sz22hmPzWzxrFeyMzWmVmLmbW0tbUdR7ml5dNvPY0vvOdM5leXcd2dT9P8hd+x61Bv2GWJSEQV6yyX/ws0uftrgHuB9WOt5O63uHuzuzc3NDSMtcqsUl9Vxn86/2QuO3Mh7b0Zugey/GTD7rDLEpGImkyg7wGGt7iXBvOOcPeD7j4QPP028NrilDc7/Nc1y/nUxSs4/5Q67tiwW10vInJcJhPojwErzGyZmaWAtcBdw1cws0XDnr4b2Fy8Ekvfoppy/uGS0/johcvYc7iPi66/nyu/8RAvHlT3i4hM3oSB7u5Z4GrgNxSC+sfuvsnMPm9m7w5Wu8bMNpnZU8A1wIenquBS9rYzFvL9j53H65bVsfWlLj7xww0aHkBEJk33FJ2hfrtpP+u+v4G/f8upfPZtK3F33cpORHRP0Sh62xkL+atzlvCNP2ynLBHjuw+9wJf/5izedJq+TBaRsWkslxnsuneewaLaNF/67bMc6B7gmtueYF9HX9hlicgMpUCfwWoqktxyVTNvfdV8/s9HzqVvMMdX730u7LJEZIZSl8sM96pFc/j2h84F4G/PP4n1D+3kYM8A//yOVSyrrwy5OhGZSdRCj5Br3rKCK1Yv4dHnD/Gx9Y/x7Qd30NGbCbssEZkhFOgRMrcyxVfev5pvXtVMa+cAX/jlZj66/jH6BnVqo4go0CPpguXzeOJzl/D1D57D4y+2856v/z9u/dPzbG/rDrs0EQmRAj2ikvEY73jNItZ/5Dy6B7L8293PcPGX/8j/+tVmntnbSTaXD7tEEZlmurCoROw93MeNv3+O2x8rDIx50an1XHvZ6SysSVNfVRZydSJSLMe6sEiBXkLcnfu3trJlfxdf+s1W8sGuvezMhaxZ2cDrl9fTWFcRbpEickIU6LPQjrZunn2pm7/sOczNf9xBLu9UpxOsPbeRxroK1pw2n5PmKdxFokaBPsvt7+intaufL/5yM0/sOsxgNk8iZpzVWMuimjSLa8t5w4p6FtWkqa1IqYtGZAZToMsR+byz53Af6x/aydN7O9jf0c/ejn4Gs4UvUavKEvz1OUvI5J1MNs/5p8zj3KY6zFB3jcgMoECXYxrI5vjFE3sYzOb53eZWNrzQTioRI2bGge7CfUviMWPlgmqq0gk+/Pom5lWmqCxLML+60JqfPycd5iaIzBoKdDku+bxz+2O7ONg9wL7Ofna0dbPzQC/7O/tHrGcG5y+bx5zyBK1dAzRUlXHmkhpes7SGlQurqUglqClPsq+jjweebeM9Zy+hLBEPaatEok2BLkXTn8mxeV8nPQM5DvYM0N4zyIHuQf7wbCs9AzkW16bZd7ifHQd6RvxeTXmSTC5P72COZfWV1FWmKEvE2N3ex8fXLCebd55v6+Etp88nETcW15TT3jvIsoZKNu3ppKoswdK55aSTccpTOhjI7KVAl2nX2Z/h6d0dPH+wh96BHC8c6mEgk2f1SbXc+cRe4jGjoy9D3p0t+7sASMSMbH7iv8f6qjJWzK9if2c/C+aUsbpxLs++1EV5Kk7MjEU1aZrmVTKnvPDJIJt3qssShU8KFUlyOSeViLFgTpluGiKRo0CXGWswm+fhHQdpmlfJvKoUDz7XRjoZZ+/hfmrKk2zd38kZS2pwhz2H++jP5Hj+QA/PtXazoLqMvR19PLO3kyVzywEwjP0d/QxO4krZ+qoUdZUpegZyZHJ5YmaYFWqqKIuzcsEcuvozpBIxTqmvxIFs3snlnGzeKUvGOKmuAgPmBAcO3ClLxmnvGWRuZYq4GXWVKZLxGGaF7qnRYmY0zaukoizOkX+Owc/qdIJYTAcdeZkCXUraQDZHKh470toeyOZo78nQ0Vd4xGNGZ1+G/kyOQ72DxM3oz+R4em8nXf0ZKssSpOIx3CHvhdb7S50D7G7vZU46SddAlj3tvcRjRjwWIxEz4jGjeyBLR9/UjnaZSsRIxoxM3snlnXQiRlU6QXd/lljMmFuRojwZx6zwxXXMjJhBLJhOxIyyZJxUPEYybiTjMRJxI5d3DKitSJHLOzl38nkn737koJIYWj9W+N1E3EjF4yQTFrxejFjMyGTzpJNxKoMD0vMHelhSW05FWRzD6MvkCr8fi9HRl6EsEaM6nSCZiBE3G7Pu2LDtGbltEy+LmRGLGelkjFQ8RibnDGRzZHNe+J1YYZ148PvDf69w0J3ZB1Ddgk5K2ugvWMsScRbWxFlYM7Vn3rg7PYM53J3ugSyJWAzH6RvMMbcyRUdvhlzeOdQ7SC4/FJhHt9IzuTzPH+g5cuqomWEUDi5tXQNk837kINKfydPVn6EqncAd2nsHGcjkybnjXnj9XBDMeXcyOaejL8NgNk82lyeb98J1CEGod/RlgteOvRyGxpFPI5lcnmyu8DOTyzOJHrEZxQxeaZt1eMjb8IOE2ZGD39D+iAefnoYaAxT+w91JJmKkg7/NoQNmzgsH5o9euIx/uOS0Im+tAl3kuJkZVWWFf0LV6eRRy+cE85qY+EYkb1gRjXvF5oKQH8zlyWTz5PKFTzT9mTw9g1lyeeekugpaOwcYzOXI5aE8GSebL/zOnHThy/HOviyZfL4QcsGBzj34pOAc+bRwrGUj1htjWd9gloHg00NZIkY8ZkeC1z0I2WB66GCbH3ZgHHodH1ZHIl5oxefzhW63XHCEiwVH6aGDARQO1P2ZwtDWQ58ihn6+eknNlOwfBbqITFqhVRonnTz2mUYaViIckxo+18wuNbOtZrbNzK4dY3mZmf0oWP6ImTUVu1ARETm2CQPdzOLA14HLgFXAB8xs1ajVPga0u/upwFeA64tdqIiIHNtkWujnAdvcfYe7DwK3A1eMWucKYH0w/VPgYpvpXxWLiJSYyQT6EmDXsOe7g3ljruPuWaADmDf6hcxsnZm1mFlLW1vb8VUsIiJjmtZb0Ln7Le7e7O7NDQ3R+FZfRCQqJhPoe4DGYc+XBvPGXMfMEkANcLAYBYqIyORMJtAfA1aY2TIzSwFrgbtGrXMX8KFg+krgPg/rElQRkVlqwvPQ3T1rZlcDvwHiwHfcfZOZfR5ocfe7gFuB75vZNuAQhdAXEZFpFNpYLmbWBrxwnL9eDxwoYjlh0rbMTNqWmUnbAie7+5hfQoYW6CfCzFrGG5wmarQtM5O2ZWbSthzbtJ7lIiIiU0eBLiJSIqIa6LeEXUARaVtmJm3LzKRtOYZI9qGLiMjRotpCFxGRURToIiIlInKBPtHY7DOdme00s7+Y2ZNm1hLMqzOze83sueDn3LDrHIuZfcfMWs3s6WHzxqzdCm4M9tNGMzsnvMqPNs62/IuZ7Qn2zZNmdvmwZf892JatZvb2cKo+mpk1mtn9ZvaMmW0ys08F8yO3X46xLVHcL2kze9TMngq25V+D+cuCe0ZsC+4hkQrmF+eeEh7ccikKDwpXqm4HTgFSwFPAqrDreoXbsBOoHzXvP4Brg+lrgevDrnOc2t8InAM8PVHtwOXArwADzgceCbv+SWzLvwD/bYx1VwV/a2XAsuBvMB72NgS1LQLOCaargWeDeiO3X46xLVHcLwZUBdNJ4JHg//ePgbXB/JuBjwfTnwBuDqbXAj86nveNWgt9MmOzR9Hw8eTXA+8JsZZxufsDFIZ2GG682q8AvucFDwO1ZrZoeiqd2DjbMp4rgNvdfcDdnwe2UfhbDJ2773P3x4PpLmAzheGsI7dfjrEt45nJ+8XdvTt4mgweDryFwj0j4Oj9csL3lIhaoE9mbPaZzoHfmtkGM1sXzFvg7vuC6f3AgnBKOy7j1R7VfXV10BXxnWFdX5HYluBj+tkUWoOR3i+jtgUiuF/MLG5mTwKtwL0UPkEc9sI9I2BkvZO6p8REohbopeAidz+Hwi39Pmlmbxy+0AufuSJ5LmmUaw98A1gOrAb2AV8Ot5zJM7Mq4A7g0+7eOXxZ1PbLGNsSyf3i7jl3X01hyPHzgNOn+j2jFuiTGZt9RnP3PcHPVuDnFHb0S0Mfe4OfreFV+IqNV3vk9pW7vxT8I8wD3+Llj+8zelvMLEkhAH/g7j8LZkdyv4y1LVHdL0Pc/TBwP3ABhS6uoVFuh9dblHtKRC3QJzM2+4xlZpVmVj00DbwNeJqR48l/CLgznAqPy3i13wX8XXBWxflAx7AugBlpVF/yeynsGyhsy9rgTIRlwArg0emubyxBP+utwGZ3v2HYosjtl/G2JaL7pcHMaoPpcuASCt8J3E/hnhFw9H458XtKhP1t8HF8e3w5hW+/twP/HHY9r7D2Uyh8K/8UsGmofgp9Zb8HngN+B9SFXes49d9G4SNvhkL/38fGq53Ct/xfD/bTX4DmsOufxLZ8P6h1Y/APbNGw9f852JatwGVh1z+srosodKdsBJ4MHpdHcb8cY1uiuF9eAzwR1Pw08Llg/ikUDjrbgJ8AZcH8dPB8W7D8lON5X136LyJSIqLW5SIiIuNQoIuIlAgFuohIiVCgi4iUCAW6iEiJUKCLiJQIBbqISIn4//EyUjNMKObjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0IEPAcide5lS"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF8wPwoAo_xp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "7a3b9934-7e36-4435-afa6-a915b58ec10f"
      },
      "source": [
        "# testing model predict with seaborn and plots\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_noise():\n",
        "    input_image = np.full((28, 28), 0)\n",
        "\n",
        "    # Random noise\n",
        "    # input_image = np.random.rand(28, 28)\n",
        "    # input_image[input_image >= 0.5] = 1\n",
        "    # input_image[input_image < 0.5] = 0\n",
        "\n",
        "    input_image = input_image.astype(np.float32)\n",
        "    input_image = np.expand_dims(input_image, 0)\n",
        "    input_image = np.expand_dims(input_image, -1)\n",
        "    return input_image\n",
        "\n",
        "test_image = generate_noise()\n",
        "if is_grayscale:\n",
        "    softmax_predictions, sigmoid_predictions = model.predict(test_image)\n",
        "    softmax_predictions = softmax_predictions.reshape(28, 28)\n",
        "    softmax_predictions = np.exp(softmax_predictions)\n",
        "    softmax_predictions = softmax_predictions / np.sum(softmax_predictions)\n",
        "    sigmoid_predictions = sigmoid_predictions.reshape(28, 28)\n",
        "    heatmap = sb.heatmap(softmax_predictions)\n",
        "    plt.show()\n",
        "    heatmap = sb.heatmap(sigmoid_predictions)\n",
        "else:\n",
        "    softmax_predictions = model.predict(test_image)\n",
        "    softmax_predictions = softmax_predictions.reshape(28, 28)\n",
        "    softmax_predictions = np.exp(softmax_predictions)\n",
        "    softmax_predictions = softmax_predictions / np.sum(softmax_predictions)\n",
        "    heatmap = sb.heatmap(softmax_predictions)\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PBu4a18br7wL",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "\n",
        "def inference(model, input_image, directory, iterations, temp_start=2, temp_end=0.5, top_k=250, is_grayscale=True, is_debug=False):\n",
        "    create_image(input_image, \"{}/input.png\".format(directory))\n",
        "\n",
        "    temperatures = np.linspace(temp_end, temp_start, num=iterations)[::-1]\n",
        "    # pprint(temperatures)\n",
        "    \n",
        "    working_image = deepcopy(input_image)\n",
        "    working_images = []\n",
        "    num_added = 0\n",
        "    num_removed = 0\n",
        "    for i in range(iterations):\n",
        "        temp = temperatures[i]            \n",
        "        binary_image = deepcopy(working_image)\n",
        "        binary_image[binary_image > 0] = 1\n",
        "        if is_grayscale:\n",
        "            softmax_predictions, sigmoid_predictions = model.predict(binary_image)\n",
        "        else:\n",
        "            softmax_predictions = model.predict(binary_image)\n",
        "\n",
        "        softmax_predictions = softmax_predictions.flatten()\n",
        "        if is_grayscale:\n",
        "            sigmoid_predictions = sigmoid_predictions.flatten()\n",
        "\n",
        "        softmax_predictions = np.exp(softmax_predictions / temp)\n",
        "        softmax_predictions = softmax_predictions / np.sum(softmax_predictions)\n",
        "        softmax_predictions = np.nan_to_num(softmax_predictions)\n",
        "        # print(softmax_predictions)\n",
        "        # print(softmax_predictions[-1])\n",
        "        indices = np.arange(softmax_predictions.shape[0])\n",
        "\n",
        "        zipped = zip(softmax_predictions, indices)\n",
        "        zipped = list(reversed(sorted(zipped, key = lambda x : x[0])))\n",
        "        zipped = zipped[:top_k]\n",
        "        zipped = sorted(zipped, key=lambda x : x[1])\n",
        "        softmax_predictions, indices = zip(*zipped)\n",
        "        softmax_predictions = np.asarray(softmax_predictions)\n",
        "        softmax_predictions = softmax_predictions / np.sum(softmax_predictions)\n",
        "        indices = np.asarray(indices)\n",
        "\n",
        "        index = np.random.choice(indices, p=softmax_predictions)\n",
        "        working_image = working_image.flatten()\n",
        "        # if index == softmax_predictions.shape[0]:\n",
        "        #     print(\"stopping\")\n",
        "            # break\n",
        "        if is_grayscale:\n",
        "            if working_image[index] != 0:\n",
        "                num_removed += 1\n",
        "            elif working_image[index] == 0:\n",
        "                num_added += 1\n",
        "            working_image[index] = sigmoid_predictions[index]\n",
        "        else:\n",
        "            if working_image[index] == 1:\n",
        "                num_removed += 1\n",
        "                working_image[index] = 0\n",
        "            elif working_image[index] == 0:\n",
        "                num_added += 1\n",
        "                working_image[index] = 1\n",
        "            else:\n",
        "                print(working_image[index])\n",
        "        working_image = np.reshape(working_image, [1, *image_shape])\n",
        "        if i % 10 == 0:\n",
        "            if is_debug:\n",
        "                print(\"softmax\")\n",
        "                softmax_predictions = softmax_predictions.reshape(28, 28)\n",
        "                heatmap = sb.heatmap(deepcopy(softmax_predictions))\n",
        "                plt.show()\n",
        "                print(\"sigmoid\")\n",
        "                sigmoid_predictions = sigmoid_predictions.reshape(28, 28)\n",
        "                heatmap = sb.heatmap(deepcopy(sigmoid_predictions))\n",
        "                plt.show()\n",
        "            create_image(working_image, os.path.join(directory, \"working_{}.png\".format(i)))\n",
        "\n",
        "    final_image = working_image\n",
        "    final_binary_image = deepcopy(final_image)\n",
        "    final_binary_image[final_binary_image > 0] = 1\n",
        "    create_image(final_binary_image, os.path.join(directory, \"final_binary.png\"))\n",
        "\n",
        "    print(final_image.shape)\n",
        "    print(\"num added: {}. num removed: {}\".format(num_added, num_removed))\n",
        "    img = create_image(final_image, os.path.join(directory, \"final.png\"))\n",
        "    return img, deepcopy(final_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJjq3kNqJCOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC6ZVFAFeqBb",
        "colab_type": "code",
        "outputId": "3be9fff1-33a4-432c-cb40-5a68e8104998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "generated_images = []\n",
        "\n",
        "# model = keras.models.load_model(model_location)\n",
        "\n",
        "sample_sqrt = 1\n",
        "for i in range(sample_sqrt**2):\n",
        "    directory = \"images_{}\".format(i)\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    input_image = generate_noise()\n",
        "    # input_image = np.expand_dims(np.expand_dims(images[i], 0), -1)\n",
        "\n",
        "    img, _ = inference(model, input_image, directory, 200, temp_start=0.99, temp_end=0.99, top_k=1000, is_grayscale=is_grayscale, debug=True)\n",
        "    generated_images.append(img)\n",
        "    \n",
        "final_im = Image.new('RGB', (28 * sample_sqrt, 28 * sample_sqrt))\n",
        "\n",
        "y_offset = 0\n",
        "for i in range(sample_sqrt):\n",
        "    x_offset = 0\n",
        "    new_im = Image.new('RGB', (28 * sample_sqrt, 28))\n",
        "    for j in range(sample_sqrt):\n",
        "        im = generated_images[(i * sample_sqrt) + j]\n",
        "        new_im.paste(im, (x_offset, 0))\n",
        "        x_offset += 28\n",
        "    final_im.paste(new_im, (0, y_offset))\n",
        "    y_offset += 28\n",
        "    \n",
        "final_im.save('final.png')"
      ],
      "execution_count": 393,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 28, 28, 1)\n",
            "num added: 164. num removed: 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DF783hh7cg_P"
      },
      "source": [
        "## Train Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW-M3GAmeqBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterations = 500\n",
        " \n",
        "generated_samples = []\n",
        "for i in range(int(len(training_samples) / 2)):\n",
        "    directory = \"discriminator\"\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    input_image = generate_noise()\n",
        "\n",
        "    _, generated = inference(model, input_image, directory, iterations, temp_start=1, temp_end=1)\n",
        "    generated_samples.append(generated)\n",
        "\n",
        "print(len(generated_samples))\n",
        "original_gen_samples = deepcopy(generated_samples)\n",
        "generated_samples = np.asarray(generated_samples)\n",
        "print(generated_samples.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2tqKYqmJ3uJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_samples = np.random.rand(int(len(training_samples) / 2), *image_shape)\n",
        "random_samples[random_samples >= 0.5] = 1\n",
        "random_samples[random_samples < 0.5] = 0\n",
        "\n",
        "generated_samples = generated_samples.reshape(-1, *image_shape)\n",
        "images = training_samples\n",
        "images = np.expand_dims(images, axis=-1)\n",
        "\n",
        "discriminator_train_x = np.concatenate((generated_samples, random_samples, images), axis=0)\n",
        "print(generated_samples.shape)\n",
        "print(random_samples.shape)\n",
        "print(images.shape)\n",
        "discriminator_train_y = np.concatenate((np.full((generated_samples.shape[0], 1), 0), \n",
        "                                        np.full((random_samples.shape[0], 1), 0),\n",
        "                                        np.full((images.shape[0], 1), 1)), \n",
        "                                        axis=0)\n",
        "\n",
        "print(discriminator_train_x.shape)\n",
        "print(discriminator_train_y.shape)\n",
        "\n",
        "\n",
        "p = np.random.permutation(len(discriminator_train_x))\n",
        "discriminator_train_x, discriminator_train_y = discriminator_train_x[p], discriminator_train_y[p]\n",
        "print(discriminator_train_x.shape)\n",
        "print(discriminator_train_y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PVue6Y9M0Ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Flatten, Dense, Reshape\n",
        "\n",
        "def discriminator(input_size=(28, 28, 1), n_filters_start=16, growth_factor=2, num_layers=1):\n",
        "    inputs = Input(input_size)\n",
        "    droprate = 0.5\n",
        "    n_filters = n_filters_start\n",
        "    prev_layer = inputs\n",
        "    for _ in range(num_layers):\n",
        "        batch_norm = BatchNormalization()(prev_layer)\n",
        "        conv = Conv2D(n_filters, kernel_size=(3, 3), strides=(2,2), activation='relu', padding='same')(batch_norm)\n",
        "        drop_layer = Dropout(droprate)(conv)\n",
        "        prev_layer = drop_layer\n",
        "        n_filters *= growth_factor\n",
        "\n",
        "    flatten = Flatten()(prev_layer)\n",
        "    # reshape_layer = Reshape((-1, 512))(prev_layer)\n",
        "    validity = Dense(1, activation='sigmoid')(flatten)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=validity)\n",
        "    model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNM3mo1NJeub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator_model = discriminator(input_size=image_shape)\n",
        "model_location = F'/content/drive/My Drive/sc-discrim-model.hdf5'\n",
        "\n",
        "# model = keras.models.load_model(model_location)\n",
        "\n",
        "discrim_batch_size = 64\n",
        "\n",
        "steps_per_epoch = int(len(discriminator_train_x) * split / discrim_batch_size)  \n",
        "validation_steps = int(len(discriminator_train_x) * (1 - split) / discrim_batch_size)  \n",
        "\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_location,\n",
        "    monitor='val_loss',\n",
        "    save_weights_only=False,\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir='./logs', update_freq='epoch')\n",
        "\n",
        "if True:\n",
        "    discrim_history = discriminator_model.fit(\n",
        "        x=discriminator_train_x,\n",
        "        y=discriminator_train_y,\n",
        "        batch_size=discrim_batch_size,\n",
        "        validation_split=split,\n",
        "        verbose=1,\n",
        "        shuffle=True,\n",
        "        epochs=100,\n",
        "        callbacks=[model_checkpoint_callback, tensorboard_callback])\n",
        "    #epochs=cfg.epochs,\n",
        "    #callbacks=callbacks)\n",
        "# model.save(\"sc-model.hdf5\")\n",
        "if True:\n",
        "    plt.plot(discrim_history.history['loss'])\n",
        "    plt.plot(discrim_history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz7XvYS3pduE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference_with_discriminator(model, discrim_model, input_image, directory, iterations, temp_low=0.5, temp_high=2):\n",
        "    create_image(input_image, \"{}/input.png\".format(directory))\n",
        "\n",
        "    # pprint(temperatures)\n",
        "    \n",
        "    working_image = deepcopy(input_image)\n",
        "    consecutive = 0\n",
        "    for i in range(iterations):\n",
        "        discrim_predict = discrim_model.predict(working_image)[0]\n",
        "        if discrim_predict >= 0.95:\n",
        "            consecutive += 1\n",
        "            if consecutive >= 100:\n",
        "                break\n",
        "        else:\n",
        "            consecutive = 0\n",
        "\n",
        "        temp = temp_low + ((temp_high - temp_low) * (1 - discrim_predict))\n",
        "        \n",
        "        print(\"temp: {}\".format(temp))\n",
        "        predictions = model.predict(working_image)\n",
        "        predictions = predictions.flatten()\n",
        "        predictions = np.exp(predictions / temp)\n",
        "        predictions = predictions / np.sum(predictions)\n",
        "        # print(predictions)\n",
        "        indices = np.arange(predictions.shape[0])\n",
        "        index = np.random.choice(indices, p=predictions)\n",
        "        working_image = working_image.flatten()\n",
        "        if working_image[index] == 1:\n",
        "            working_image[index] = 0\n",
        "        elif working_image[index] == 0:\n",
        "            working_image[index] = 1\n",
        "        else:\n",
        "            print(working_image[index])\n",
        "        working_image = np.reshape(working_image, [1, *image_shape])\n",
        "        if i % 100 == 0:\n",
        "            create_image(working_image, os.path.join(directory, \"working_{}.png\".format(i)))\n",
        "\n",
        "    print(working_image.shape)\n",
        "    img = create_image(working_image, os.path.join(directory, \"final.png\"))\n",
        "    return img, deepcopy(working_image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NR7vdWxukd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_images = []\n",
        "\n",
        "sample_sqrt = 1\n",
        "for i in range(sample_sqrt**2):\n",
        "    directory = \"images_discrim_{}\".format(i)\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    # input_image = images[0]\n",
        "    # input_image = np.expand_dims(input_image, 0)\n",
        "\n",
        " \n",
        "    img, _ = inference_with_discriminator(model, discriminator_model, input_image, directory, 10000)\n",
        "    generated_images.append(img)\n",
        "    \n",
        "final_im = Image.new('RGB', (28 * sample_sqrt, 28 * sample_sqrt))\n",
        "\n",
        "y_offset = 0\n",
        "for i in range(sample_sqrt):\n",
        "    x_offset = 0\n",
        "    new_im = Image.new('RGB', (28 * sample_sqrt, 28))\n",
        "    for j in range(sample_sqrt):\n",
        "        im = generated_images[(i * sample_sqrt) + j]\n",
        "        new_im.paste(im, (x_offset, 0))\n",
        "        x_offset += 28\n",
        "    final_im.paste(new_im, (0, y_offset))\n",
        "    y_offset += 28\n",
        "    \n",
        "final_im.save('final_with_discrim.png')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}