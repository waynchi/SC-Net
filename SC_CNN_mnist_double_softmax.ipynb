{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SC_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waynchi/SC-Net/blob/master/SC_CNN_mnist_double_softmax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U22qZkbsfEyI",
        "colab_type": "code",
        "outputId": "2673bf1d-8f26-4150-b6d1-bdca9f8ad6cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install mnist\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mnist in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mnist) (1.18.5)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45bLorRNFfdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LsQqrsgeqA1",
        "colab_type": "code",
        "outputId": "6138f5f1-f18c-403b-9825-8e1e1de84bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.is_gpu_available()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 462
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VxF9dG1KU6Mf"
      },
      "source": [
        "# What about a GAN + Self correcting U-Net ? That would make for a cool architecture\n",
        "# Following CGAN -> adding a 1-hot vector encoding of the label to the training data\n",
        "# Simulated Annealing?\n",
        "# Generator -> VAE -> Discriminator?\n",
        "# What about feeding in a dicriminator's confidence level as a temperature during the autoregressive? Inverse confidence?\n",
        "# What about a 3 dimensional GAN?\n",
        "# What about adding attention to the model?\n",
        "\n",
        "# Umut Notes\n",
        "- Add a stop condition to the softmax\n",
        "    - Tried both 2 outputs and just an extra variable to the softmax\n",
        "    - 2 outputs fails due to it having too much weight to the loss and the loss fluctuates like crazy\n",
        "    - extra variable fails as the probability is still small even for an original image. Not sure why. Maybe because each time wew generate we use a new random which causes the dataset to be imbalanced?\n",
        "- 2 steps process (pick note and then choose how much through binary cross entropy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OeM4sX2NNYT0",
        "outputId": "927d7de1-5822-4759-ed05-eb8b3a6b706a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import mnist\n",
        "import scipy.misc\n",
        "from PIL import Image\n",
        "from pprint import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "\n",
        "def make_grayscale(data, dtype=np.float32):\n",
        "    # luma coding weighted average in video systems\n",
        "    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\n",
        "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\n",
        "    # add channel dimension\n",
        "    rst = np.expand_dims(rst, axis=3)\n",
        "    rst = rst.astype(np.uint8)\n",
        "    return rst\n",
        "\n",
        "def create_image(image, name, image_shape=(32, 32), is_grayscale=True):\n",
        "    img_arr = deepcopy(image.reshape(image_shape)).astype(np.uint8)\n",
        "\n",
        "    img = Image.fromarray(img_arr.astype(np.uint8), 'L')\n",
        "    # pprint(img_arr)\n",
        "    # print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "    img.save(name)\n",
        "    return img\n",
        "\n",
        "is_single = False\n",
        "is_grayscale = True\n",
        "is_cifar_10 = False\n",
        "\n",
        "if is_single:\n",
        "    num_samples = 8\n",
        "else:\n",
        "    num_samples = 60000\n",
        "\n",
        "if is_cifar_10:\n",
        "    (images, labels), (_, _) = cifar10.load_data()\n",
        "    images = make_grayscale(images)\n",
        "else:\n",
        "    images = mnist.train_images()\n",
        "\n",
        "    # np.random.shuffle(images)\n",
        "images = images[:num_samples, :, :]\n",
        "\n",
        "\n",
        "if not is_grayscale:\n",
        "    # For black and white\n",
        "    images[images > 0] = 1\n",
        "    # images = images / 255.0\n",
        "\n",
        "# pprint(images)\n",
        "print(images.shape)\n",
        "\n",
        "# labels = mnist.train_labels()\n",
        "# n_labels = np.max(labels) + 1\n",
        "# labels = np.eye(n_labels)[labels]\n",
        "# print(labels.shape)\n",
        "\n",
        "if is_cifar_10:\n",
        "    image_shape = images[0].shape\n",
        "else:\n",
        "    image_shape = np.expand_dims(images[0], axis=-1).shape \n",
        "\n",
        "print(images[0])\n",
        "create_image(images[0], 'my.png', image_shape=image_shape[:-1], is_grayscale=is_grayscale)\n",
        "print(image_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "(28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIaOI3kjQB60",
        "colab_type": "code",
        "outputId": "3a425e74-153a-493d-f898-e70b429b9756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "def to_one_hot(arr):\n",
        "    arr = deepcopy(arr)\n",
        "    arr = arr.astype(np.uint8)\n",
        "    n_values = 256\n",
        "    one_hot = np.eye(n_values)[arr]\n",
        "    one_hot = one_hot.astype(np.uint8)\n",
        "    return one_hot\n",
        "\n",
        "one_hot = to_one_hot(images[0])\n",
        "print(one_hot.shape)\n",
        "\n",
        "argmax_res = np.argmax(one_hot, axis=-1)\n",
        "print(argmax_res)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 256)\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OlmEDomwi9dZ",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Flatten, Dense, Softmax, Reshape, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "def built_in_softmax_kl_loss(target, output):\n",
        "    target = K.flatten(target)\n",
        "    output = K.flatten(output)\n",
        "    \n",
        "    target = target / K.sum(target)\n",
        "    output = K.softmax(output)\n",
        "    return keras.losses.kullback_leibler_divergence(target, output)\n",
        "\n",
        "keras.losses.built_in_softmax_kl_loss = built_in_softmax_kl_loss\n",
        "\n",
        "def conv_layer(n_filters, filter_size, conv):\n",
        "    conv = Conv2D(n_filters, filter_size, activation='relu', padding='same')(conv)\n",
        "    conv = Conv2D(n_filters, filter_size, activation='relu', padding='same')(conv)\n",
        "    conv = Conv2D(n_filters, filter_size, activation='relu', padding='same')(conv)\n",
        "    return conv\n",
        " \n",
        "def unet_model(input_size=(28, 28, 1), n_filters_start=32, growth_factor=2,\n",
        "               upconv=False, is_grayscale=True, num_sub_layers=3):\n",
        "    droprate=0.5\n",
        "    n_filters = n_filters_start\n",
        "    inputs = Input(input_size)\n",
        "    conv_first = conv_layer(n_filters, (3, 3), inputs)\n",
        "    pool_first = MaxPooling2D(pool_size=(2, 2))(conv_first)\n",
        "\n",
        "    prev_pool = pool_first\n",
        "    hidden_layers = []\n",
        "    for _ in range(1):\n",
        "        n_filters *= growth_factor\n",
        "        pool = BatchNormalization()(prev_pool)\n",
        "        conv = conv_layer(n_filters, (3, 3), pool)\n",
        "        pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
        "        pool = Dropout(droprate)(pool)\n",
        "        prev_pool = pool\n",
        "        hidden_layers.append(conv)\n",
        " \n",
        "    n_filters *= growth_factor\n",
        "    conv_mid = conv_layer(n_filters, (3, 3), prev_pool)\n",
        " \n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up_first = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv_mid), hidden_layers[-1]])\n",
        "    else:\n",
        "        up_first = concatenate([UpSampling2D(size=(2, 2))(conv_mid), hidden_layers[-1]])\n",
        "    up_first = BatchNormalization()(up_first)\n",
        "    conv_mid_2 = conv_layer(n_filters, (3, 3), up_first)\n",
        "    conv_mid_2 = Dropout(droprate)(conv_mid_2)\n",
        "\n",
        "    prev_conv = conv_mid_2\n",
        "    for i in range(0):\n",
        "        n_filters //= growth_factor\n",
        "        if upconv:\n",
        "            up = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(prev_conv), hidden_layers[-i-2]])\n",
        "        else:\n",
        "            up = concatenate([UpSampling2D(size=(2, 2))(prev_conv), hidden_layers[-i-2]])\n",
        "        up = BatchNormalization()(up)\n",
        "        conv = conv_layer(n_filters, (3, 3), up)\n",
        "        conv = Dropout(droprate)(conv)\n",
        "        prev_conv = conv\n",
        " \n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up_last = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv_mid_2), conv_first])\n",
        "    else:\n",
        "        up_last = concatenate([UpSampling2D(size=(2, 2))(conv_mid_2), conv_first])\n",
        "    conv_last = conv_layer(n_filters, (3, 3), up_last)\n",
        " \n",
        "    softmax_out = Conv2D(1, 1, activation='linear', name='softmax_out')(conv_last)\n",
        "\n",
        "    if is_grayscale:\n",
        "        sigmoid_out = Conv2D(256, 1, padding='valid', name='sigmoid_out')(conv_last)\n",
        "        sigmoid_out = Reshape((*image_shape[:-1], 256))(sigmoid_out)\n",
        "        sigmoid_out = Activation('softmax')(sigmoid_out)\n",
        "        # sigmoid_out = Flatten()(conv_last)\n",
        "        # sigmoid_out = Dense(np.prod(input_size), activation='sigmoid')(sigmoid_out)\n",
        "        # sigmoid_out = Reshape(input_size)(sigmoid_out)\n",
        "        model = Model(inputs=inputs, outputs=[softmax_out, sigmoid_out])\n",
        "        model.compile(optimizer=Adam(lr=0.001), loss=[built_in_softmax_kl_loss, 'categorical_crossentropy'], metrics=['accuracy'])\n",
        "    else:\n",
        "        model = Model(inputs=inputs, outputs=softmax_out)\n",
        "        model.compile(optimizer=Adam(), loss=built_in_softmax_kl_loss)\n",
        "\n",
        "    # model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rSjQr52iQzlu",
        "outputId": "2352bf89-c2f7-410b-84f4-8eeb723c7676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = unet_model(input_size=image_shape, is_grayscale=is_grayscale)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_52\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_52 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_766 (Conv2D)             (None, 28, 28, 32)   320         input_52[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_767 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_766[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_768 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_767[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_103 (MaxPooling2D (None, 14, 14, 32)   0           conv2d_768[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 14, 14, 32)   128         max_pooling2d_103[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_769 (Conv2D)             (None, 14, 14, 64)   18496       batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_770 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_769[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_771 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_770[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_104 (MaxPooling2D (None, 7, 7, 64)     0           conv2d_771[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_103 (Dropout)           (None, 7, 7, 64)     0           max_pooling2d_104[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_772 (Conv2D)             (None, 7, 7, 128)    73856       dropout_103[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_773 (Conv2D)             (None, 7, 7, 128)    147584      conv2d_772[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_774 (Conv2D)             (None, 7, 7, 128)    147584      conv2d_773[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_103 (UpSampling2D (None, 14, 14, 128)  0           conv2d_774[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_103 (Concatenate)   (None, 14, 14, 192)  0           up_sampling2d_103[0][0]          \n",
            "                                                                 conv2d_771[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 14, 14, 192)  768         concatenate_103[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_775 (Conv2D)             (None, 14, 14, 64)   110656      batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_776 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_775[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_777 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_776[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_104 (Dropout)           (None, 14, 14, 64)   0           conv2d_777[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_104 (UpSampling2D (None, 28, 28, 64)   0           dropout_104[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_104 (Concatenate)   (None, 28, 28, 96)   0           up_sampling2d_104[0][0]          \n",
            "                                                                 conv2d_768[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_778 (Conv2D)             (None, 28, 28, 32)   27680       concatenate_104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_779 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_778[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_780 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_779[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "sigmoid_out (Conv2D)            (None, 28, 28, 256)  8448        conv2d_780[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_52 (Reshape)            (None, 28, 28, 256)  0           sigmoid_out[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "softmax_out (Conv2D)            (None, 28, 28, 1)    33          conv2d_780[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 28, 28, 256)  0           reshape_52[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 720,257\n",
            "Trainable params: 719,809\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsFM5XMYeqBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBEdqEBxFqNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# discriminator_model = discriminator(input_size=image_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SVUVU8Kt_aCm",
        "colab": {}
      },
      "source": [
        "from copy import deepcopy\n",
        "import math\n",
        "import itertools\n",
        "import time\n",
        "import random\n",
        "\n",
        "def mask_image_with_noise(image, is_grayscale=True):\n",
        "    image = deepcopy(image)\n",
        "    sampling_percentage_mask = np.random.uniform(0, 100)\n",
        "    sampling_percentage_noise = np.random.uniform(0, 5)\n",
        "    non_zero = np.nonzero(image)\n",
        "    mask = np.full(len(non_zero[0]), False)\n",
        "    noise = np.full(len(non_zero[0]), False)\n",
        "    amount_to_mask = math.floor(len(non_zero[0]) * (sampling_percentage_mask / 100.0))\n",
        "    mask[:amount_to_mask] = True\n",
        "    amount_of_noise = math.floor(len(non_zero[0]) * (sampling_percentage_noise / 100.0))\n",
        "    noise[:amount_of_noise] = True\n",
        "    np.random.shuffle(mask)\n",
        "    np.random.shuffle(noise)\n",
        "    # pprint(mask1)\n",
        "    output_image = deepcopy(image)\n",
        "    xor_target = np.full(output_image.shape, False)\n",
        "\n",
        "    r1 = list(itertools.compress(non_zero[0], mask))\n",
        "    c1 = list(itertools.compress(non_zero[1], mask))\n",
        "    output_image[r1, c1] = 0\n",
        "    xor_target[r1, c1] = True\n",
        "\n",
        "    # There might be overlap but that is ok\n",
        "    r2 = list(itertools.compress(non_zero[0], noise))\n",
        "    c2 = list(itertools.compress(non_zero[1], noise))\n",
        "    random_values = np.random.uniform(0, 1, (len(r2), 1))\n",
        "    random_values *= 255\n",
        "    random_values = np.around(random_values)\n",
        "    random_values = random_values.astype(np.uint8)\n",
        "    # random_values /= 255\n",
        "    output_image[r2, c2] = random_values\n",
        "    xor_target[r2, c2] = True\n",
        "\n",
        "    return output_image, xor_target\n",
        "\n",
        "\n",
        "class ImageGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, sample_list, image_shape, batch_size, samples_per_data_item, stops_per_data_item, is_grayscale=True, seed=None):\n",
        "        print(\"sample_list: {}\".format(len(sample_list)))\n",
        "        self.sample_list = sample_list\n",
        "        self.image_shape = image_shape\n",
        "        self.batch_size = batch_size\n",
        "        self.samples_per_data_item = samples_per_data_item\n",
        "        self.stops_per_data_item = stops_per_data_item\n",
        "        self.is_grayscale = is_grayscale\n",
        "        self.sample_index = 0\n",
        "        self.seed = seed\n",
        "        self.dtype = np.uint8\n",
        "        # if self.seed is not None:\n",
        "        #     np.random.seed(self.seed)\n",
        "\n",
        "    def generate_training_pairs(self):\n",
        "        '''\n",
        "        Generates Training Pairs till @training_input / @training_target have @batch_size files.\n",
        "        '''\n",
        "        training_input = []\n",
        "        training_original = []\n",
        "        training_target = []\n",
        "        while len(training_input) < self.batch_size:\n",
        "            original_image = deepcopy(self.sample_list[self.sample_index])\n",
        "            original_image = original_image.reshape(self.image_shape)\n",
        "            binary_image = deepcopy(original_image)\n",
        "            binary_image[binary_image > 0] = 1\n",
        "            self.sample_index = (self.sample_index + 1) % len(self.sample_list)\n",
        "            # print(\"sample_list length: {}. sample_index: {}\".format(\n",
        "            #     len(self.sample_list), self.sample_index))\n",
        "            try:\n",
        "                # augment by adding and removing random values in the array\n",
        "\n",
        "                # Add random values\n",
        "                for _ in range(self.samples_per_data_item):\n",
        "                    original_image = original_image.astype(self.dtype)\n",
        "                    input_image, xor_target = mask_image_with_noise(original_image, is_grayscale=self.is_grayscale)\n",
        "\n",
        "                    input_image = input_image.astype(self.dtype)\n",
        "                    xor_target = xor_target.astype(self.dtype)\n",
        "\n",
        "                    training_input.append(deepcopy(input_image))\n",
        "                    training_original.append(to_one_hot(np.squeeze(original_image)))\n",
        "                    # training_original.append(deepcopy(original_image))\n",
        "                    training_target.append(deepcopy(xor_target))\n",
        "\n",
        "            except Exception as e:\n",
        "                print('Error generating input and target pair')\n",
        "                traceback.print_exc()\n",
        "        training_input = np.asarray(training_input)\n",
        "        training_target = np.asarray(training_target)\n",
        "        training_original = np.asarray(training_original)\n",
        "        return training_input, training_target, training_original\n",
        "\n",
        "    def save_image(self, img_arr, img_name):\n",
        "        # img_arr = img_arr.reshape(self.image_shape)\n",
        "        print(img_name)\n",
        "        print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "        img_arr = img_arr[:, :, 0]\n",
        "        print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "        print(img_arr)\n",
        "        #pprint(img_arr)\n",
        "        print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "        img = Image.fromarray(img_arr.astype(np.uint8), 'L')\n",
        "        img.save(img_name)\n",
        "\n",
        "    def get_random_training_pair(self):\n",
        "        training_input, training_target, training_original = self.generate_training_pairs()\n",
        "        print(\"training_input shape: {}\".format(training_input.shape))\n",
        "        index = random.randrange(0, len(training_input))\n",
        "        self.save_image(deepcopy(training_input[index]), 'training_input.png')\n",
        "        self.save_image(deepcopy(training_target[index]) * 255, 'training_target.png')\n",
        "        print(training_original.shape)\n",
        "        original_image = deepcopy(training_original[index])\n",
        "        original_image = np.argmax(original_image, axis=-1)\n",
        "        print(original_image.shape)\n",
        "        original_image = np.expand_dims(original_image, axis=-1)\n",
        "        self.save_image(original_image, 'training_original.png')\n",
        "\n",
        "    def generate_validation_samples(self):\n",
        "        old_batch_size = self.batch_size\n",
        "        self.batch_size = len(self.sample_list) * (self.samples_per_data_item + self.stops_per_data_item)\n",
        "        training_input, training_target, training_original = self.generate_training_pairs()\n",
        "        # training_input = np.asarray(self.training_input[:self.batch_size])\n",
        "        # training_target = np.asarray(self.training_target[:self.batch_size])\n",
        "        self.batch_size = old_batch_size\n",
        "        if self.is_grayscale:\n",
        "            return training_input, [training_target, training_original]\n",
        "        else:\n",
        "            return training_input, training_target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''Generates 1 batch of data'''\n",
        "        training_input, training_target, training_original = self.generate_training_pairs()\n",
        "        # training_input = np.asarray(self.training_input[:self.batch_size])\n",
        "        # training_target = np.asarray(self.training_target[:self.batch_size])\n",
        "        # self.training_input = self.training_input[self.batch_size:]\n",
        "        # self.training_target = self.training_target[self.batch_size:]\n",
        "        # print(\"training input sum: {}. target sum: {}\".format(training_input.sum(), training_target.sum()))\n",
        "        if is_grayscale:\n",
        "            return training_input, [training_target, training_original]\n",
        "        else:\n",
        "            return np.asarray(training_input), np.asarray(training_target)\n",
        "\n",
        "    def __len__(self):\n",
        "        '''Number of batches / epoch'''\n",
        "        # print(\"sample_list: {}. samples_per_data_item: {}, batch size: {}\".\n",
        "        #       format(len(self.sample_list), self.samples_per_data_item,\n",
        "        #              self.batch_size))\n",
        "        samples_to_generate = int(\n",
        "            (len(self.sample_list) * (self.samples_per_data_item + self.stops_per_data_item)) /\n",
        "            self.batch_size)\n",
        "        # print(\"samples to generate: {}\".format(samples_to_generate))\n",
        "        return samples_to_generate\n",
        "    \n",
        "    # def on_epoch_begin(self):\n",
        "    #     if self.seed is not None:\n",
        "    #         np.random.seed(self.seed)\n",
        "    #     else:\n",
        "    #         np.random.seed(time.time())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1zwLYew1a-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Config\n",
        "stops_per_data_item = 0\n",
        "if is_single:\n",
        "    batch_size = 8\n",
        "    samples_per_data_item = 1\n",
        "    split = 1\n",
        "else:\n",
        "    batch_size = 128\n",
        "    samples_per_data_item = 1\n",
        "    split = 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ngo7o_rw2TsK",
        "outputId": "31d68713-e966-402b-c97f-b3cddcfb65de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "training_samples = images[:int(len(images) * split)]\n",
        "validation_samples = images[int(len(images) * split):]\n",
        "\n",
        "print(\"training samples: {}. validation samples: {}\".format(len(training_samples), len(validation_samples)))\n",
        "\n",
        "steps_per_epoch = int(len(training_samples) * (samples_per_data_item + stops_per_data_item) / batch_size)\n",
        "print(\"steps per epoch: {}\".format(steps_per_epoch))\n",
        "\n",
        "# pprint(training_samples[0])\n",
        "\n",
        "training_generator = ImageGenerator(\n",
        "    sample_list=training_samples,\n",
        "    image_shape=image_shape,\n",
        "    batch_size=batch_size,\n",
        "    samples_per_data_item=samples_per_data_item,\n",
        "    stops_per_data_item=stops_per_data_item,\n",
        "    is_grayscale=is_grayscale)\n",
        "\n",
        "validation_generator = ImageGenerator(\n",
        "    sample_list=validation_samples,\n",
        "    image_shape=image_shape,\n",
        "    batch_size=batch_size,\n",
        "    samples_per_data_item=samples_per_data_item,\n",
        "    stops_per_data_item=stops_per_data_item,\n",
        "    is_grayscale=is_grayscale)\n",
        "\n",
        "validation_data = validation_generator.generate_validation_samples()\n",
        "\n",
        "# print(\"validation data input and target shape: {}\".format(validation_data[0].shape))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training samples: 54000. validation samples: 6000\n",
            "steps per epoch: 421\n",
            "sample_list: 54000\n",
            "sample_list: 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsbSXfJcezGC",
        "colab_type": "code",
        "outputId": "7b7f52ee-0dcb-477b-8b1a-329481c9d584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "training_generator.get_random_training_pair()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training_input shape: (128, 28, 28, 1)\n",
            "training_input.png\n",
            "img shape: (28, 28, 1). img sum: 16302\n",
            "img shape: (28, 28). img sum: 16302\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23  79 192\n",
            "    0 216  91   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 252   0\n",
            "  252 252   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 147 209 252 252   0\n",
            "  168  80  31   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  38 175   0   0 214   0  25\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 198 253 255 209  25   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 114 234 252   0  28   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  23 234   0 252   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  29 252   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 253 253 128   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 253 252 233   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 252 168   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 113   0 252 168   0   0  76 113 113   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 254 253 216   0   0   0   0   0   0\n",
            "  141   0   4   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 221   0 253 252 252 252   0\n",
            "  252   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 253   0 252   0 156   0  56 106   0\n",
            "    0 252   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 153   0   0 139   0   0   0   0   4\n",
            "    0   0 252 101   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  76   0 253 253   0   0   0   0   4\n",
            "    0 253 253 114   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  19   0 252   0   0   0  57 179\n",
            "  252 252   0  88   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  19   0 253 252 252 252 253\n",
            "    0 252   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 153 252   0   0   0\n",
            "    0  52   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "img shape: (28, 28). img sum: 16302\n",
            "training_target.png\n",
            "img shape: (28, 28, 1). img sum: 16320\n",
            "img shape: (28, 28). img sum: 16320\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  255   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 255 255   0 255\n",
            "    0   0 255   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 255   0   0   0   0 255\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 255 255   0 255   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 255   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 255   0 255   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 255 255   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 255   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 255   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 255 255   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 255   0   0   0   0   0   0   0 255\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 255   0   0   0 255 255 255 255 255 255\n",
            "    0 255   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 255 255 255 255 255   0   0   0   0 255\n",
            "    0 255 255   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 255   0 255   0 255   0   0 255\n",
            "  255   0 255   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 255 255   0   0   0   0   0   0\n",
            "  255 255   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 255   0   0 255   0   0   0   0\n",
            "  255   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 255   0 255 255 255   0   0\n",
            "    0   0 255   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 255   0   0   0   0   0\n",
            "  255   0 255   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 255   0   0 255 255 255\n",
            "  255   0 255   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "img shape: (28, 28). img sum: 16320\n",
            "(128, 28, 28, 256)\n",
            "(28, 28)\n",
            "training_original.png\n",
            "img shape: (28, 28, 1). img sum: 27812\n",
            "img shape: (28, 28). img sum: 27812\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23  79 192\n",
            "  216 216  91   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  13 209 252 253\n",
            "  252 252 227   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  38 147 209 252 252 244\n",
            "  168  80  31   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  38 175 253 252 214 139  25\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 198 253 255 209  25   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 114 234 252 234  28   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  23 234 252 252 100   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  29 252 252 151   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 154 253 253 128   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 253 252 233  22   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  89 253 252 168   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 113 253 252 168   0   0  76 113 113  51\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 114 254 253 216 191 254 253 253 253 242\n",
            "  141  53   4   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  38 253 252 252 252 253 252 252 252 253\n",
            "  252 252 103   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 253 252 252 214 156  56  56 106 178\n",
            "  252 252 228   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 153 252 252 139   0   0   0   0   4\n",
            "   78 252 252 101   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  76 231 253 253  76   0   0   0   4\n",
            "  128 253 253 114   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  19 190 252 244  94  57  57 179\n",
            "  252 252 252  88   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  19 193 253 252 252 252 253\n",
            "  252 252 127   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  13 153 252 252 252 253\n",
            "  177  52   3   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "img shape: (28, 28). img sum: 27812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk-zvNP9DGWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_location = F'/content/drive/My Drive/sc-model-es-net-mnist-grayscale-double-softmax.hdf5'\n",
        "log_dir = F'/content/drive/My Drive/logs'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkGTGGr06HUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# updatable plot\n",
        "# a minimal example\n",
        "from IPython.display import clear_output\n",
        "\n",
        "class PlotLosses(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        \n",
        "        self.fig = plt.figure()\n",
        "        \n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        \n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.i)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.i += 1\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        plt.plot(self.x, self.losses, label=\"loss\")\n",
        "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
        "        plt.legend()\n",
        "        plt.xscale('log')\n",
        "        plt.show();\n",
        "        \n",
        "plot_losses = PlotLosses()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dQKfsm7sEpV0",
        "outputId": "841bb61a-b458-411f-c6da-0ae3a2cb89c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "\n",
        "model = unet_model(input_size=image_shape, is_grayscale=is_grayscale)\n",
        "\n",
        "resume_training = False\n",
        "if resume_training:\n",
        "    model = keras.models.load_model(model_location)\n",
        "\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_location,\n",
        "    monitor='val_loss',\n",
        "    save_weights_only=False,\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    save_best_only=False)\n",
        "\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, update_freq='epoch')\n",
        "\n",
        "if True:\n",
        "    if is_single:\n",
        "        history = model.fit(\n",
        "            training_generator,\n",
        "            # validation_data=validation_data,\n",
        "            verbose=1,\n",
        "            shuffle=True,\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            epochs=3000,\n",
        "            callbacks=[model_checkpoint_callback])#, tensorboard_callback])\n",
        "    else:\n",
        "        history = model.fit(\n",
        "            training_generator,\n",
        "            validation_data=validation_data,\n",
        "            verbose=1,\n",
        "            shuffle=True,\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            epochs=1000,\n",
        "            callbacks=[model_checkpoint_callback, plot_losses, tensorboard_callback])#, tensorboard_callback])\n",
        "    #epochs=cfg.epochs,\n",
        "    #callbacks=callbacks)\n",
        "# model.save(\"sc-model.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_54\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_54 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_796 (Conv2D)             (None, 28, 28, 32)   320         input_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_797 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_796[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_798 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_797[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_107 (MaxPooling2D (None, 14, 14, 32)   0           conv2d_798[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 14, 14, 32)   128         max_pooling2d_107[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_799 (Conv2D)             (None, 14, 14, 64)   18496       batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_800 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_799[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_801 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_800[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_108 (MaxPooling2D (None, 7, 7, 64)     0           conv2d_801[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_107 (Dropout)           (None, 7, 7, 64)     0           max_pooling2d_108[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_802 (Conv2D)             (None, 7, 7, 128)    73856       dropout_107[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_803 (Conv2D)             (None, 7, 7, 128)    147584      conv2d_802[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_804 (Conv2D)             (None, 7, 7, 128)    147584      conv2d_803[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_107 (UpSampling2D (None, 14, 14, 128)  0           conv2d_804[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_107 (Concatenate)   (None, 14, 14, 192)  0           up_sampling2d_107[0][0]          \n",
            "                                                                 conv2d_801[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 14, 14, 192)  768         concatenate_107[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_805 (Conv2D)             (None, 14, 14, 64)   110656      batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_806 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_805[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_807 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_806[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_108 (Dropout)           (None, 14, 14, 64)   0           conv2d_807[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_108 (UpSampling2D (None, 28, 28, 64)   0           dropout_108[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_108 (Concatenate)   (None, 28, 28, 96)   0           up_sampling2d_108[0][0]          \n",
            "                                                                 conv2d_798[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_808 (Conv2D)             (None, 28, 28, 32)   27680       concatenate_108[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_809 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_808[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_810 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_809[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "sigmoid_out (Conv2D)            (None, 28, 28, 256)  8448        conv2d_810[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_54 (Reshape)            (None, 28, 28, 256)  0           sigmoid_out[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "softmax_out (Conv2D)            (None, 28, 28, 1)    33          conv2d_810[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 28, 28, 256)  0           reshape_54[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 720,257\n",
            "Trainable params: 719,809\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-475-4bddf0ed0e5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             callbacks=[model_checkpoint_callback, plot_losses, tensorboard_callback])#, tensorboard_callback])\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;31m#epochs=cfg.epochs,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#callbacks=callbacks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m                 initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mcallback_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_callback_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     callbacks.set_params({\n\u001b[1;32m    102\u001b[0m         \u001b[0;34m'epochs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v2.py\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;34m\"\"\"Sets Keras model and writes graph if specified.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1785\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0msummary_ops_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malways_record_summaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m               \u001b[0msummary_ops_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m             summary_writable = (\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(param, step, name)\u001b[0m\n\u001b[1;32m    905\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m       \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_serialize_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36m_serialize_graph\u001b[0;34m(arbitrary_graph)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_serialize_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marbitrary_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marbitrary_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marbitrary_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marbitrary_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU7a7s_5JRMR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   Loss\n",
        "  1. \n",
        "2.   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-51yFm3JLzv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKxrjiG_eqBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"Loss\"\n",
        "if is_single:\n",
        "    plt.plot(history.history['loss'])\n",
        "    # plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train'], loc='upper left')\n",
        "    # plt.xscale('log')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0IEPAcide5lS"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF8wPwoAo_xp",
        "colab_type": "code",
        "outputId": "77be6e46-f0ac-499f-f1e7-2cb8f8155a9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "# testing model predict with seaborn and plots\n",
        "model = keras.models.load_model(model_location)\n",
        "import seaborn as  sb\n",
        "import matplotlib.pyplot as plt\n",
        "print(image_shape)\n",
        "def generate_noise():\n",
        "    input_image = np.full(image_shape, 0)\n",
        "    # input_image = np.expand_dims(images[0], -1)\n",
        "\n",
        "    # Random noise\n",
        "    # input_image = np.random.rand(28, 28)\n",
        "    # input_image[input_image >= 0.5] = 1\n",
        "    # input_image[input_image < 0.5] = 0\n",
        "\n",
        "    input_image = input_image.astype(np.uint8)\n",
        "    input_image = np.expand_dims(input_image, 0)\n",
        "    return input_image\n",
        "\n",
        "test_image = generate_noise()\n",
        "if is_grayscale:\n",
        "    softmax_predictions, sigmoid_predictions = model.predict(test_image)\n",
        "    softmax_predictions = softmax_predictions.reshape(image_shape[0], image_shape[1])\n",
        "    heatmap = sb.heatmap(softmax_predictions)\n",
        "    plt.show()\n",
        "    softmax_predictions = np.exp(softmax_predictions)\n",
        "    softmax_predictions = softmax_predictions / np.sum(softmax_predictions)\n",
        "    print(sigmoid_predictions.shape)\n",
        "    # print(sigmoid_predictions[])\n",
        "    sigmoid_predictions = np.argmax(sigmoid_predictions, axis=-1)\n",
        "    print(sigmoid_predictions.shape)\n",
        "    sigmoid_predictions = sigmoid_predictions.reshape(image_shape[0], image_shape[1])\n",
        "    heatmap = sb.heatmap(softmax_predictions)\n",
        "    plt.show()\n",
        "    heatmap = sb.heatmap(sigmoid_predictions)\n",
        "    plt.show()\n",
        "else:\n",
        "    softmax_predictions = model.predict(test_image)\n",
        "    softmax_predictions = softmax_predictions.reshape(28, 28)\n",
        "    softmax_predictions = np.exp(softmax_predictions)\n",
        "    softmax_predictions = softmax_predictions / np.sum(softmax_predictions)\n",
        "    heatmap = sb.heatmap(softmax_predictions)\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(1, 28, 28, 256)\n",
            "(1, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dfZRlVXnn8e+v3ppukG5AQegm0kqTrCYmYnoISRxFMAGji85akbGTcUCHpNc44ltcEohrmYkzGNqXEFdGMukIhKARsGVIRwkq4ssyExta1MiLYMtLupr3Brrpt+qqus/8cU7jpbrq7n1v3Vt177m/D+ssbp2zz65d51bt3nfv5zxHEYGZmXWvgflugJmZNeaO2sysy7mjNjPrcu6ozcy6nDtqM7MuN9TxbzCy1GElZpZlYv82zbaO8aceyO5zhl/88ll/v7ngEbWZWZdLjqgl/QKwGlha7toGbIyIezvZMDOzltQm57sFbddwRC3pj4HrAAG3l5uAz0u6uPPNMzNr0uRE/tYj1OjOREn3AydHxPiU/SPA3RGxYobz1gJrATS4+FcGBg5tX4vNrLLaMUe9/5G7s+eoR447uRJz1DXguGn2H1sem1ZErI+IVRGxyp20mc2pWi1/6xGpOer3AV+X9BNga7nv54ATgQs72TAzs5ZE73TAuRp21BFxi6STgFN54WLiHRFRvRl7M+t9FVxMTEZ9REQN+O4ctMXMbPb6bURtZtZrooeiOXK5ozazaumhRcJc7qjNrFo89WFm1uX6cTHRzKyneERtZtblvJho/awn7rWdgXPt9hEvJlq/6uVO2vpLFe/Fc0dtZtVSwTnq5IMDJP2CpDMlHTZl/9mda5aZWYsqmJQplY/6PcA/Au8G7pK0uu7wRzvZMDOzlkQtf+sRqamPPwR+JSJ2SToB2CDphIj4FA2mLafko8apTs1szkyOp8v0mFRHPRARuwAi4iFJp1N01i+jQUcdEeuB9eCH25rZHOuhKY1cqTnqxyW96sAXZaf9ZuDFwCs72TAzs5b04dTHecALoscjYgI4T9LfdKxVlpQTLjcwkPeQ+QGlyw1mlCnqygvkU2a5HI0eJ3dALaMMwGTGH28t8w88p11Fff7Q2VYVHFGnHhww2uDYv7S/OWZms9RvHbWZWa+JCi4m5n2eNTPrFW2co5Z0tqT7JG2RdPE0xxdIur48vqmMjjtw7JJy/32Szqrb/35Jd0u6S9LnJR2Saoc7ajOrljbd8CJpEPg08EZgJfB7klZOKXYB8ExEnAhcDqwrz10JrAFOBs4GrpA0KGkp8B5gVUT8IjBYlmvIHbWZVUv7RtSnAlsi4oGI2A9cB6yeUmY1cE35egNwpoqV8tXAdRExFhEPAlvK+qCYcl4oaQhYBDySaog7ajOrliZG1JLWStpct62tq2kpsLXu69FyH9OVKSPidgBHzXRuRGwDPgH8O/AosCMivpr6kbyYaGbV0kR8dP3NeXNB0hEUo+3lwLPAFyS9LSI+2+g8d9RzKCdyODe+eHBgMFlm4dBIVl2Lhhcky7xoaFFWXUuG89IFHDqQbtuI0j8jwEDGld0Xecnkd07uS5Z5ZnxXVl3P7s8rt2d8LFlmIvPxUrWM0LTKR21PtO3BAduA4+u+Xlbum67MaDmVsRjY3uDcNwAPRsSTAJJuBH4daNhRe+rDzKqlfXPUdwArJC2XNEKx6LdxSpmNwPnl67cAt0Vxp9NGYE0ZFbIcWAHcTjHlcZqkReVc9pnAvamGeERtZtXSphteImJC0oXAVyiiM66KiLslfQTYHBEbgSuBayVtAZ6mjOAoy90A3ENxd/e7oniiwSZJG4A7y/3fJ2PqRbm3uT5/gvT3EXFebnknZfoZT338jKc+fsZTHz8zsX/brHML7P3Hj2X/iAtXX9QTDy9qOKKWNHWYL+D1kpYARMQ5M5znNKdmNj/68BbyZRRD989Q/EMsYBXwyUYnOc2pmc2bHsqKlyu1mLgK+B7wIYp4v28CeyPiWxHxrU43zsysaRMT+VuPSGXPqwGXS/pC+f/HU+eYmc2rCqaNzep0y3Sn50p6E7Czs03qPbk5mHPyPg9lLBICHJqxALh45LBkGYBjRhYnyxw39KKsuo7XwqxyS2vpn3NJ3voZIxl/l+OZS0YPZFT2k+HdWXU9OPxsVrlH9m1Pltmxf09WXfsn06PE3HzaPbsw2Ydz1C8QEV8GvtyhtpiZzV6/d9RmZl2vgouJ7qjNrFomM+fMeog7ajOrFk99mJl1OXfUZmZdznPU/Scn9G54MO8yLhgcTpbJybsBsGQ4HXr30oywO4CTBvPKnTKRzs/xylpeGNlLj34uWebQl+zPqmsg+cQ5iLyquPMHxybLvIZD+MbCdKjlnqG8Gyp2Dafzi4xn5vrIyXuyv5bXrvGMeORmcwXNhah1X5tmyx21ZcnppPtFTidt88hTH2ZmXa6CUR8NhwaSflXS4eXrhZL+TNI/SVonKe/zspnZXGrTU8i7Seoz3FXAgUnHT1E8ZmZdue/qDrbLzKw1FeyoU1MfA+WTdQFWRcSry9ffkfSDmU5yPmozmzdduMA5W6kR9V2S3lG+/qGkVQCSTgLGZzopItZHxKqIWOVO2szmVAVH1KmO+g+A10n6KbAS+FdJDwB/Wx4zM+sutcjfekQqH/UO4O3lguLysvxoRDw+F43rpNzUpDkx0rmxzy8aTj938MiM+GiAlw4fniyzYiAvNekvj+cF//zyYDr2+edOyUvtOfKy9CetgcVLsupiON3+2JmXmvSkx9MpR+/ffkxWXaMZz4UEOGwwHQi+e3BvVl0TkY54qGUmJ815TqMypxnmtEusYNRHbj7qncAPO9wW62I5nbRZN4gemtLI5ThqM6uWHprSyOWO2syqxbk+zMy6nEfUZmZdbqJPFxPNzHqGpz7MzLqcpz66X150NCgzjnpQ6ZSWOXmmARYNpuOtD8soA3CE0uWOjMGsupZMpkcgCw+d8UbU1gxltG3RwrZ9u9iTl5B6bF/6T2I885dsgryR3WRmOcvj8Dwzs27nEbWZWZfrt45a0giwBngkIm6V9PvArwP3Ausjos2fh83MZqkPbyG/uiyzSNL5wGHAjcCZwKnA+dOd5DSnZjZf+vGZia+MiF+SNARsA46LiElJn6VB7o+IWA+sBxgaWVq9q2Zm3asPO+qBcvrjUGARxRNengYWAHmhDmZmc6kPoz6uBH4MDAIfAr5Q5qM+Dbiuw20zM2tev42oI+JySdeXrx+R9PfAG4C/jYjb56KB8y0njnpYefHKhwykP4QsUN4HlaGMOPA9mVmAHxlO/4yH7sjLbb3o0bGsckNH7kmWGXjJEVl1sW9fssj443n5nJ949iXJMk8dkjdie3Yy71rsySg3npFnGmAiYyFtso0jzq7sEvuto4aig657/SywoaMtMjObhci4gavXOI7azKqlgiPq9GdeM7MeErXI3lIknS3pPklbJF08zfEFkq4vj2+SdELdsUvK/fdJOqtu/xJJGyT9WNK9kn4t1Q6PqM2sWto0opY0CHwa+E1gFLhD0saIuKeu2AXAMxFxoqQ1wDrgrZJWUtwseDJwHHCrpJMiYhL4FHBLRLyljKpLPkzVI2ozq5ZaE1tjpwJbIuKBiNhPEem2ekqZ1cA15esNwJkqMr6tBq6LiLGIeBDYApwqaTHwWoqIOiJif7n215A7ajOrlJioZW+S1kraXLetratqKbC17uvRch/TlYmICWAHcFSDc5cDTwJXS/q+pM9ISt667Y7azKqliRF1RKyPiFV12/oOt24IeDXw1xFxCrAbOGjue7qTrIHaHEeK5uYmfi4jH1Zuzm0GR5JFJkfy4ruPfTovh/Th+3cny2hhXm7u2q50XWNP5o1JRgfS3/MJ8nJbP1tLx3cD7JtMv5djGWUAxmsZcdSZT0CJ6M3oiTbm+tgGHF/39bJy33RlRstUG4uB7Q3OHQVGI2JTuX8DGR21R9RmVi3tm6O+A1ghaXldJtGNU8ps5GfJ6d4C3BbFv3AbgTVlVMhyYAVwe0Q8BmyV9PPlOWcC95DgEbWZVUq7RtQRMSHpQuArFGk0roqIuyV9BNgcERspFgWvlbSFIg/SmvLcuyXdQNEJTwDvKiM+AN4NfK7s/B8A3pFqiztqM6uWNt6YGBE3AzdP2ffhutf7gHNnOPdS4NJp9v8AWNVMOxpOfUhaLOmyMjD7aUnbywDtyyQtaXDe8yuptVp6/tDMrF1iIn/rFak56huAZ4DTI+LIiDgKeH2574aZTqpfSfVDA8xsLkUtf+sVqY76hIhYV06AAxARj0XEOuBlnW2amVkL2reY2DVSc9QPS7oIuCYiHgeQdAzwdl4YzF1ZOSFKuSF8OWFR+2t5n8d2kg69G1fmb2JG7M/jg7CMdOjagPKuxdCx6bSpOva4rLq0J53CtDaZF6q4cyBdbm9mytGxWm5IXbpcTvpSyPsdq1U+PG++W9B+qT/Rt1LcZfOtco76aeCbwJHMMIFu1ZTTSZt1gypOfaQeHPAM8Mfl9gKS3kHx8Fszs64RmZ+eeslsbnj5s7a1wsysTfpuRC3p32Y6BBzT/uaYmc1O1Ko3ok4tJh4DnEURjldPwP/rSIvMzGahl0bKuVId9ZeAw8o7aV5A0jc70iIzs1mI6LMRdURc0ODY77e/OWZms9OPI+qekxv5mRsjWssol5s2MieF6f7MGN2cYH1lxAQD7M24l3Y4Mzxv8dHpmGaAwVemUx1o+cqsugZ2P5csM7RgNKuu8YxLlpuKNldW7PMcp9vtZbkx872kch21mfW3flxMNDPrKe6ozcy6XI/e+d5QRzrq8gGRawE0uBhn0DOzuVLFEXUqH/Xhkv5c0rWSfn/KsStmOs9pTs1svkQoe+sVqVvIr6a4ueWLFM//+qKkA8v/p3W0ZWZmLZicVPbWK1JTH6+IiN8tX98k6UPAbZLO6XC7zMxa0ksj5VypjnqBpIGIItAzIi6VtA34NnBYx1vXQblx1DkxrhO1vNjn8Yxy+5WXjzonrnY4BrPqynFE5rzfYSfmldMvvyZZZuAlec+mmHz0wWSZoUPz3u/hjGIjyruuI8pbAhpUOjfaQEb+cSv03Rw18E/AGfU7IuLvgA8A+zvUJjOzlkXkb70idQv5RTPsv0XSRzvTJDOz1vXjiLoR56M2s64zWRvI3nqF81GbWaX00pRGLuejNrNKqfVh1IfzUZtZT+m78DznozazXtOPUx99LyfeOjcf9URGrun9tbw46pxl4NwcxoMZlR01mVfX0CuOzvueP/eL6UKZ8ekMpn+NNZJX1aEZb+VI5hr8woHhrHLDGeUGB8ay6hrIiHioVbAjq9ePUx9mZj2ll6I5crmjNrNKqeIHBnfUZlYpVZz6aPozgqTkJKSktZI2S9pcq+1urWVmZi2oYprT1A0vR07dBdwu6RRAEfH0dOdFxHpgPcDQyNIqfhIxsy5VwYeQJ6c+ngIenrJvKXAnxVTQyzvRKDOzVkUFMw2mOuoPAr8JfDAifgQg6cGIWN7xlvWQdqZMzQ7PyzAx0L6xxZeH93Lu2CHJclpyeNu+Z+zZkVdw59QbZ6epK/OyDme8l8OZHUFO+lKA4YF02tTcunKogh1ZvYkemtLIlbrh5ZOSrgcul7QV+FOquahqCTmdtFk36McRNRExCpxbPtXla8CijrfKzKxFVZyjzv48FREbgdcDbwCQ9I5ONcrMrFWBsrde0dTEV0TsjYi7yi+dj9rMuk6tiS1F0tmS7pO0RdLF0xxfIOn68vgmSSfUHbuk3H+fpLOmnDco6fuSvpTzMzkftZlVymSbRsqSBoFPUwRUjAJ3SNoYEffUFbsAeCYiTpS0BlgHvFXSSmANcDJwHHCrpJMink/4817gXiBr9d35qM2sUtr4JK5TgS0R8QCApOuA1UB9R70a+B/l6w3A/5akcv91ETEGPChpS1nfv0paBrwJuBT4o5yGOB+1mVVKrYkRtaS1wNq6XevLG/aguGdka92xUeBXp1TxfJmImJC0Aziq3P/dKecuLV//JXAR8KLcdjofdRvUsuOo02k7c2Ncc1KmjmeUARgjXS4z4Sixd19WudrTj6Tr2r41WQag9sBDyTJ7n0jHKgPsGkxf//2ZcQW56W9zFIO0jHI9tEDWKc3ED9ffRT0XJL0ZeCIivifp9NzzqpcP0Mz6WhsXE7cBx9d9vazcN20ZSUPAYmB7g3N/AzhH0kPAdcAZkj6baog7ajOrlJqUvSXcAayQtFzSCMXi4MYpZTYC55ev3wLcFsWtyhuBNWVUyHJgBXB7RFwSEcsi4oSyvtsi4m2phjjNqZlVSu40XUo553wh8BVgELgqIu6W9BFgc3lvyZXAteVi4dMUnS9luRsoFh4ngHfVRXw0remOWtJREbE9Ueb5CXoNLmZg4NAWm2dm1pw2Rn0QETcDN0/Z9+G61/uAc2c491KKyI6Z6v4m8M2cdjSc+pB0maQXl69XSXoA2CTpYUmva9CA9RGxKiJWuZM2s7lUQ9lbr0jNUb8pIp4qX38ceGtEnEgRAP7JjrbMzKwF0cTWK1JTH0OShiJiAlgYEXcARMT9khZ0vnlmZs1p59RHt0h11FcAN0u6DLhF0qeAG4EzgINugrHGcvJWh/L+nc+J3a5ljhkmM8rtHcgLEIon07mhAWqP3J8uNPrTrLrG73s0XdXWJVl1PTGcLrMjxrPq2lvLK5cTb52b8zx6apzYGVXMnpe64eWvJP0IeCdwUll+BXAT8D873zwzs+ZM9uGIesaVyTLN6dXtb5KZWeuqOKKezQ0vTnNqZl2nnWlOu4XTnJpZpVTwkYlOc2pm1dJLI+VcTnNqZpXSrlvIu4nTnJpZpfRjHLVlGMjNFZxRrp35hAfaWNeezGXnySd3Z5Ub3PZgskztoYez6tq3Nf1h96csyqrrSU0ky+ya3J9V11hmHPVELf0925nbOlfO72tufPdc6sepDzOznuKO2sysy3XfGH/23FGbWaV4jjqT81Gb2XypYtRHKh/1KknfkPRZScdL+pqkHZLukHTKTOc5H7WZzZcakb31itRa/hXAx4AvU9zg8jcRsRi4uDxmZtZV+u4WcmA4Iv4ZQNK6iNgAEBFfl/SJjreuR+SEMUFeuFxuqN+g0vFyOWUAhjNSvtw6uIs3TB6WLDe5Mx1qBhCPplOT1h5p+MS35z01mm7XU5mTfM+Sbv/O2lhWXXtreWF8+zPC88ZreR/oc9LfVl0Vr0Dq13efpN+ieAR6SPqdiLipfAxXFaeCbAY5nbRZN+ilkXKuVEf93yimPmoUOT/eKenvgG3AH3a2aWZmzZvIfPhGL2n4mTcifhgRZ0XEGyPixxHx3ohYEhEnAz8/R200M8tWxWcmOh+1mVVK3y0mOh+1mfWaXgq7y+V81GZWKdXrpp2P2swqppemNHI5H3WXyU1zmhMjPZwZR32IBpNlvjO0l9PHFybLRV4YNbFvX7JMbXdeHPLOvUvSZUbyxlnPRTo1aW760pz46Nxyk7W87icn7Whkjjm7MYVpjskKjqmdlMmy5HTSZt2g70bUZma9JvcTQy9xR21mlVLFEXUqe95iSZdJ+rGkpyVtl3RvuS89MWhmNsf6MXveDRSheadHxJERcRTw+nLfDTOdJGmtpM2SNtdqec/QMzNrh368M/GEiFgXEY8d2BERj0XEOuBlM53kfNRmNl8miOytV6Q66oclXSTp+bsQJR0j6Y+BrZ1tmplZ86KJ/3pFajHxrRQPCfhW2VkH8DiwEfhPHW5bz5iPeNOcvNWDmalcBjNit3MfQzeZDo8GIJ7bky6zL29ZaF8tHQe+JzOj2u6MGOncPNNjk3nlJibTGYMnIzOOOqPz6dX46FxVXExM3fDyjKSrga8B342IXQeOSTobuKXD7TMza0ovjZRzpaI+3gP8I3AhcJek1XWHP9rJhpmZtaLvsudRPBzgVyJil6QTgA2SToiIT5H/adjMbM5MVnBqJzWJOXBguiMiHgJOB94o6S9wR21mXaidcdSSzpZ0n6Qtki6e5vgCSdeXxzeVA9oDxy4p998n6axy3/GSviHpHkl3S3pvzs+U6qgfl/SqA1+UnfabgRcDr8z5BmZmc6ldUR+SBoFPA28EVgK/J2nllGIXAM9ExInA5cC68tyVwBrgZOBs4IqyvgngAxGxEjgNeNc0dR4k1VGfBzxWvyMiJiLiPOC1qcrNzOZaG+eoTwW2RMQDEbEfuA5YPaXMauCa8vUG4ExJKvdfFxFjEfEgsAU4NSIejYg7ASLiOeBeYGmqIalnJo7W3+wy5di/pCo3M5trzUx91N9FXW5r66paygvvFxnl4E71+TIRMQHsAI7KObecJjkF2JT6mZyUKSEn1Ge8lo6Dhby8wwMZuaEBahkLJpOZ69rjGTG6ezKfrjm+J6/98dzeZJlaZhz1REa8+FjmtRjLeI/2TbY3H3VOjHRu7HNWPurcurJKdZ9mwvMiYj2wvnOtmZ6kw4AvAu+LiJ2p8u6ozaxS2hj1sQ04vu7rZeW+6cqMShoCFgPbG50raZiik/5cRNyY05DZPIXczKzrtDHq4w5ghaTlkkYoFgc3TimzETi/fP0W4LYoPrJsBNaUUSHLgRXA7eX89ZXAvRHxF7k/k0fUZlYp7bqRJSImJF0IfAUYBK6KiLslfQTYHBEbKTrdayVtAZ6m6Mwpy90A3EMR6fGuiJiU9BrgvwA/knTgWbR/EhE3N2pLw45a0uHAJRTD9n+OiH+oO3ZFRPz3Gc5bC6wF0OBinEHPzOZKO28hLzvQm6fs+3Dd633AuTOceylw6ZR936GFe1BSUx9Xl5V+kWIY/0VJC8pjp810ktOcmtl8qeKDA1JTH6+IiN8tX98k6UPAbZLO6XC7zMxaUsXsgKmOeoGkgYgifigiLpW0Dfg2cFjHW9dBuW9lzps+kRmeN5YR1jWovPXd4YF0GNy+zPCw3YPpcrcO7OSXeFGy3BPb0mUAFh79bLLMzodHsuraNpReanki0mlVAXZMpsMGjxg+lG17tyfLjU3khfHlhHfmfpzPCs/Lqql3TVbwJ0z1Cv8EnFG/IyL+DvgAkJds1yohp5PuFzmdtM2fKk59pO5MvIgiPvDMMkD7wP5bgPd0unFmZs2KiOytV6TyUb+bIh/1uzk4H/Wl059lZjZ/qjiiTk3urcX5qM2sh1TxCS+pjvoF+aglnU7RWb8Md9Rm1oX68cEBzkdtZj2lH6c+zqO4/fF5ZSq/8yT9TcdaZWbWol7qgHOlnkI+2uBYX+SjzlkZnqxlphPNiJfNTY05lFFuT20sq67HJ3Yly3yNXRw7lA6dHx/IC69femc63G9v5uTavcP7kmVGJ5KZJAF4Znx3ssy+ibzI1Nz0t5M5cdQVT03aTr0UzZHLSZksS04nbdYN+m5EbWbWa/ox6uMgko6OiCc60Rgzs9nKeWJOr0mlOT1y6i6K5NenAIqIpzvWMjOzFvTjHPVTwMNT9i0F7qRYt3j5dCc5H7WZzZcqzlGn4qg/CNwHnBMRyyNiOTBavp62kwbnozaz+RNN/NcrUuF5n5R0PXC5pK3An+IIIDPrYrU+nPo4EEt9bvmwgK8Bizreqi6S85bnxMECjGWESOfGZOfkOn5uMC8H8/aB9JryY4Pp/NEAPxk6JKvcgoHhZJmJyLuuO8bTP+eujDIAu8fTsef7M/KKg2Of50svjZRzJf9CJf0Cxbz0bRQd9SvK/WeX6U7NzLpGFaM+UmlO30NdmlPgtyLirvLwRzvcNjOzptUisrdekRpR/yFOc2pmPaQfpz6c5tTMekovjZRzOc2pmVVK34Xn4TSnZtZjJjOjhXqJ05yaWaX04y3kliH31yI33jrve6a/a24+5DGl44L3DuTlYN6Zkc8ZYKCNSxxZeb4n8/J858RIV3EOtEqqeAu5O2ozqxSPqM3MulwVP/Gkoj4OIumoTjTEzKwdqhj1kboz8TJJLy5fr5L0ALBJ0sOSXtfgvLWSNkvaXKvlzVmambXDZNSyt16RGlG/KSKeKl9/HHhrRJwI/CbwyZlOcppTM5svEZG99YrUHPWQpKEydnphRNwBEBH3S1rQ+eaZmTWninPUqY76CuBmSZcBt0j6FHAjcAbwg043zsysWb00Us6VuuHlryT9CHgncFJZfgVwE/C/Ot+8amlnbuuccpLTsRzg3ND9o1/jqB8D1gObDiRogiIfNeB81GbWVao4om4qH7Wk1XWHnY/azLpOFaM+nI/azCqlHxcTnY/azHpK30194HzUZtZj2nlnoqSzJd0naYuki6c5vkDS9eXxTeXMw4Fjl5T775N0Vm6d00l11OdRLCY+LyImIuI84LU538DMbC6164YXSYPAp4E3AiuB35O0ckqxC4BnyhsBLwfWleeuBNYAJwNnA1dIGsys8yANO+qIGI2Ix2Y45nzUZtZ12vhw21OBLRHxQETsB64DVk8psxq4pny9AThTRVzsauC6iBiLiAeBLWV9OXUepOPZ8yb2bztoLlvS2ohY3476+6GudtfnulxXp+trd9uaMV2fMxNJa4G1dbvW17V7KbC17tgo8KtTqni+TERMSNoBHFXu/+6Uc5eWr1N1HqTp7HltsjZdxHV1sD7X5bo6XV+729YR9XmJym1e/nFJma+O2sys220Djq/7elm5b9oykoaAxcD2Bufm1HkQd9RmZtO7A1ghabmkEYrFwY1TymwEzi9fvwW4LYpVyo3AmjIqZDlF6o3bM+s8yHw94aWdHy/6oa521+e6XFen6+vKKYRmlHPOFwJfAQaBqyLibkkfATZHxEbgSuBaSVuApyk6XspyNwD3ABPAuyKKx6NPV2eqLapicLiZWZV46sPMrMu5ozYz63Jz2lG3cutkg7qOl/QNSfdIulvSe9vQvkFJ35f0pVnWs0TSBkk/lnSvpF+bRV3vL3++uyR9XtIhTZx7laQnJN1Vt+9ISV+T9JPy/0fMsr6Plz/nv0n6v5KWtFpX3bEPSIoDz+tstS5J7y7bdrekj7Val6RXSfqupB+UzwI9NbOuaX9HW3kPGtTV9PVP/e00c/0b1dXK9bcZNHO75Ww2ionznwIvB0aAHwIrZ1HfscCry9cvAu6fTTFCMRkAAAQZSURBVH1lPX8E/APwpVnWcw3wB+XrEWBJi/UsBR6keAwawA3A25s4/7XAq4G76vZ9DLi4fH0xsG6W9f0WMFS+Xpdb33R1lfuPp1hoeRh48Sza9XrgVmBB+fXRs6jrq8Aby9e/DXxzNr+jrbwHDepq+vo3+ttp9vo3aFdL19/b9NtcjqhbunVyJhHxaETcWb5+DriXn9350zRJy4A3AZ9ptY6ynsUUf+xXlm3bHxHPzqLKIWBhGaO5CHgk98SI+DbFSnS9+lterwF+Zzb1RcRXo3imJhR3Yi2bRdugyJdwEU08bGWGut4JXBYRY2WZJ2ZRVwCHl68Xk/keNPgdbfo9mKmuVq5/4m+nqevfoK6Wrr9Nby476ulux2y5Y62nImPVKcCmWVTzlxS/oLPNJr4ceBK4upxG+Yyklh7FHhHbgE8A/w48CuyIiK/Osn3HRMSj5evHgGNmWV+9/wr8c6snq3gwxbaI+GEb2nIS8B9VZDT7lqT/MIu63gd8XNJWivfjkmYrmPI7Oqv3oMHve9PXv76u2V7/Ke1q5/Xvez2/mCjpMOCLwPsiYmeLdbwZeCIivteGJg1RfHT+64g4BdhN8fG2lXYdQTH6Wg4cBxwq6W1taCMAUXwmbUt8pqQPUcSLfq7F8xcBfwJ8uB3toXgfjgROAz4I3CC1/BDJdwLvj4jjgfdTflrK1eh3tNn3YKa6Wrn+9XWV57Z8/adpVzuvf9+by466pVsnG5E0TPHL8bmIuHEWVf0GcI6khyimZM6Q9NkW6xoFRiPiwGhnA0XH3Yo3AA9GxJMRMU7xBPhfb7GuAx6XdCxA+f9ZfySV9HaKPOX/uex4WvEKin+Qfli+D8uAOyW9tMX6RoEbo3A7xSelrMXJaZxPce0BvkAxjZdlht/Rlt6DmX7fW7n+09TV8vWfoV3tvP59by476pZunZxJ+a/zlcC9EfEXs2lYRFwSEcsi4oSyXbdFREsj1yjSwm6V9PPlrjMp7k5qxb8Dp0laVP68Z1LMAc5G/S2v51M8E7NlKh5yfBFwTkTsabWeiPhRRBwdESeU78MoxSLVtGl2M9xEsaCFpJMoFnWfarGuR4DXla/PAH6Sc1KD39Gm34OZ6mrl+k9XV6vXv8HP2M7rb3O5ckmxYn4/RfTHh2ZZ12soPjL+G/CDcvvtNrTxdGYf9fEqYHPZtpuAI2ZR158BPwbuAq6lXEXPPPfzFHPb4xR/eBdQpGD8OkVncytw5Czr20Kx9nDgPfg/rdY15fhD5Ed9TNeuEeCz5XW7EzhjFnW9BvgeRaTSJorniLb8O9rKe9Cgrqavf87fTu71b9Culq6/t+k330JuZtblen4x0cys6txRm5l1OXfUZmZdzh21mVmXc0dtZtbl3FGbmXU5d9RmZl3u/wMxtJJTVPdoewAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PBu4a18br7wL",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "\n",
        "def inference(model, input_image, directory, iterations, temp_start=2, temp_end=0.5, top_k=250, is_grayscale=True, is_debug=False):\n",
        "    create_image(input_image, \"{}/input.png\".format(directory), image_shape=image_shape[:-1])\n",
        "\n",
        "    # temperatures = np.linspace(temp_start, temp_end, num=iterations)\n",
        "    temperatures = np.geomspace(temp_start, temp_end, num=iterations)\n",
        "    temperatures_reverse = (temp_start + temp_end) - temperatures[::-1]\n",
        "    temperatures = np.concatenate((temperatures_reverse[:int(temperatures.shape[0]/2)], temperatures[int(temperatures.shape[0]/2):]))\n",
        "    \n",
        "    working_image = deepcopy(input_image)\n",
        "    working_images = []\n",
        "    num_added = 0\n",
        "    num_removed = 0\n",
        "    for i in range(iterations):\n",
        "        temp = temperatures[i]            \n",
        "        binary_image = deepcopy(working_image)\n",
        "        binary_image[binary_image > 0] = 1\n",
        "        if is_grayscale:\n",
        "            softmax_predictions, sigmoid_predictions = model.predict(working_image)\n",
        "        else:\n",
        "            softmax_predictions = model.predict(binary_image)\n",
        "\n",
        "        softmax_predictions = softmax_predictions.flatten()\n",
        "        if is_grayscale:\n",
        "            # sigmoid_predictions = np.argmax(sigmoid_predictions, axis=-1)\n",
        "            sigmoid_predictions = sigmoid_predictions.reshape(-1, 256)\n",
        "\n",
        "        softmax_predictions = np.exp(softmax_predictions / temp)\n",
        "        softmax_predictions = softmax_predictions / np.sum(softmax_predictions)\n",
        "        # softmax_predictions = np.nan_to_num(softmax_predictions)\n",
        "        # print(softmax_predictions)\n",
        "        # print(softmax_predictions[-1])\n",
        "        indices = np.arange(softmax_predictions.shape[0])\n",
        "\n",
        "        zipped = zip(softmax_predictions, indices)\n",
        "        zipped = list(reversed(sorted(zipped, key = lambda x : x[0])))\n",
        "        zipped = zipped[:top_k]\n",
        "        zipped = sorted(zipped, key=lambda x : x[1])\n",
        "        softmax_predictions, indices = zip(*zipped)\n",
        "        softmax_predictions = np.asarray(softmax_predictions)\n",
        "        softmax_predictions = softmax_predictions / np.sum(softmax_predictions)\n",
        "        indices = np.asarray(indices)\n",
        "\n",
        "        index = np.random.choice(indices, p=softmax_predictions)\n",
        "        working_image = working_image.flatten()\n",
        "        # if index == softmax_predictions.shape[0]:\n",
        "        #     print(\"stopping\")\n",
        "            # break\n",
        "        if is_grayscale:\n",
        "            if working_image[index] != 0:\n",
        "                num_removed += 1\n",
        "            elif working_image[index] == 0:\n",
        "                num_added += 1\n",
        "            sigmoid_probs = sigmoid_predictions[index]\n",
        "            sigmoid_indices = np.arange(sigmoid_probs.shape[0])\n",
        "            working_image[index] = np.random.choice(sigmoid_indices, p=sigmoid_probs)\n",
        "        else:\n",
        "            if working_image[index] == 1:\n",
        "                num_removed += 1\n",
        "                working_image[index] = 0\n",
        "            elif working_image[index] == 0:\n",
        "                num_added += 1\n",
        "                working_image[index] = 1\n",
        "            else:\n",
        "                print(working_image[index])\n",
        "        working_image = np.reshape(working_image, [1, *image_shape])\n",
        "        if i % 10 == 0:\n",
        "            if is_debug:\n",
        "                print(\"softmax\")\n",
        "                softmax_predictions = softmax_predictions.reshape(image_shape[:-1])\n",
        "                heatmap = sb.heatmap(deepcopy(softmax_predictions))\n",
        "                plt.show()\n",
        "                print(\"sigmoid\")\n",
        "                sigmoid_predictions = np.argmax(sigmoid_predictions, axis=-1).reshape(image_shape[:-1])\n",
        "                heatmap = sb.heatmap(deepcopy(sigmoid_predictions))\n",
        "                plt.show()\n",
        "            create_image(working_image, os.path.join(directory, \"working_{}.png\".format(i)), image_shape=image_shape[:-1])\n",
        "\n",
        "    final_image = working_image\n",
        "    final_binary_image = deepcopy(final_image)\n",
        "    final_binary_image[final_binary_image > 0] = 1\n",
        "    create_image(final_binary_image, os.path.join(directory, \"final_binary.png\"), image_shape=image_shape[:-1])\n",
        "\n",
        "    print(final_image.shape)\n",
        "    print(\"num added: {}. num removed: {}\".format(num_added, num_removed))\n",
        "    img = create_image(final_image, os.path.join(directory, 'final.png'), image_shape=image_shape[:-1])\n",
        "    return img, deepcopy(final_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC6ZVFAFeqBb",
        "colab_type": "code",
        "outputId": "a7027ebb-89c5-400d-e990-dc4b830a02f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "# model = keras.models.load_model(model_location)\n",
        "\n",
        "drive_folder = '/content/drive/My Drive'\n",
        "\n",
        "model_names = [# 'sc-model-es-net-60000-4',\n",
        "               #'sc-model-es-net-60000-16',\n",
        "               'sc-model-es-net-mnist-grayscale-double-softmax',\n",
        "               #'sc-model-nade-60000-4'\n",
        "               ]\n",
        "\n",
        "config = {\n",
        "    'sc-model-es-net-60000-4': {\n",
        "        \"iterations\": 300,\n",
        "        \"temp_start\": 0.99,\n",
        "        \"temp_end\": 0.99,\n",
        "        \"top_k\": 10000\n",
        "    },\n",
        "    'sc-model-es-net-mnist-grayscale-double-softmax': {\n",
        "        \"iterations\": 500,\n",
        "        \"temp_start\": 5,\n",
        "        \"temp_end\": 2,\n",
        "        \"top_k\": 10000\n",
        "    },\n",
        "    'sc-model-nade-60000-4': {\n",
        "        \"iterations\": 170,\n",
        "        \"temp_start\": 0.99,\n",
        "        \"temp_end\": 0.99,\n",
        "        \"top_k\" : 10000\n",
        "    },\n",
        "\n",
        "}\n",
        "\n",
        "sample_sqrt = 5\n",
        "for model_name in model_names:\n",
        "    model = keras.models.load_model(os.path.join(drive_folder, model_name + '.hdf5'))\n",
        "    model_config = config[model_name]\n",
        "    generated_images = []\n",
        "    for i in range(sample_sqrt**2):\n",
        "        directory = \"images_{}\".format(i)\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "        input_image = generate_noise()\n",
        "        # input_image = np.expand_dims(np.expand_dims(images[i], 0), -1)\n",
        "\n",
        "        img, _ = inference(model, input_image, directory, \n",
        "                           model_config['iterations'], temp_start=model_config['temp_start'], \n",
        "                           temp_end=model_config['temp_end'], top_k=model_config['top_k'], \n",
        "                           is_grayscale=is_grayscale, is_debug=False)\n",
        "        generated_images.append(img)\n",
        "    \n",
        "    final_im = Image.new('RGB', (28 * sample_sqrt, 28 * sample_sqrt))\n",
        "\n",
        "    y_offset = 0\n",
        "    for i in range(sample_sqrt):\n",
        "        x_offset = 0\n",
        "        new_im = Image.new('RGB', (28 * sample_sqrt, 28))\n",
        "        for j in range(sample_sqrt):\n",
        "            im = deepcopy(generated_images[(i * sample_sqrt) + j])\n",
        "            new_im.paste(im, (x_offset, 0))\n",
        "            x_offset += 28\n",
        "        final_im.paste(new_im, (0, y_offset))\n",
        "        y_offset += 28\n",
        "        \n",
        "    final_im.save(model_name + '.png')"
      ],
      "execution_count": 568,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 28, 28, 1)\n",
            "num added: 297. num removed: 203\n",
            "(1, 28, 28, 1)\n",
            "num added: 272. num removed: 228\n",
            "(1, 28, 28, 1)\n",
            "num added: 305. num removed: 195\n",
            "(1, 28, 28, 1)\n",
            "num added: 283. num removed: 217\n",
            "(1, 28, 28, 1)\n",
            "num added: 282. num removed: 218\n",
            "(1, 28, 28, 1)\n",
            "num added: 223. num removed: 277\n",
            "(1, 28, 28, 1)\n",
            "num added: 253. num removed: 247\n",
            "(1, 28, 28, 1)\n",
            "num added: 294. num removed: 206\n",
            "(1, 28, 28, 1)\n",
            "num added: 300. num removed: 200\n",
            "(1, 28, 28, 1)\n",
            "num added: 193. num removed: 307\n",
            "(1, 28, 28, 1)\n",
            "num added: 305. num removed: 195\n",
            "(1, 28, 28, 1)\n",
            "num added: 222. num removed: 278\n",
            "(1, 28, 28, 1)\n",
            "num added: 252. num removed: 248\n",
            "(1, 28, 28, 1)\n",
            "num added: 270. num removed: 230\n",
            "(1, 28, 28, 1)\n",
            "num added: 343. num removed: 157\n",
            "(1, 28, 28, 1)\n",
            "num added: 290. num removed: 210\n",
            "(1, 28, 28, 1)\n",
            "num added: 225. num removed: 275\n",
            "(1, 28, 28, 1)\n",
            "num added: 247. num removed: 253\n",
            "(1, 28, 28, 1)\n",
            "num added: 329. num removed: 171\n",
            "(1, 28, 28, 1)\n",
            "num added: 236. num removed: 264\n",
            "(1, 28, 28, 1)\n",
            "num added: 239. num removed: 261\n",
            "(1, 28, 28, 1)\n",
            "num added: 250. num removed: 250\n",
            "(1, 28, 28, 1)\n",
            "num added: 195. num removed: 305\n",
            "(1, 28, 28, 1)\n",
            "num added: 255. num removed: 245\n",
            "(1, 28, 28, 1)\n",
            "num added: 319. num removed: 181\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}