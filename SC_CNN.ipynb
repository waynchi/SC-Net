{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VxF9dG1KU6Mf"
   },
   "source": [
    "# What about a GAN + Self correcting U-Net ? That would make for a cool architecture\n",
    "# Following CGAN -> adding a 1-hot vector encoding of the label to the training data\n",
    "# Simulated Annealing?\n",
    "# Generator -> VAE -> Discriminator?\n",
    "# What about feeding in a dicriminator's confidence level as a temperature during the autoregressive? Inverse confidence?\n",
    "# What about a 3 dimensional GAN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OlmEDomwi9dZ",
    "outputId": "ea9c9063-6f03-4d61-a3dd-22dddbb27ef2"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "def built_in_softmax_kl_loss(target, output):\n",
    "    target = K.flatten(target)\n",
    "    output = K.flatten(output)\n",
    "    \n",
    "    target = target / K.sum(target)\n",
    "    output = K.softmax(output)\n",
    "    return keras.losses.kullback_leibler_divergence(target, output)\n",
    "\n",
    "keras.losses.built_in_softmax_kl_loss = built_in_softmax_kl_loss\n",
    " \n",
    "def unet_model(input_size=(28, 28, 1), n_filters_start=16, growth_factor=2,\n",
    "               upconv=False):\n",
    "    droprate=0.1\n",
    "    n_filters = n_filters_start\n",
    "    inputs = Input(input_size)\n",
    "    conv_first = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv_first = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_first)\n",
    "    pool_first = MaxPooling2D(pool_size=(2, 2))(conv_first)\n",
    "\n",
    "    prev_pool = pool_first\n",
    "    hidden_layers = []\n",
    "    for _ in range(1):\n",
    "        n_filters *= growth_factor\n",
    "        pool = BatchNormalization()(prev_pool)\n",
    "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool)\n",
    "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv)\n",
    "        pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "        pool = Dropout(droprate)(pool)\n",
    "        prev_pool = pool\n",
    "        hidden_layers.append(conv)\n",
    " \n",
    "    n_filters *= growth_factor\n",
    "    conv_mid = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(prev_pool)\n",
    "    conv_mid = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_mid)\n",
    " \n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up_first = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv_mid), hidden_layers[-1]])\n",
    "    else:\n",
    "        up_first = concatenate([UpSampling2D(size=(2, 2))(conv_mid), hidden_layers[-1]])\n",
    "    up_first = BatchNormalization()(up_first)\n",
    "    conv_mid_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up_first)\n",
    "    conv_mid_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_mid_2)\n",
    "    conv_mid_2 = Dropout(droprate)(conv_mid_2)\n",
    "\n",
    "    prev_conv = conv_mid_2\n",
    "    for i in range(0):\n",
    "        n_filters //= growth_factor\n",
    "        if upconv:\n",
    "            up = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(prev_conv), hidden_layers[-i-2]])\n",
    "        else:\n",
    "            up = concatenate([UpSampling2D(size=(2, 2))(prev_conv), hidden_layers[-i-2]])\n",
    "        up = BatchNormalization()(up)\n",
    "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up)\n",
    "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv)\n",
    "        conv = Dropout(droprate)(conv)\n",
    "        prev_conv = conv\n",
    " \n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up_last = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv_mid_2), conv_first])\n",
    "    else:\n",
    "        up_last = concatenate([UpSampling2D(size=(2, 2))(conv_mid_2), conv_first])\n",
    "    conv_last = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up_last)\n",
    "    conv_last = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_last)\n",
    " \n",
    "    conv_out = Conv2D(1, 1, activation='linear')(conv_last)\n",
    " \n",
    "    model = Model(inputs=inputs, outputs=conv_out)\n",
    "    # model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer=Adam(), loss=built_in_softmax_kl_loss, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OeM4sX2NNYT0",
    "outputId": "6de853c8-7666-42e5-9d97-2fa53bfb2616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 10)\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import mnist\n",
    "import scipy.misc\n",
    "from PIL import Image\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "def create_image(image, name, image_shape=(28, 28)):\n",
    "    img_arr = deepcopy(image.reshape(image_shape)).astype(np.uint8)\n",
    "    # print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
    "    # print(img_arr)\n",
    "    img_arr[img_arr > 0] = 255\n",
    "    # pprint(img_arr)\n",
    "    # print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
    "    img = Image.fromarray(img_arr.astype(np.uint8), 'L')\n",
    "    img.save(name)\n",
    "    return img\n",
    "\n",
    "images = mnist.train_images()\n",
    "images[images > 0] = 1\n",
    "# images = images.reshape(images.shape[0], -1)\n",
    "print(images.shape)\n",
    "\n",
    "labels = mnist.train_labels()\n",
    "n_labels = np.max(labels) + 1\n",
    "labels = np.eye(n_labels)[labels]\n",
    "print(labels.shape)\n",
    "\n",
    "create_image(images[0], 'my.png')\n",
    "print(labels[0])\n",
    "\n",
    "# images = images[:1000, :, :]\n",
    "# print(images[0].shape)\n",
    "# pprint(images[0])\n",
    "# img = Image.fromarray(images[0], 'L')\n",
    "# img.save('my.png')\n",
    "# img.show()\n",
    "\n",
    "image_shape = np.expand_dims(images[0], axis=-1).shape \n",
    "# print(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "id": "rSjQr52iQzlu",
    "outputId": "a5ac23f9-e28f-4c85-ea5e-8a7ae367e852"
   },
   "outputs": [],
   "source": [
    "# model = unet_model(input_size=image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVUVU8Kt_aCm"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import math\n",
    "import itertools\n",
    "def mask_image(image):\n",
    "    image = deepcopy(image)\n",
    "    sampling_percentage = np.random.uniform(0, 100)\n",
    "    non_zero = np.nonzero(image)\n",
    "    mask1 = np.full(len(non_zero[0]), False)\n",
    "    mask1[:math.floor(len(non_zero[0]) * (sampling_percentage/100))] = True\n",
    "    np.random.shuffle(mask1)\n",
    "    # pprint(mask1)\n",
    "    r1 = list(itertools.compress(non_zero[0], mask1))\n",
    "    c1 = list(itertools.compress(non_zero[1], mask1))\n",
    "    output_image = deepcopy(image)\n",
    "    output_image[r1,c1] = 0\n",
    "    return output_image\n",
    "\n",
    "def mask_image_with_noise(image):\n",
    "    image = deepcopy(image)\n",
    "    sampling_percentage_mask = np.random.uniform(0, 100)\n",
    "    sampling_percentage_noise = np.random.uniform(0, 20)\n",
    "    non_zero = np.nonzero(image)\n",
    "    zeroes = np.nonzero(image == 0)\n",
    "    mask = np.full(len(non_zero[0]), False)\n",
    "    noise = np.full(len(zeroes[0]), False) \n",
    "    mask[:math.floor(len(non_zero[0]) * (sampling_percentage_mask/100))] = True\n",
    "    noise[:math.floor(len(non_zero[0]) * (sampling_percentage_noise/100))] = True\n",
    "    np.random.shuffle(mask)\n",
    "    np.random.shuffle(noise)\n",
    "    # pprint(mask1)\n",
    "    output_image = deepcopy(image)\n",
    "    r1 = list(itertools.compress(non_zero[0], mask))\n",
    "    c1 = list(itertools.compress(non_zero[1], mask))\n",
    "    r2 = list(itertools.compress(zeroes[0], noise))\n",
    "    c2 = list(itertools.compress(zeroes[1], noise))\n",
    "    output_image[r1,c1] = 0\n",
    "    output_image[r2,c2] = 1\n",
    "    return output_image\n",
    "\n",
    "class ImageGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, sample_list, image_shape, batch_size, samples_per_data_item, seed=None):\n",
    "        print(\"sample_list: {}\".format(len(sample_list)))\n",
    "        self.sample_list = sample_list\n",
    "        self.image_shape = image_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.samples_per_data_item = samples_per_data_item\n",
    "        self.training_input = []\n",
    "        self.training_target = []\n",
    "        self.training_original = []\n",
    "        self.sample_index = 0\n",
    "        self.seed = seed\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "\n",
    "    def generate_training_pairs(self):\n",
    "        '''\n",
    "        Generates Training Pairs till @training_input / @training_target have @batch_size files.\n",
    "        '''\n",
    "        while len(self.training_input) < self.batch_size:\n",
    "            original_image = self.sample_list[self.sample_index]\n",
    "            original_image = original_image.reshape(self.image_shape)\n",
    "            original_image[original_image > 0] = 1\n",
    "            self.sample_index = (self.sample_index + 1) % len(self.sample_list)\n",
    "            # print(\"sample_list length: {}. sample_index: {}\".format(\n",
    "            #     len(self.sample_list), self.sample_index))\n",
    "            try:\n",
    "                # augment by adding and removing random values in the array\n",
    "\n",
    "                # Add random values\n",
    "                for _ in range(self.samples_per_data_item):\n",
    "                    input_image = mask_image_with_noise(original_image)\n",
    "\n",
    "                    xor_target = np.logical_xor(input_image, original_image)\n",
    "                    input_image = input_image.astype(np.float32)\n",
    "                    xor_target = xor_target.astype(np.float32)\n",
    "                    original_image = original_image.astype(np.float32)\n",
    "                    self.training_input.append(deepcopy(input_image))\n",
    "                    self.training_original.append(deepcopy(original_image))\n",
    "                    self.training_target.append(deepcopy(xor_target))\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Error generating input and target pair')\n",
    "                traceback.print_exc()\n",
    "\n",
    "    def save_image(self, img_arr, img_name):\n",
    "        print(img_name)\n",
    "        print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
    "        img_arr = img_arr[:, :, 0]\n",
    "        print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
    "        #pprint(img_arr)\n",
    "        img_arr[img_arr != 0] = 255\n",
    "        #pprint(img_arr)\n",
    "        print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
    "        img = Image.fromarray(img_arr.astype(np.uint8), 'L')\n",
    "        img.save(img_name)\n",
    "\n",
    "    def get_random_training_pair(self):\n",
    "        import random\n",
    "        self.generate_training_pairs()\n",
    "        index = random.randrange(0, len(self.training_input))\n",
    "        self.save_image(deepcopy(self.training_input[index]), 'training_input.png')\n",
    "        self.save_image(deepcopy(self.training_target[index]), 'training_target.png')\n",
    "        self.save_image(deepcopy(self.training_original[index]), 'training_original.png')\n",
    "\n",
    "    def generate_validation_samples(self):\n",
    "        old_batch_size = self.batch_size\n",
    "        self.batch_size = len(self.sample_list) * self.samples_per_data_item\n",
    "        self.generate_training_pairs()\n",
    "        training_input = np.asarray(self.training_input[:self.batch_size])\n",
    "        training_target = np.asarray(self.training_target[:self.batch_size])\n",
    "        self.batch_size = old_batch_size\n",
    "        return training_input, training_target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Generates 1 batch of data'''\n",
    "        self.generate_training_pairs()\n",
    "        training_input = np.asarray(self.training_input[:self.batch_size])\n",
    "        training_target = np.asarray(self.training_target[:self.batch_size])\n",
    "        self.training_input = self.training_input[self.batch_size:]\n",
    "        self.training_target = self.training_target[self.batch_size:]\n",
    "        # print(\"training input sum: {}. target sum: {}\".format(training_input.sum(), training_target.sum()))\n",
    "        return training_input, training_target\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Number of batches / epoch'''\n",
    "        # print(\"sample_list: {}. samples_per_data_item: {}, batch size: {}\".\n",
    "        #       format(len(self.sample_list), self.samples_per_data_item,\n",
    "        #              self.batch_size))\n",
    "        samples_to_generate = int(\n",
    "            (len(self.sample_list) * self.samples_per_data_item) /\n",
    "            self.batch_size)\n",
    "        # print(\"samples to generate: {}\".format(samples_to_generate))\n",
    "        return samples_to_generate\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ngo7o_rw2TsK",
    "outputId": "0f4e3e63-e505-4fca-85a3-e8de0f7cfea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples: 48000. validation samples: 12000\n",
      "sample_list: 48000\n",
      "sample_list: 12000\n",
      "training_input.png\n",
      "img shape: (28, 28, 1). img sum: 77.0\n",
      "img shape: (28, 28). img sum: 77.0\n",
      "img shape: (28, 28). img sum: 19635.0\n",
      "training_target.png\n",
      "img shape: (28, 28, 1). img sum: 185.0\n",
      "img shape: (28, 28). img sum: 185.0\n",
      "img shape: (28, 28). img sum: 47175.0\n",
      "training_original.png\n",
      "img shape: (28, 28, 1). img sum: 216.0\n",
      "img shape: (28, 28). img sum: 216.0\n",
      "img shape: (28, 28). img sum: 55080.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "samples_per_data_item = 4\n",
    "\n",
    "split = 0.8\n",
    "\n",
    "training_samples = images[:int(len(images) * split)]\n",
    "validation_samples = images[int(len(images) * split):]\n",
    "\n",
    "print(\"training samples: {}. validation samples: {}\".format(len(training_samples), len(validation_samples)))\n",
    "\n",
    "steps_per_epoch = int(len(training_samples) * samples_per_data_item / batch_size)\n",
    "\n",
    "# pprint(training_samples[0])\n",
    "\n",
    "training_generator = ImageGenerator(\n",
    "    sample_list=training_samples,\n",
    "    image_shape=image_shape,\n",
    "    batch_size=batch_size,\n",
    "    samples_per_data_item=samples_per_data_item)\n",
    "\n",
    "validation_generator = ImageGenerator(\n",
    "    sample_list=validation_samples,\n",
    "    image_shape=image_shape,\n",
    "    batch_size=batch_size,\n",
    "    samples_per_data_item=samples_per_data_item,\n",
    "    seed=7)\n",
    "\n",
    "# validation_data = validation_generator.generate_validation_samples()\n",
    "\n",
    "# print(\"validation data input and target shape: {}\".format(validation_data[0].shape))\n",
    "validation_generator.get_random_training_pair()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TpnxtwGqOfDi"
   },
   "outputs": [],
   "source": [
    "#validation_data = validation_data_generator.generate_validation_pairs()\n",
    "#print(\"Done generating validation data\", getsizeof(validation_data), validation_data[0].nbytes)\n",
    "\n",
    "#tensorflow_log_dir = cfg.tensorboard_log_dir + cfg.experiment_name\n",
    "# checkpoint_path = cfg.checkpoint_root + cfg.experiment_name + \"-weights-epoch:{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "# checkpoint_path = cfg.checkpoint_root + cfg.experiment_name + \"-best-model-epoch:{epoch:04d}.hdf5\"\n",
    "\n",
    "# callbacks = keras_traning_callbacks(tensorflow_log_dir,\n",
    "                                      # checkpoint_path,\n",
    "                                      # tag=cfg.experiment_name,\n",
    "                                      # n_timesteps=n_timesteps,\n",
    "                                      # steps_per_log=steps_per_epoch,\n",
    "                                      # steps_per_save=steps_per_epoch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dQKfsm7sEpV0",
    "outputId": "eaf13d16-29dd-4792-8475-46df67f0cda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-6fd8bffda91a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     history = model.fit(\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mtraining_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1131\u001b[0m             training_utils.check_generator_arguments(\n\u001b[0;32m   1132\u001b[0m                 y, sample_weight, validation_split=validation_split)\n\u001b[1;32m-> 1133\u001b[1;33m             return self.fit_generator(\n\u001b[0m\u001b[0;32m   1134\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m                 \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1716\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1717\u001b[0m         \"\"\"\n\u001b[1;32m-> 1718\u001b[1;33m         return training_generator.fit_generator(\n\u001b[0m\u001b[0;32m   1719\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1720\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                 outs = model.train_on_batch(x, y,\n\u001b[0m\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3792\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3794\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m     \"\"\"\n\u001b[1;32m-> 1605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1645\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "# model = unet_model(input_size=(28, 28, 1))\n",
    "model = keras.models.load_model('sc-model.hdf5')\n",
    "\n",
    "#history = model.fit_generator(\n",
    "#    training_generator,\n",
    "    # validation_data=validation_data,\n",
    "\n",
    "#zeroed = deepcopy(training_samples)\n",
    "#zeroed[True] = 0\n",
    "#pprint(zeroed)\n",
    "#pprint(training_samples)\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(F'sc-model.hdf5'),\n",
    "    monitor='val_loss',\n",
    "    save_weights_only=False,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir='./logs', update_freq='epoch')\n",
    "\n",
    "if False:\n",
    "    history = model.fit(\n",
    "        training_generator,\n",
    "        validation_data=validation_generator,\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=200,\n",
    "        callbacks=[model_checkpoint_callback, tensorboard_callback])\n",
    "    #epochs=cfg.epochs,\n",
    "    #callbacks=callbacks)\n",
    "# model.save(\"sc-model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Loss\"\n",
    "if False:\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0IEPAcide5lS"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESgUWTkceMr3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n",
      "img shape: (28, 28). img sum: 406\n",
      "img shape: (28, 28). img sum: 103530\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model = keras.models.load_model('sc-model.hdf5')\n",
    "\n",
    "# input_image = mask_image_with_noise(images[0])\n",
    "input_image = np.random.rand(28, 28)\n",
    "input_image[input_image >= 0.5] = 1\n",
    "input_image[input_image < 0.5] = 0\n",
    "input_image = input_image.astype(np.float32)\n",
    "# pprint(input_image)\n",
    "input_image = np.expand_dims(input_image, 0)\n",
    "input_image = np.expand_dims(input_image, -1)\n",
    "print(input_image.shape)\n",
    "\n",
    "create_image(input_image, \"input.png\")\n",
    "\n",
    "\n",
    "working_image = deepcopy(input_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PBu4a18br7wL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "def inference(model, input_image, directory, iterations, temp_start=2, temp_end=0.5):\n",
    "    create_image(input_image, \"{}/input.png\".format(directory))\n",
    "\n",
    "    temperatures = np.linspace(temp_end, temp_start, num=iterations)[::-1]\n",
    "    # pprint(temperatures)\n",
    "    \n",
    "    working_image = deepcopy(input_image)\n",
    "    for i in range(iterations):\n",
    "        temp = temperatures[i]\n",
    "        predictions = model.predict(working_image)\n",
    "        predictions = predictions.flatten()\n",
    "        predictions = np.exp(predictions / temp)\n",
    "        predictions = predictions / np.sum(predictions)\n",
    "        # print(predictions)\n",
    "        indices = np.arange(predictions.shape[0])\n",
    "        index = np.random.choice(indices, p=predictions)\n",
    "        working_image = working_image.flatten()\n",
    "        if working_image[index] == 1:\n",
    "            working_image[index] = 0\n",
    "        elif working_image[index] == 0:\n",
    "            working_image[index] = 1\n",
    "        else:\n",
    "            print(working_image[index])\n",
    "        working_image = np.reshape(working_image, [1, *image_shape])\n",
    "        if i % 100 == 0:\n",
    "            create_image(working_image, os.path.join(directory, \"working_{}.png\".format(i)))\n",
    "\n",
    "    print(working_image.shape)\n",
    "    img = create_image(working_image, os.path.join(directory, \"final.png\"))\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "\n",
    "sample_sqrt = 5\n",
    "for i in range(sample_sqrt**2):\n",
    "    directory = \"images_{}\".format(i * j)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    input_image = np.random.rand(28, 28)\n",
    "    input_image[input_image >= 0.5] = 1\n",
    "    input_image[input_image < 0.5] = 0\n",
    "    input_image = input_image.astype(np.float32)\n",
    "    # pprint(input_image)\n",
    "    input_image = np.expand_dims(input_image, 0)\n",
    "    input_image = np.expand_dims(input_image, -1)\n",
    "\n",
    "    images.append(inference(model, input_image, directory, 2000, temp_start=2, temp_end=0.5))\n",
    "    \n",
    "final_im = Image.new('RGB', (28 * sample_sqrt, 28 * sample_sqrt))\n",
    "\n",
    "y_offset = 0\n",
    "for i in range(sample_sqrt):\n",
    "    x_offset = 0\n",
    "    new_im = Image.new('RGB', (28 * sample_sqrt, 28))\n",
    "    for j in range(sample_sqrt):\n",
    "        im = images[(i * sample_sqrt) + j]\n",
    "        new_im.paste(im, (x_offset, 0))\n",
    "        x_offset += 28\n",
    "    final_im.paste(new_im, (0, y_offset))\n",
    "    y_offset += 28\n",
    "    \n",
    "final_im.save('final.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DF783hh7cg_P"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SC-CNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
