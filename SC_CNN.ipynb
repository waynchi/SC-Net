{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SC_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waynchi/SC-Net/blob/master/SC_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U22qZkbsfEyI",
        "colab_type": "code",
        "outputId": "639efefb-217b-4d39-f294-dd9bfa8d557f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install mnist\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 491,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mnist in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mnist) (1.18.4)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45bLorRNFfdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LsQqrsgeqA1",
        "colab_type": "code",
        "outputId": "58ba97ad-dd15-4b3a-a4a6-b256f5d787b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.is_gpu_available()\n"
      ],
      "execution_count": 492,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 492
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VxF9dG1KU6Mf"
      },
      "source": [
        "# What about a GAN + Self correcting U-Net ? That would make for a cool architecture\n",
        "# Following CGAN -> adding a 1-hot vector encoding of the label to the training data\n",
        "# Simulated Annealing?\n",
        "# Generator -> VAE -> Discriminator?\n",
        "# What about feeding in a dicriminator's confidence level as a temperature during the autoregressive? Inverse confidence?\n",
        "# What about a 3 dimensional GAN?\n",
        "# What about adding attention to the model?\n",
        "\n",
        "# Umut Notes\n",
        "- Add a stop condition to the softmax\n",
        "    - Tried both 2 outputs and just an extra variable to the softmax\n",
        "    - 2 outputs fails due to it having too much weight to the loss and the loss fluctuates like crazy\n",
        "    - extra variable fails as the probability is still small even for an original image. Not sure why. Maybe because each time wew generate we use a new random which causes the dataset to be imbalanced?\n",
        "- 2 steps process (pick note and then choose how much through binary cross entropy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OeM4sX2NNYT0",
        "outputId": "2155c320-44ab-4ccf-a0bb-4a70c48394dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import mnist\n",
        "import scipy.misc\n",
        "from PIL import Image\n",
        "from pprint import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "\n",
        "def create_image(image, name, image_shape=(28, 28), is_grayscale=True):\n",
        "    img_arr = deepcopy(image.reshape(image_shape)).astype(np.float32)\n",
        "    img_arr = img_arr * 255.0\n",
        "\n",
        "    img = Image.fromarray(img_arr.astype(np.uint8), 'L')\n",
        "    # pprint(img_arr)\n",
        "    # print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "    img.save(name)\n",
        "    return img\n",
        "\n",
        "images = mnist.train_images()\n",
        "num_samples = 60000\n",
        "# np.random.shuffle(images)\n",
        "images = images[:num_samples, :, :]\n",
        "\n",
        "is_grayscale = True\n",
        "\n",
        "if not is_grayscale:\n",
        "    # For black and white\n",
        "    images[images > 0] = 1\n",
        "    # images = images / 255.0\n",
        "else:\n",
        "    # For grayscale\n",
        "    images = images / 255.0\n",
        "\n",
        "# pprint(images)\n",
        "print(images.shape)\n",
        "\n",
        "# labels = mnist.train_labels()\n",
        "# n_labels = np.max(labels) + 1\n",
        "# labels = np.eye(n_labels)[labels]\n",
        "# print(labels.shape)\n",
        "\n",
        "create_image(images[0], 'my.png', is_grayscale=is_grayscale)\n",
        "\n",
        "image_shape = np.expand_dims(images[0], axis=-1).shape \n",
        "# print(image_shape)"
      ],
      "execution_count": 493,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OlmEDomwi9dZ",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Flatten, Dense, Softmax\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "def built_in_softmax_kl_loss(target, output):\n",
        "    target = K.flatten(target)\n",
        "    output = K.flatten(output)\n",
        "    \n",
        "    target = target / K.sum(target)\n",
        "    output = K.softmax(output)\n",
        "    return keras.losses.kullback_leibler_divergence(target, output)\n",
        "\n",
        "keras.losses.built_in_softmax_kl_loss = built_in_softmax_kl_loss\n",
        " \n",
        "def unet_model(input_size=(28, 28, 1), n_filters_start=32, growth_factor=2,\n",
        "               upconv=False, is_grayscale=True):\n",
        "    droprate=0.5\n",
        "    n_filters = n_filters_start\n",
        "    inputs = Input(input_size)\n",
        "    conv_first = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv_first = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_first)\n",
        "    pool_first = MaxPooling2D(pool_size=(2, 2))(conv_first)\n",
        "\n",
        "    prev_pool = pool_first\n",
        "    hidden_layers = []\n",
        "    for _ in range(1):\n",
        "        n_filters *= growth_factor\n",
        "        pool = BatchNormalization()(prev_pool)\n",
        "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool)\n",
        "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv)\n",
        "        pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
        "        pool = Dropout(droprate)(pool)\n",
        "        prev_pool = pool\n",
        "        hidden_layers.append(conv)\n",
        " \n",
        "    n_filters *= growth_factor\n",
        "    conv_mid = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(prev_pool)\n",
        "    conv_mid = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_mid)\n",
        " \n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up_first = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv_mid), hidden_layers[-1]])\n",
        "    else:\n",
        "        up_first = concatenate([UpSampling2D(size=(2, 2))(conv_mid), hidden_layers[-1]])\n",
        "    up_first = BatchNormalization()(up_first)\n",
        "    conv_mid_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up_first)\n",
        "    conv_mid_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_mid_2)\n",
        "    conv_mid_2 = Dropout(droprate)(conv_mid_2)\n",
        "\n",
        "    prev_conv = conv_mid_2\n",
        "    for i in range(0):\n",
        "        n_filters //= growth_factor\n",
        "        if upconv:\n",
        "            up = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(prev_conv), hidden_layers[-i-2]])\n",
        "        else:\n",
        "            up = concatenate([UpSampling2D(size=(2, 2))(prev_conv), hidden_layers[-i-2]])\n",
        "        up = BatchNormalization()(up)\n",
        "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up)\n",
        "        conv = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv)\n",
        "        conv = Dropout(droprate)(conv)\n",
        "        prev_conv = conv\n",
        " \n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up_last = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv_mid_2), conv_first])\n",
        "    else:\n",
        "        up_last = concatenate([UpSampling2D(size=(2, 2))(conv_mid_2), conv_first])\n",
        "    conv_last = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up_last)\n",
        "    conv_last = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv_last)\n",
        " \n",
        "    softmax_out = Conv2D(1, 1, activation='linear')(conv_last)\n",
        "    # softmax_out = Flatten()(conv_out)\n",
        "\n",
        "    # flatten = Flatten()(conv_last)\n",
        "    # dense = Dense(1, activation='linear')(flatten)\n",
        "\n",
        "    # softmax_out = concatenate([conv_out, dense])\n",
        "\n",
        "    if is_grayscale:\n",
        "        sigmoid_out = Conv2D(1, 1, activation='sigmoid')(conv_last)\n",
        "        model = Model(inputs=inputs, outputs=[softmax_out, sigmoid_out])\n",
        "        model.compile(optimizer=Adam(), loss=[built_in_softmax_kl_loss, 'binary_crossentropy'], metrics=['accuracy'])\n",
        "    else:\n",
        "        model = Model(inputs=inputs, outputs=softmax_out)\n",
        "        model.compile(optimizer=Adam(), loss=built_in_softmax_kl_loss)\n",
        "\n",
        "    # model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rSjQr52iQzlu",
        "outputId": "48e101fa-3f9b-420a-c9a9-9328d2880d4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "model = unet_model(input_size=image_shape, is_grayscale=is_grayscale)"
      ],
      "execution_count": 495,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_60\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_60 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_670 (Conv2D)             (None, 28, 28, 32)   320         input_60[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_671 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_670[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_119 (MaxPooling2D (None, 14, 14, 32)   0           conv2d_671[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 14, 14, 32)   128         max_pooling2d_119[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_672 (Conv2D)             (None, 14, 14, 64)   18496       batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_673 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_672[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_120 (MaxPooling2D (None, 7, 7, 64)     0           conv2d_673[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_119 (Dropout)           (None, 7, 7, 64)     0           max_pooling2d_120[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_674 (Conv2D)             (None, 7, 7, 128)    73856       dropout_119[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_675 (Conv2D)             (None, 7, 7, 128)    147584      conv2d_674[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_119 (UpSampling2D (None, 14, 14, 128)  0           conv2d_675[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_119 (Concatenate)   (None, 14, 14, 192)  0           up_sampling2d_119[0][0]          \n",
            "                                                                 conv2d_673[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 14, 14, 192)  768         concatenate_119[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_676 (Conv2D)             (None, 14, 14, 64)   110656      batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_677 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_676[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_120 (Dropout)           (None, 14, 14, 64)   0           conv2d_677[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_120 (UpSampling2D (None, 28, 28, 64)   0           dropout_120[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_120 (Concatenate)   (None, 28, 28, 96)   0           up_sampling2d_120[0][0]          \n",
            "                                                                 conv2d_671[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_678 (Conv2D)             (None, 28, 28, 32)   27680       concatenate_120[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_679 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_678[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_680 (Conv2D)             (None, 28, 28, 1)    33          conv2d_679[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_681 (Conv2D)             (None, 28, 28, 1)    33          conv2d_679[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 471,906\n",
            "Trainable params: 471,458\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsFM5XMYeqBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBEdqEBxFqNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# discriminator_model = discriminator(input_size=image_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SVUVU8Kt_aCm",
        "colab": {}
      },
      "source": [
        "from copy import deepcopy\n",
        "import math\n",
        "import itertools\n",
        "def mask_image(image, is_grayscale=True):\n",
        "    image = deepcopy(image)\n",
        "    sampling_percentage = np.random.uniform(0, 100)\n",
        "    non_zero = np.nonzero(image)\n",
        "    mask1 = np.full(len(non_zero[0]), False)\n",
        "    mask1[:math.floor(len(non_zero[0]) * (sampling_percentage/100))] = True\n",
        "    np.random.shuffle(mask1)\n",
        "    # pprint(mask1)\n",
        "    r1 = list(itertools.compress(non_zero[0], mask1))\n",
        "    c1 = list(itertools.compress(non_zero[1], mask1))\n",
        "    output_image = deepcopy(image)\n",
        "    output_image[r1,c1] = 0\n",
        "    return output_image\n",
        "\n",
        "def mask_image_with_noise(image, is_grayscale=True):\n",
        "    image = deepcopy(image)\n",
        "    sampling_percentage_mask = np.random.uniform(0, 100)\n",
        "    sampling_percentage_noise = np.random.uniform(0, 20)\n",
        "    non_zero = np.nonzero(image)\n",
        "    zeroes = np.nonzero(image == 0)\n",
        "    mask = np.full(len(non_zero[0]), False)\n",
        "    noise = np.full(len(zeroes[0]), False) \n",
        "    amount_to_mask = math.floor(len(non_zero[0]) * (sampling_percentage_mask/100))\n",
        "    mask[:amount_to_mask] = True\n",
        "    amount_to_mask_2 = math.floor(len(zeroes[0]) * (sampling_percentage_noise/100))\n",
        "    noise[:amount_to_mask_2] = True\n",
        "    np.random.shuffle(mask)\n",
        "    np.random.shuffle(noise)\n",
        "    # pprint(mask1)\n",
        "    output_image = deepcopy(image)\n",
        "    r1 = list(itertools.compress(non_zero[0], mask))\n",
        "    c1 = list(itertools.compress(non_zero[1], mask))\n",
        "    r2 = list(itertools.compress(zeroes[0], noise))\n",
        "    c2 = list(itertools.compress(zeroes[1], noise))\n",
        "    output_image[r1,c1] = 0\n",
        "    output_image[r2,c2] = 1\n",
        "    return output_image\n",
        "\n",
        "class ImageGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, sample_list, image_shape, batch_size, samples_per_data_item, stops_per_data_item, is_grayscale=True, seed=None):\n",
        "        print(\"sample_list: {}\".format(len(sample_list)))\n",
        "        self.sample_list = sample_list\n",
        "        self.image_shape = image_shape\n",
        "        self.batch_size = batch_size\n",
        "        self.samples_per_data_item = samples_per_data_item\n",
        "        self.stops_per_data_item = stops_per_data_item\n",
        "        self.is_grayscale = is_grayscale\n",
        "        # self.training_input = []\n",
        "        # self.training_target = []\n",
        "        # self.training_original = []\n",
        "        self.sample_index = 0\n",
        "        self.seed = seed\n",
        "        # if self.seed is not None:\n",
        "        #     np.random.seed(self.seed)\n",
        "\n",
        "    def generate_training_pairs(self):\n",
        "        '''\n",
        "        Generates Training Pairs till @training_input / @training_target have @batch_size files.\n",
        "        '''\n",
        "        training_input = []\n",
        "        training_original = []\n",
        "        training_target = []\n",
        "        while len(training_input) < self.batch_size:\n",
        "            original_image = deepcopy(self.sample_list[self.sample_index])\n",
        "            original_image = original_image.reshape(self.image_shape)\n",
        "            binary_image = deepcopy(original_image)\n",
        "            binary_image[binary_image > 0] = 1\n",
        "            self.sample_index = (self.sample_index + 1) % len(self.sample_list)\n",
        "            # print(\"sample_list length: {}. sample_index: {}\".format(\n",
        "            #     len(self.sample_list), self.sample_index))\n",
        "            try:\n",
        "                # augment by adding and removing random values in the array\n",
        "\n",
        "                # Add random values\n",
        "                for _ in range(self.samples_per_data_item):\n",
        "                    input_image = mask_image_with_noise(binary_image, is_grayscale=self.is_grayscale)\n",
        "\n",
        "                    input_image = input_image.astype(np.float32)\n",
        "                    original_image = original_image.astype(np.float32)\n",
        "\n",
        "                    xor_target = np.logical_xor(input_image, binary_image)\n",
        "                    xor_target = xor_target.astype(np.float32)\n",
        "                    # xor_target = xor_target.flatten()\n",
        "                    # xor_target = np.append(xor_target, 0.0)\n",
        "                    \n",
        "                    training_input.append(deepcopy(input_image))\n",
        "                    training_original.append(deepcopy(original_image))\n",
        "                    training_target.append(deepcopy(xor_target))\n",
        "\n",
        "                # Add original\n",
        "                for _ in range(self.stops_per_data_item):\n",
        "                    training_input.append(deepcopy(original_image.astype(np.float32)))\n",
        "                    training_original.append(deepcopy(original_image.astype(np.float32)))\n",
        "                    xor_target = np.full(np.prod(self.image_shape), 0.0, dtype=np.float32)\n",
        "                    xor_target = np.append(xor_target, 1.0)\n",
        "                    training_target.append(deepcopy(xor_target))\n",
        "\n",
        "            except Exception as e:\n",
        "                print('Error generating input and target pair')\n",
        "                traceback.print_exc()\n",
        "        return np.asarray(training_input), np.asarray(training_target), np.asarray(training_original)\n",
        "\n",
        "    def save_image(self, img_arr, img_name):\n",
        "        # img_arr = img_arr.reshape(self.image_shape)\n",
        "        print(img_name)\n",
        "        print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "        img_arr = img_arr[:, :, 0]\n",
        "        print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "        #pprint(img_arr)\n",
        "        img_arr = img_arr * 255\n",
        "        #pprint(img_arr)\n",
        "        print(\"img shape: {}. img sum: {}\".format(img_arr.shape, img_arr.sum()))\n",
        "        img = Image.fromarray(img_arr.astype(np.uint8), 'L')\n",
        "        img.save(img_name)\n",
        "\n",
        "    def get_random_training_pair(self):\n",
        "        import random\n",
        "        training_input, training_target, training_original = self.generate_training_pairs()\n",
        "        print(\"training_input shape: {}\".format(training_input.shape))\n",
        "        index = random.randrange(0, len(training_input))\n",
        "        self.save_image(deepcopy(training_input[index]), 'training_input.png')\n",
        "        # training_image = training_target[index][:np.prod(self.image_shape)]\n",
        "        # print(training_target[index][-1])\n",
        "        self.save_image(deepcopy(training_target[index]), 'training_target.png')\n",
        "        self.save_image(deepcopy(training_original[index]), 'training_original.png')\n",
        "\n",
        "    def generate_validation_samples(self):\n",
        "        old_batch_size = self.batch_size\n",
        "        self.batch_size = len(self.sample_list) * (self.samples_per_data_item + self.stops_per_data_item)\n",
        "        training_input, training_target, training_original = self.generate_training_pairs()\n",
        "        # training_input = np.asarray(self.training_input[:self.batch_size])\n",
        "        # training_target = np.asarray(self.training_target[:self.batch_size])\n",
        "        self.batch_size = old_batch_size\n",
        "        if self.is_grayscale:\n",
        "            return training_input, [training_target, training_original]\n",
        "        else:\n",
        "            return training_input, training_target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''Generates 1 batch of data'''\n",
        "        training_input, training_target, training_original = self.generate_training_pairs()\n",
        "        # training_input = np.asarray(self.training_input[:self.batch_size])\n",
        "        # training_target = np.asarray(self.training_target[:self.batch_size])\n",
        "        # self.training_input = self.training_input[self.batch_size:]\n",
        "        # self.training_target = self.training_target[self.batch_size:]\n",
        "        # print(\"training input sum: {}. target sum: {}\".format(training_input.sum(), training_target.sum()))\n",
        "        if is_grayscale:\n",
        "            return np.asarray(training_input), [np.asarray(training_target), np.asarray(training_original)]\n",
        "        else:\n",
        "            return np.asarray(training_input), np.asarray(training_target)\n",
        "\n",
        "    def __len__(self):\n",
        "        '''Number of batches / epoch'''\n",
        "        # print(\"sample_list: {}. samples_per_data_item: {}, batch size: {}\".\n",
        "        #       format(len(self.sample_list), self.samples_per_data_item,\n",
        "        #              self.batch_size))\n",
        "        samples_to_generate = int(\n",
        "            (len(self.sample_list) * (self.samples_per_data_item + self.stops_per_data_item)) /\n",
        "            self.batch_size)\n",
        "        # print(\"samples to generate: {}\".format(samples_to_generate))\n",
        "        return samples_to_generate\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        pass\n",
        "        # np.random.seed(7)\n",
        "    #    if self.seed is not None:\n",
        "    #        np.random.seed(self.seed)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1zwLYew1a-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Config\n",
        "batch_size = 128\n",
        "samples_per_data_item = 4\n",
        "stops_per_data_item = 0\n",
        "split = 0.8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ngo7o_rw2TsK",
        "outputId": "05895f6d-902c-45dd-d6b7-17f0ac2deba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "\n",
        "training_samples = images[:int(len(images) * split)]\n",
        "validation_samples = images[int(len(images) * split):]\n",
        "\n",
        "print(\"training samples: {}. validation samples: {}\".format(len(training_samples), len(validation_samples)))\n",
        "\n",
        "steps_per_epoch = int(len(training_samples) * (samples_per_data_item + stops_per_data_item) / batch_size)\n",
        "print(\"steps per epoch: {}\".format(steps_per_epoch))\n",
        "\n",
        "# pprint(training_samples[0])\n",
        "\n",
        "training_generator = ImageGenerator(\n",
        "    sample_list=training_samples,\n",
        "    image_shape=image_shape,\n",
        "    batch_size=batch_size,\n",
        "    samples_per_data_item=samples_per_data_item,\n",
        "    stops_per_data_item=stops_per_data_item,\n",
        "    is_grayscale=is_grayscale)\n",
        "\n",
        "validation_generator = ImageGenerator(\n",
        "    sample_list=validation_samples,\n",
        "    image_shape=image_shape,\n",
        "    batch_size=batch_size,\n",
        "    samples_per_data_item=samples_per_data_item,\n",
        "    stops_per_data_item=stops_per_data_item,\n",
        "    is_grayscale=is_grayscale)\n",
        "\n",
        "validation_data = validation_generator.generate_validation_samples()\n",
        "\n",
        "# print(\"validation data input and target shape: {}\".format(validation_data[0].shape))\n",
        "training_generator.get_random_training_pair()\n",
        "\n",
        "\n"
      ],
      "execution_count": 499,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training samples: 48000. validation samples: 12000\n",
            "steps per epoch: 1500\n",
            "sample_list: 48000\n",
            "sample_list: 12000\n",
            "training_input shape: (128, 28, 28, 1)\n",
            "training_input.png\n",
            "img shape: (28, 28, 1). img sum: 57.0\n",
            "img shape: (28, 28). img sum: 57.0\n",
            "img shape: (28, 28). img sum: 14535.0\n",
            "training_target.png\n",
            "img shape: (28, 28, 1). img sum: 243.0\n",
            "img shape: (28, 28). img sum: 243.0\n",
            "img shape: (28, 28). img sum: 61965.0\n",
            "training_original.png\n",
            "img shape: (28, 28, 1). img sum: 138.95294189453125\n",
            "img shape: (28, 28). img sum: 138.95294189453125\n",
            "img shape: (28, 28). img sum: 35433.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk-zvNP9DGWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_location = F'/content/drive/My Drive/sc-model-es-net-60000-4.hdf5'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dQKfsm7sEpV0",
        "outputId": "6124b9c2-a638-4333-e322-bc1fcac0d004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "\n",
        "model = unet_model(input_size=image_shape, is_grayscale=is_grayscale)\n",
        "# model = keras.models.load_model(model_location)\n",
        "\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_location,\n",
        "    monitor='val_loss',\n",
        "    save_weights_only=False,\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    save_best_only=False)\n",
        "\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir='./logs', update_freq='epoch')\n",
        "\n",
        "if True:\n",
        "    history = model.fit(\n",
        "        training_generator,\n",
        "        validation_data=validation_data,\n",
        "        verbose=1,\n",
        "        shuffle=True,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=30,\n",
        "        callbacks=[model_checkpoint_callback])#, tensorboard_callback])\n",
        "    #epochs=cfg.epochs,\n",
        "    #callbacks=callbacks)\n",
        "# model.save(\"sc-model.hdf5\")"
      ],
      "execution_count": 501,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_61\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_61 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_682 (Conv2D)             (None, 28, 28, 32)   320         input_61[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_683 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_682[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_121 (MaxPooling2D (None, 14, 14, 32)   0           conv2d_683[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 14, 14, 32)   128         max_pooling2d_121[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_684 (Conv2D)             (None, 14, 14, 64)   18496       batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_685 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_684[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_122 (MaxPooling2D (None, 7, 7, 64)     0           conv2d_685[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_121 (Dropout)           (None, 7, 7, 64)     0           max_pooling2d_122[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_686 (Conv2D)             (None, 7, 7, 128)    73856       dropout_121[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_687 (Conv2D)             (None, 7, 7, 128)    147584      conv2d_686[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_121 (UpSampling2D (None, 14, 14, 128)  0           conv2d_687[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_121 (Concatenate)   (None, 14, 14, 192)  0           up_sampling2d_121[0][0]          \n",
            "                                                                 conv2d_685[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 14, 14, 192)  768         concatenate_121[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_688 (Conv2D)             (None, 14, 14, 64)   110656      batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_689 (Conv2D)             (None, 14, 14, 64)   36928       conv2d_688[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_122 (Dropout)           (None, 14, 14, 64)   0           conv2d_689[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_122 (UpSampling2D (None, 28, 28, 64)   0           dropout_122[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_122 (Concatenate)   (None, 28, 28, 96)   0           up_sampling2d_122[0][0]          \n",
            "                                                                 conv2d_683[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_690 (Conv2D)             (None, 28, 28, 32)   27680       concatenate_122[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_691 (Conv2D)             (None, 28, 28, 32)   9248        conv2d_690[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_692 (Conv2D)             (None, 28, 28, 1)    33          conv2d_691[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_693 (Conv2D)             (None, 28, 28, 1)    33          conv2d_691[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 471,906\n",
            "Trainable params: 471,458\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "1500/1500 [==============================] - 80s 53ms/step - loss: 0.6909 - conv2d_692_loss: 0.5205 - conv2d_693_loss: 0.1704 - conv2d_692_accuracy: 0.1369 - conv2d_693_accuracy: 0.8058 - val_loss: 0.6241 - val_conv2d_692_loss: 0.4641 - val_conv2d_693_loss: 0.1600 - val_conv2d_692_accuracy: 0.0337 - val_conv2d_693_accuracy: 0.8064\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 2/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.6197 - conv2d_692_loss: 0.4597 - conv2d_693_loss: 0.1600 - conv2d_692_accuracy: 0.0069 - conv2d_693_accuracy: 0.8062 - val_loss: 0.6057 - val_conv2d_692_loss: 0.4485 - val_conv2d_693_loss: 0.1572 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8079\n",
            "\n",
            "Epoch 00002: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 3/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.6044 - conv2d_692_loss: 0.4475 - conv2d_693_loss: 0.1569 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8063 - val_loss: 0.5932 - val_conv2d_692_loss: 0.4377 - val_conv2d_693_loss: 0.1554 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8054\n",
            "\n",
            "Epoch 00003: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 4/30\n",
            "1500/1500 [==============================] - 79s 53ms/step - loss: 0.5972 - conv2d_692_loss: 0.4413 - conv2d_693_loss: 0.1559 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8062 - val_loss: 0.5864 - val_conv2d_692_loss: 0.4324 - val_conv2d_693_loss: 0.1541 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8049\n",
            "\n",
            "Epoch 00004: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 5/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5925 - conv2d_692_loss: 0.4376 - conv2d_693_loss: 0.1549 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8062 - val_loss: 0.5799 - val_conv2d_692_loss: 0.4274 - val_conv2d_693_loss: 0.1526 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8066\n",
            "\n",
            "Epoch 00005: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 6/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5871 - conv2d_692_loss: 0.4332 - conv2d_693_loss: 0.1539 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8062 - val_loss: 0.5814 - val_conv2d_692_loss: 0.4284 - val_conv2d_693_loss: 0.1530 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8059\n",
            "\n",
            "Epoch 00006: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 7/30\n",
            "1500/1500 [==============================] - 79s 53ms/step - loss: 0.5839 - conv2d_692_loss: 0.4307 - conv2d_693_loss: 0.1533 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8063 - val_loss: 0.5735 - val_conv2d_692_loss: 0.4222 - val_conv2d_693_loss: 0.1512 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8064\n",
            "\n",
            "Epoch 00007: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 8/30\n",
            "1500/1500 [==============================] - 79s 53ms/step - loss: 0.5823 - conv2d_692_loss: 0.4291 - conv2d_693_loss: 0.1532 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8064 - val_loss: 0.5724 - val_conv2d_692_loss: 0.4214 - val_conv2d_693_loss: 0.1510 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8072\n",
            "\n",
            "Epoch 00008: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 9/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5793 - conv2d_692_loss: 0.4268 - conv2d_693_loss: 0.1525 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8065 - val_loss: 0.5691 - val_conv2d_692_loss: 0.4189 - val_conv2d_693_loss: 0.1503 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8070\n",
            "\n",
            "Epoch 00009: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 10/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5766 - conv2d_692_loss: 0.4246 - conv2d_693_loss: 0.1520 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8065 - val_loss: 0.5688 - val_conv2d_692_loss: 0.4185 - val_conv2d_693_loss: 0.1503 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8063\n",
            "\n",
            "Epoch 00010: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 11/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5772 - conv2d_692_loss: 0.4251 - conv2d_693_loss: 0.1522 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8066 - val_loss: 0.5683 - val_conv2d_692_loss: 0.4181 - val_conv2d_693_loss: 0.1502 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8061\n",
            "\n",
            "Epoch 00011: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 12/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5743 - conv2d_692_loss: 0.4227 - conv2d_693_loss: 0.1516 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8066 - val_loss: 0.5671 - val_conv2d_692_loss: 0.4172 - val_conv2d_693_loss: 0.1500 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8069\n",
            "\n",
            "Epoch 00012: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 13/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5729 - conv2d_692_loss: 0.4214 - conv2d_693_loss: 0.1514 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8066 - val_loss: 0.5665 - val_conv2d_692_loss: 0.4166 - val_conv2d_693_loss: 0.1500 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8067\n",
            "\n",
            "Epoch 00013: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 14/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5721 - conv2d_692_loss: 0.4209 - conv2d_693_loss: 0.1512 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8066 - val_loss: 0.5645 - val_conv2d_692_loss: 0.4150 - val_conv2d_693_loss: 0.1495 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8067\n",
            "\n",
            "Epoch 00014: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 15/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5698 - conv2d_692_loss: 0.4191 - conv2d_693_loss: 0.1507 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8068 - val_loss: 0.5626 - val_conv2d_692_loss: 0.4133 - val_conv2d_693_loss: 0.1493 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8069\n",
            "\n",
            "Epoch 00015: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 16/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5689 - conv2d_692_loss: 0.4183 - conv2d_693_loss: 0.1506 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8068 - val_loss: 0.5640 - val_conv2d_692_loss: 0.4146 - val_conv2d_693_loss: 0.1494 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8071\n",
            "\n",
            "Epoch 00016: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 17/30\n",
            "1500/1500 [==============================] - 77s 52ms/step - loss: 0.5686 - conv2d_692_loss: 0.4182 - conv2d_693_loss: 0.1504 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8068 - val_loss: 0.5646 - val_conv2d_692_loss: 0.4153 - val_conv2d_693_loss: 0.1494 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8065\n",
            "\n",
            "Epoch 00017: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 18/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5680 - conv2d_692_loss: 0.4175 - conv2d_693_loss: 0.1505 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8068 - val_loss: 0.5637 - val_conv2d_692_loss: 0.4143 - val_conv2d_693_loss: 0.1494 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8074\n",
            "\n",
            "Epoch 00018: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 19/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5680 - conv2d_692_loss: 0.4176 - conv2d_693_loss: 0.1504 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8068 - val_loss: 0.5612 - val_conv2d_692_loss: 0.4121 - val_conv2d_693_loss: 0.1491 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8062\n",
            "\n",
            "Epoch 00019: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 20/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5659 - conv2d_692_loss: 0.4158 - conv2d_693_loss: 0.1501 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8068 - val_loss: 0.5640 - val_conv2d_692_loss: 0.4146 - val_conv2d_693_loss: 0.1494 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8065\n",
            "\n",
            "Epoch 00020: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 21/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5669 - conv2d_692_loss: 0.4166 - conv2d_693_loss: 0.1502 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8067 - val_loss: 0.5605 - val_conv2d_692_loss: 0.4117 - val_conv2d_693_loss: 0.1488 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8073\n",
            "\n",
            "Epoch 00021: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 22/30\n",
            "1500/1500 [==============================] - 79s 53ms/step - loss: 0.5662 - conv2d_692_loss: 0.4161 - conv2d_693_loss: 0.1501 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8068 - val_loss: 0.5598 - val_conv2d_692_loss: 0.4111 - val_conv2d_693_loss: 0.1487 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8062\n",
            "\n",
            "Epoch 00022: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 23/30\n",
            "1500/1500 [==============================] - 79s 53ms/step - loss: 0.5657 - conv2d_692_loss: 0.4156 - conv2d_693_loss: 0.1501 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8068 - val_loss: 0.5591 - val_conv2d_692_loss: 0.4105 - val_conv2d_693_loss: 0.1486 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8065\n",
            "\n",
            "Epoch 00023: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 24/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5643 - conv2d_692_loss: 0.4145 - conv2d_693_loss: 0.1498 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8069 - val_loss: 0.5592 - val_conv2d_692_loss: 0.4106 - val_conv2d_693_loss: 0.1485 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8060\n",
            "\n",
            "Epoch 00024: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 25/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5633 - conv2d_692_loss: 0.4138 - conv2d_693_loss: 0.1495 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8069 - val_loss: 0.5585 - val_conv2d_692_loss: 0.4101 - val_conv2d_693_loss: 0.1484 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8065\n",
            "\n",
            "Epoch 00025: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 26/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5635 - conv2d_692_loss: 0.4140 - conv2d_693_loss: 0.1495 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8069 - val_loss: 0.5589 - val_conv2d_692_loss: 0.4103 - val_conv2d_693_loss: 0.1487 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8057\n",
            "\n",
            "Epoch 00026: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 27/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5620 - conv2d_692_loss: 0.4128 - conv2d_693_loss: 0.1493 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8069 - val_loss: 0.5588 - val_conv2d_692_loss: 0.4102 - val_conv2d_693_loss: 0.1486 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8063\n",
            "\n",
            "Epoch 00027: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 28/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5618 - conv2d_692_loss: 0.4125 - conv2d_693_loss: 0.1493 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8069 - val_loss: 0.5578 - val_conv2d_692_loss: 0.4096 - val_conv2d_693_loss: 0.1483 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8071\n",
            "\n",
            "Epoch 00028: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 29/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5628 - conv2d_692_loss: 0.4134 - conv2d_693_loss: 0.1494 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8070 - val_loss: 0.5585 - val_conv2d_692_loss: 0.4100 - val_conv2d_693_loss: 0.1485 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8065\n",
            "\n",
            "Epoch 00029: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n",
            "Epoch 30/30\n",
            "1500/1500 [==============================] - 78s 52ms/step - loss: 0.5620 - conv2d_692_loss: 0.4125 - conv2d_693_loss: 0.1495 - conv2d_692_accuracy: 0.0000e+00 - conv2d_693_accuracy: 0.8069 - val_loss: 0.5593 - val_conv2d_692_loss: 0.4107 - val_conv2d_693_loss: 0.1486 - val_conv2d_692_accuracy: 0.0000e+00 - val_conv2d_693_accuracy: 0.8069\n",
            "\n",
            "Epoch 00030: saving model to /content/drive/My Drive/sc-model-es-net-60000-4.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKxrjiG_eqBO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f1760da0-cc4e-4766-b1a0-ca7a1c569753"
      },
      "source": [
        "# \"Loss\"\n",
        "if True:\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 502,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0IEPAcide5lS"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF8wPwoAo_xp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "d9f50c95-f7d5-4e3b-af3e-bf708f7a0cb8"
      },
      "source": [
        "# testing model predict with seaborn and plots\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_noise():\n",
        "    input_image = np.full((28, 28), 0)\n",
        "\n",
        "    # Random noise\n",
        "    # input_image = np.random.rand(28, 28)\n",
        "    # input_image[input_image >= 0.5] = 1\n",
        "    # input_image[input_image < 0.5] = 0\n",
        "\n",
        "    input_image = input_image.astype(np.float32)\n",
        "    input_image = np.expand_dims(input_image, 0)\n",
        "    input_image = np.expand_dims(input_image, -1)\n",
        "    return input_image\n",
        "\n",
        "test_image = generate_noise()\n",
        "if is_grayscale:\n",
        "    softmax_predictions, sigmoid_predictions = model.predict(test_image)\n",
        "    softmax_predictions = softmax_predictions.reshape(28, 28)\n",
        "    softmax_predictions = np.exp(softmax_predictions)\n",
        "    softmax_predictions = softmax_predictions / np.sum(softmax_predictions)\n",
        "    sigmoid_predictions = sigmoid_predictions.reshape(28, 28)\n",
        "    heatmap = sb.heatmap(softmax_predictions)\n",
        "    plt.show()\n",
        "    heatmap = sb.heatmap(sigmoid_predictions)\n",
        "else:\n",
        "    softmax_predictions = model.predict(test_image)\n",
        "    softmax_predictions = softmax_predictions.reshape(28, 28)\n",
        "    softmax_predictions = np.exp(softmax_predictions)\n",
        "    softmax_predictions = softmax_predictions / np.sum(softmax_predictions)\n",
        "    heatmap = sb.heatmap(softmax_predictions)\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 503,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PBu4a18br7wL",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "\n",
        "def inference(model, input_image, directory, iterations, temp_start=2, temp_end=0.5, top_k=250, is_grayscale=True, is_debug=False, filename='final.png'):\n",
        "    create_image(input_image, \"{}/input.png\".format(directory))\n",
        "\n",
        "    temperatures = np.linspace(temp_end, temp_start, num=iterations)[::-1]\n",
        "    # pprint(temperatures)\n",
        "    \n",
        "    working_image = deepcopy(input_image)\n",
        "    working_images = []\n",
        "    num_added = 0\n",
        "    num_removed = 0\n",
        "    for i in range(iterations):\n",
        "        temp = temperatures[i]            \n",
        "        binary_image = deepcopy(working_image)\n",
        "        binary_image[binary_image > 0] = 1\n",
        "        if is_grayscale:\n",
        "            softmax_predictions, sigmoid_predictions = model.predict(binary_image)\n",
        "        else:\n",
        "            softmax_predictions = model.predict(binary_image)\n",
        "\n",
        "        softmax_predictions = softmax_predictions.flatten()\n",
        "        if is_grayscale:\n",
        "            sigmoid_predictions = sigmoid_predictions.flatten()\n",
        "\n",
        "        softmax_predictions = np.exp(softmax_predictions / temp)\n",
        "        softmax_predictions = softmax_predictions / np.sum(softmax_predictions)\n",
        "        softmax_predictions = np.nan_to_num(softmax_predictions)\n",
        "        # print(softmax_predictions)\n",
        "        # print(softmax_predictions[-1])\n",
        "        indices = np.arange(softmax_predictions.shape[0])\n",
        "\n",
        "        zipped = zip(softmax_predictions, indices)\n",
        "        zipped = list(reversed(sorted(zipped, key = lambda x : x[0])))\n",
        "        zipped = zipped[:top_k]\n",
        "        zipped = sorted(zipped, key=lambda x : x[1])\n",
        "        softmax_predictions, indices = zip(*zipped)\n",
        "        softmax_predictions = np.asarray(softmax_predictions)\n",
        "        softmax_predictions = softmax_predictions / np.sum(softmax_predictions)\n",
        "        indices = np.asarray(indices)\n",
        "\n",
        "        index = np.random.choice(indices, p=softmax_predictions)\n",
        "        working_image = working_image.flatten()\n",
        "        # if index == softmax_predictions.shape[0]:\n",
        "        #     print(\"stopping\")\n",
        "            # break\n",
        "        if is_grayscale:\n",
        "            if working_image[index] != 0:\n",
        "                num_removed += 1\n",
        "            elif working_image[index] == 0:\n",
        "                num_added += 1\n",
        "            working_image[index] = sigmoid_predictions[index]\n",
        "        else:\n",
        "            if working_image[index] == 1:\n",
        "                num_removed += 1\n",
        "                working_image[index] = 0\n",
        "            elif working_image[index] == 0:\n",
        "                num_added += 1\n",
        "                working_image[index] = 1\n",
        "            else:\n",
        "                print(working_image[index])\n",
        "        working_image = np.reshape(working_image, [1, *image_shape])\n",
        "        if i % 10 == 0:\n",
        "            if is_debug:\n",
        "                print(\"softmax\")\n",
        "                softmax_predictions = softmax_predictions.reshape(28, 28)\n",
        "                heatmap = sb.heatmap(deepcopy(softmax_predictions))\n",
        "                plt.show()\n",
        "                print(\"sigmoid\")\n",
        "                sigmoid_predictions = sigmoid_predictions.reshape(28, 28)\n",
        "                heatmap = sb.heatmap(deepcopy(sigmoid_predictions))\n",
        "                plt.show()\n",
        "            create_image(working_image, os.path.join(directory, \"working_{}.png\".format(i)))\n",
        "\n",
        "    final_image = working_image\n",
        "    final_binary_image = deepcopy(final_image)\n",
        "    final_binary_image[final_binary_image > 0] = 1\n",
        "    create_image(final_binary_image, os.path.join(directory, \"final_binary.png\"))\n",
        "\n",
        "    print(final_image.shape)\n",
        "    print(\"num added: {}. num removed: {}\".format(num_added, num_removed))\n",
        "    img = create_image(final_image, os.path.join(directory, 'final.png'))\n",
        "    return img, deepcopy(final_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJjq3kNqJCOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC6ZVFAFeqBb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d5aeeea3-a91e-4ddb-89e4-c0a796cddfbf"
      },
      "source": [
        "# model = keras.models.load_model(model_location)\n",
        "\n",
        "drive_folder = '/content/drive/My Drive'\n",
        "\n",
        "model_names = ['sc-model-es-net-60000-4',\n",
        "               #'sc-model-es-net-60000-16',\n",
        "               'sc-model-nade-60000-4']\n",
        "\n",
        "config = {\n",
        "    'sc-model-es-net-60000-4': {\n",
        "        \"iterations\": 400,\n",
        "        \"temp_start\": 0.99,\n",
        "        \"temp_end\": 0.99,\n",
        "        \"top_k\": 1000\n",
        "    },\n",
        "    'sc-model-nade-60000-4': {\n",
        "        \"iterations\": 300,\n",
        "        \"temp_start\": 0.99,\n",
        "        \"temp_end\": 0.99,\n",
        "        \"top_k\" : 1000\n",
        "    }\n",
        "}\n",
        "\n",
        "sample_sqrt = 5\n",
        "for model_name in model_names:\n",
        "    model = keras.models.load_model(os.path.join(drive_folder, model_name + '.hdf5'))\n",
        "    model_config = config[model_name]\n",
        "    generated_images = []\n",
        "    for i in range(sample_sqrt**2):\n",
        "        directory = \"images_{}\".format(i)\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "        input_image = generate_noise()\n",
        "        # input_image = np.expand_dims(np.expand_dims(images[i], 0), -1)\n",
        "\n",
        "        img, _ = inference(model, input_image, directory, model_config['iterations'], temp_start=model_config['temp_start'], temp_end=model_config['temp_end'], top_k=model_config['top_k'], is_grayscale=is_grayscale, is_debug=False, filename=model_name)\n",
        "        generated_images.append(img)\n",
        "    \n",
        "    final_im = Image.new('RGB', (28 * sample_sqrt, 28 * sample_sqrt))\n",
        "\n",
        "    y_offset = 0\n",
        "    for i in range(sample_sqrt):\n",
        "        x_offset = 0\n",
        "        new_im = Image.new('RGB', (28 * sample_sqrt, 28))\n",
        "        for j in range(sample_sqrt):\n",
        "            im = deepcopy(generated_images[(i * sample_sqrt) + j])\n",
        "            new_im.paste(im, (x_offset, 0))\n",
        "            x_offset += 28\n",
        "        final_im.paste(new_im, (0, y_offset))\n",
        "        y_offset += 28\n",
        "        \n",
        "    final_im.save(model_name + '.png')"
      ],
      "execution_count": 530,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 28, 28, 1)\n",
            "num added: 224. num removed: 276\n",
            "(1, 28, 28, 1)\n",
            "num added: 219. num removed: 281\n",
            "(1, 28, 28, 1)\n",
            "num added: 223. num removed: 277\n",
            "(1, 28, 28, 1)\n",
            "num added: 128. num removed: 372\n",
            "(1, 28, 28, 1)\n",
            "num added: 219. num removed: 281\n",
            "(1, 28, 28, 1)\n",
            "num added: 243. num removed: 257\n",
            "(1, 28, 28, 1)\n",
            "num added: 122. num removed: 378\n",
            "(1, 28, 28, 1)\n",
            "num added: 160. num removed: 340\n",
            "(1, 28, 28, 1)\n",
            "num added: 137. num removed: 363\n",
            "(1, 28, 28, 1)\n",
            "num added: 154. num removed: 346\n",
            "(1, 28, 28, 1)\n",
            "num added: 289. num removed: 211\n",
            "(1, 28, 28, 1)\n",
            "num added: 231. num removed: 269\n",
            "(1, 28, 28, 1)\n",
            "num added: 76. num removed: 424\n",
            "(1, 28, 28, 1)\n",
            "num added: 256. num removed: 244\n",
            "(1, 28, 28, 1)\n",
            "num added: 143. num removed: 357\n",
            "(1, 28, 28, 1)\n",
            "num added: 174. num removed: 326\n",
            "(1, 28, 28, 1)\n",
            "num added: 219. num removed: 281\n",
            "(1, 28, 28, 1)\n",
            "num added: 257. num removed: 243\n",
            "(1, 28, 28, 1)\n",
            "num added: 205. num removed: 295\n",
            "(1, 28, 28, 1)\n",
            "num added: 142. num removed: 358\n",
            "(1, 28, 28, 1)\n",
            "num added: 232. num removed: 268\n",
            "(1, 28, 28, 1)\n",
            "num added: 108. num removed: 392\n",
            "(1, 28, 28, 1)\n",
            "num added: 121. num removed: 379\n",
            "(1, 28, 28, 1)\n",
            "num added: 206. num removed: 294\n",
            "(1, 28, 28, 1)\n",
            "num added: 210. num removed: 290\n",
            "(1, 28, 28, 1)\n",
            "num added: 498. num removed: 2\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 497. num removed: 3\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 498. num removed: 2\n",
            "(1, 28, 28, 1)\n",
            "num added: 497. num removed: 3\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 499. num removed: 1\n",
            "(1, 28, 28, 1)\n",
            "num added: 498. num removed: 2\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n",
            "(1, 28, 28, 1)\n",
            "num added: 500. num removed: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DF783hh7cg_P"
      },
      "source": [
        "## Train Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW-M3GAmeqBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterations = 500\n",
        " \n",
        "generated_samples = []\n",
        "for i in range(int(len(training_samples) / 2)):\n",
        "    directory = \"discriminator\"\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    input_image = generate_noise()\n",
        "\n",
        "    _, generated = inference(model, input_image, directory, iterations, temp_start=1, temp_end=1)\n",
        "    generated_samples.append(generated)\n",
        "\n",
        "print(len(generated_samples))\n",
        "original_gen_samples = deepcopy(generated_samples)\n",
        "generated_samples = np.asarray(generated_samples)\n",
        "print(generated_samples.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2tqKYqmJ3uJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_samples = np.random.rand(int(len(training_samples) / 2), *image_shape)\n",
        "random_samples[random_samples >= 0.5] = 1\n",
        "random_samples[random_samples < 0.5] = 0\n",
        "\n",
        "generated_samples = generated_samples.reshape(-1, *image_shape)\n",
        "images = training_samples\n",
        "images = np.expand_dims(images, axis=-1)\n",
        "\n",
        "discriminator_train_x = np.concatenate((generated_samples, random_samples, images), axis=0)\n",
        "print(generated_samples.shape)\n",
        "print(random_samples.shape)\n",
        "print(images.shape)\n",
        "discriminator_train_y = np.concatenate((np.full((generated_samples.shape[0], 1), 0), \n",
        "                                        np.full((random_samples.shape[0], 1), 0),\n",
        "                                        np.full((images.shape[0], 1), 1)), \n",
        "                                        axis=0)\n",
        "\n",
        "print(discriminator_train_x.shape)\n",
        "print(discriminator_train_y.shape)\n",
        "\n",
        "\n",
        "p = np.random.permutation(len(discriminator_train_x))\n",
        "discriminator_train_x, discriminator_train_y = discriminator_train_x[p], discriminator_train_y[p]\n",
        "print(discriminator_train_x.shape)\n",
        "print(discriminator_train_y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PVue6Y9M0Ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Flatten, Dense, Reshape\n",
        "\n",
        "def discriminator(input_size=(28, 28, 1), n_filters_start=16, growth_factor=2, num_layers=1):\n",
        "    inputs = Input(input_size)\n",
        "    droprate = 0.5\n",
        "    n_filters = n_filters_start\n",
        "    prev_layer = inputs\n",
        "    for _ in range(num_layers):\n",
        "        batch_norm = BatchNormalization()(prev_layer)\n",
        "        conv = Conv2D(n_filters, kernel_size=(3, 3), strides=(2,2), activation='relu', padding='same')(batch_norm)\n",
        "        drop_layer = Dropout(droprate)(conv)\n",
        "        prev_layer = drop_layer\n",
        "        n_filters *= growth_factor\n",
        "\n",
        "    flatten = Flatten()(prev_layer)\n",
        "    # reshape_layer = Reshape((-1, 512))(prev_layer)\n",
        "    validity = Dense(1, activation='sigmoid')(flatten)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=validity)\n",
        "    model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNM3mo1NJeub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator_model = discriminator(input_size=image_shape)\n",
        "model_location = F'/content/drive/My Drive/sc-discrim-model.hdf5'\n",
        "\n",
        "# model = keras.models.load_model(model_location)\n",
        "\n",
        "discrim_batch_size = 64\n",
        "\n",
        "steps_per_epoch = int(len(discriminator_train_x) * split / discrim_batch_size)  \n",
        "validation_steps = int(len(discriminator_train_x) * (1 - split) / discrim_batch_size)  \n",
        "\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_location,\n",
        "    monitor='val_loss',\n",
        "    save_weights_only=False,\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir='./logs', update_freq='epoch')\n",
        "\n",
        "if True:\n",
        "    discrim_history = discriminator_model.fit(\n",
        "        x=discriminator_train_x,\n",
        "        y=discriminator_train_y,\n",
        "        batch_size=discrim_batch_size,\n",
        "        validation_split=split,\n",
        "        verbose=1,\n",
        "        shuffle=True,\n",
        "        epochs=100,\n",
        "        callbacks=[model_checkpoint_callback, tensorboard_callback])\n",
        "    #epochs=cfg.epochs,\n",
        "    #callbacks=callbacks)\n",
        "# model.save(\"sc-model.hdf5\")\n",
        "if True:\n",
        "    plt.plot(discrim_history.history['loss'])\n",
        "    plt.plot(discrim_history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz7XvYS3pduE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference_with_discriminator(model, discrim_model, input_image, directory, iterations, temp_low=0.5, temp_high=2):\n",
        "    create_image(input_image, \"{}/input.png\".format(directory))\n",
        "\n",
        "    # pprint(temperatures)\n",
        "    \n",
        "    working_image = deepcopy(input_image)\n",
        "    consecutive = 0\n",
        "    for i in range(iterations):\n",
        "        discrim_predict = discrim_model.predict(working_image)[0]\n",
        "        if discrim_predict >= 0.95:\n",
        "            consecutive += 1\n",
        "            if consecutive >= 100:\n",
        "                break\n",
        "        else:\n",
        "            consecutive = 0\n",
        "\n",
        "        temp = temp_low + ((temp_high - temp_low) * (1 - discrim_predict))\n",
        "        \n",
        "        print(\"temp: {}\".format(temp))\n",
        "        predictions = model.predict(working_image)\n",
        "        predictions = predictions.flatten()\n",
        "        predictions = np.exp(predictions / temp)\n",
        "        predictions = predictions / np.sum(predictions)\n",
        "        # print(predictions)\n",
        "        indices = np.arange(predictions.shape[0])\n",
        "        index = np.random.choice(indices, p=predictions)\n",
        "        working_image = working_image.flatten()\n",
        "        if working_image[index] == 1:\n",
        "            working_image[index] = 0\n",
        "        elif working_image[index] == 0:\n",
        "            working_image[index] = 1\n",
        "        else:\n",
        "            print(working_image[index])\n",
        "        working_image = np.reshape(working_image, [1, *image_shape])\n",
        "        if i % 100 == 0:\n",
        "            create_image(working_image, os.path.join(directory, \"working_{}.png\".format(i)))\n",
        "\n",
        "    print(working_image.shape)\n",
        "    img = create_image(working_image, os.path.join(directory, \"final.png\"))\n",
        "    return img, deepcopy(working_image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NR7vdWxukd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_images = []\n",
        "\n",
        "sample_sqrt = 1\n",
        "for i in range(sample_sqrt**2):\n",
        "    directory = \"images_discrim_{}\".format(i)\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    # input_image = images[0]\n",
        "    # input_image = np.expand_dims(input_image, 0)\n",
        "\n",
        " \n",
        "    img, _ = inference_with_discriminator(model, discriminator_model, input_image, directory, 10000)\n",
        "    generated_images.append(img)\n",
        "    \n",
        "final_im = Image.new('RGB', (28 * sample_sqrt, 28 * sample_sqrt))\n",
        "\n",
        "y_offset = 0\n",
        "for i in range(sample_sqrt):\n",
        "    x_offset = 0\n",
        "    new_im = Image.new('RGB', (28 * sample_sqrt, 28))\n",
        "    for j in range(sample_sqrt):\n",
        "        im = generated_images[(i * sample_sqrt) + j]\n",
        "        new_im.paste(im, (x_offset, 0))\n",
        "        x_offset += 28\n",
        "    final_im.paste(new_im, (0, y_offset))\n",
        "    y_offset += 28\n",
        "    \n",
        "final_im.save('final_with_discrim.png')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}